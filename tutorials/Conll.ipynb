{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONLL Entity Relation Extraction Tutorial\n",
    "This tutorial is to show you how to make a very simple, yet thorough learning program that also utilizes knowledge integration to apply constraints on Entity Recognition and Relation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root Folder Absoloute path:  /home/hfaghihi/Framework/DomiKnowS\n"
     ]
    }
   ],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "root = os.path.dirname(currentdir)\n",
    "print(\"root Folder Absoloute path: \", root)\n",
    "\n",
    "import sys\n",
    "sys.path.append(root)\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Graph\n",
    "First we define the graph code that defines the domain knowledge for this problem.\n",
    "This graph defines a set of input side data structure in the subgraph of *linguistics* and define the output decision space in the subgraph of *application*. We encourage you to follow the same split for more readable graph declaration but the structure is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file for dataNode is in: /home/hfaghihi/Framework/DomiKnowS/tutorials/datanode.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('arg1', 'phrase'), ('arg2', 'phrase')]) is used.\n"
     ]
    }
   ],
   "source": [
    "from regr.graph import Graph, Concept, Relation\n",
    "from regr.graph.logicalConstrain import ifL, andL, nandL, V\n",
    "\n",
    "\n",
    "Graph.clear()\n",
    "Concept.clear()\n",
    "Relation.clear()\n",
    "\n",
    "with Graph('global') as graph:\n",
    "    with Graph('linguistic') as ling_graph:       \n",
    "        word = Concept(name='word')\n",
    "        phrase = Concept(name='phrase')\n",
    "        sentence = Concept(name='sentence')\n",
    "        (rel_sentence_contains_word,) = sentence.contains(word)\n",
    "        (rel_sentence_contains_phrase,) = sentence.contains(phrase)\n",
    "        (rel_phrase_contains_word,) = phrase.contains(word)\n",
    "\n",
    "        pair = Concept(name='pair')\n",
    "        (rel_pair_phrase1, rel_pair_phrase2) = pair.has_a(arg1=phrase, arg2=phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can use the graph structure as a background knowledge to introduce rules into the inference algorithms, you can specify the keyword *auto_constraint* to be **True** if you want us to generate automatic constraints based on the graph. You can disable the constraint generation for specific relationship definition by using the same keyword and making it equal to **False**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph:\n",
    "    with Graph('application', auto_constraint=True) as app_graph:\n",
    "        entity = phrase(name='entity')\n",
    "        people = entity(name='people', auto_constraint=True)\n",
    "        organization = entity(name='organization', auto_constraint=False)\n",
    "        location = entity(name='location', auto_constraint=None)\n",
    "        # auto_constraint->True due to its graph\n",
    "        other = entity(name='other')\n",
    "        o = entity(name='O')\n",
    "\n",
    "        work_for = pair(name='work_for')\n",
    "        \n",
    "        located_in = pair(name='located_in')\n",
    "        \n",
    "\n",
    "        live_in = pair(name='live_in')\n",
    "        # auto_constraint->True due to its graph\n",
    "\n",
    "        orgbase_on = pair(name='orgbase_on')\n",
    "        kill = pair(name='kill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **has_a** relationship is equivalant to having a many to many table structure between the arguments in the relation. So the *pair*, we are introducing a relationship between phrases. The **contains** relationship also implies a parent child structure which is a one-to-many relationship between the concept that contains the other one and the concept being contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph:\n",
    "    with app_graph:    \n",
    "        ifL(work_for, V(name='x'), andL(people, V(v=('x', rel_pair_phrase1.name)), organization, V(v=('x', rel_pair_phrase2.name))))\n",
    "#         work_for.has_a(people, organization, auto_constraint=True)\n",
    "\n",
    "#         ifL(located_in, V(name='x'), andL(location, V(v=('x', rel_pair_phrase1.name)), location, V(v=('x', rel_pair_phrase2.name))))\n",
    "        located_in.has_a(location, location, auto_constraint=True)\n",
    "        \n",
    "#         ifL(live_in, V(name='x'), andL(people, V(v=('x', rel_pair_phrase1.name)), location, V(v=('x', rel_pair_phrase2.name))))\n",
    "        live_in.has_a(people, location, auto_constraint=None)\n",
    "\n",
    "        #ifL(orgbase_on, ('x', 'y'), andL(organization, ('x',), location, ('y',)))\n",
    "        ifL(orgbase_on, V(name='x'), andL(organization, V(v=('x', rel_pair_phrase1.name)), location, V(v=('x', rel_pair_phrase2.name))))\n",
    "        \n",
    "        #ifL(kill, ('x', 'y'), andL(people, ('x',), people, ('y',)))\n",
    "        ifL(kill, V(name='x'), andL(people, V(v=('x', rel_pair_phrase1.name)), people, V(v=('x', rel_pair_phrase2.name))))\n",
    "        \n",
    "        nandL(people, organization, location, other, o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To introduce the domain range constraints for relationships, we can use either the **has_a** graph structure or directluy introduce a constraint by using our Constraint interface. Remember that if you use the **has_a** to introduce the rules for the domain and range of the arguments, you have to specify the auto_constraints to be *True*. If you put *auto_constraint=None* or do not add any *auto_constraint* input then the *auto_constraint* value will be inherited from the graph definition as all the nodes and relationships are defined inside the graph.\n",
    "\n",
    "The **nandL** constraint is also implying that the concept classes mentioned in the paranthesis are disjoint.\n",
    "\n",
    "For more information on how to write your own constraints, please refer to our constraint interface tutorials and documents!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Data Reader\n",
    "Here we use the Pytorch DataLoader to define our training and test instances. You can use your customized readers as long as the output for the reader class is an iterable object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from examples.conll04.conll.data.reader import Conll04CorpusReader\n",
    "\n",
    "class Conll04DataLoader(DataLoader):\n",
    "    def __init__(self, path, reader=None, **kwargs):\n",
    "        self.path = path\n",
    "        self.reader = reader or Conll04CorpusReader()\n",
    "        sentences_list, relations_list = self.reader(path)\n",
    "        samples = list(zip(sentences_list, relations_list))\n",
    "        super().__init__(samples, collate_fn=self._collate_fn, **kwargs)\n",
    "    \n",
    "    def _collate_fn(self, batch):\n",
    "        sentences, relations = zip(*batch)\n",
    "        # (tokens, pos, label)\n",
    "        # (relation_type, (src_index, src_token), (dst_index, dst_token))\n",
    "        tokens, postags, labels = zip(*sentences)\n",
    "        data_item = {\n",
    "            'sentence': [' '.join(token_list) for token_list in tokens],\n",
    "            'tokens': list(tokens),\n",
    "            'postag': list(postags),\n",
    "            'label': list(labels),\n",
    "            'relation': list(relations),\n",
    "        }\n",
    "        #import pdb; pdb.set_trace()\n",
    "        return data_item\n",
    "\n",
    "class SingletonDataLoader(Conll04DataLoader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, batch_size=1, **kwargs)\n",
    "\n",
    "    def _collate_fn(self, batch):\n",
    "        assert len(batch) == 1\n",
    "        sentences, relations = zip(*batch)\n",
    "        # (tokens, pos, label)\n",
    "        # (relation_type, (src_index, src_token), (dst_index, dst_token))\n",
    "        tokens, postags, labels = zip(*sentences)\n",
    "        data_item = {\n",
    "            #'sentence': [' '.join(token_list) for token_list in tokens],\n",
    "            'tokens': tokens[0],\n",
    "            'postag': postags[0],\n",
    "            'label': labels[0],\n",
    "            'relation': relations[0],\n",
    "        }\n",
    "        return data_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the output of the reader looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Corpus: 100%|██████████| 114213/114213 [00:00<00:00, 240096.81it/s]\n",
      "Reading Corpus: 100%|██████████| 28028/28028 [00:00<00:00, 233398.10it/s]\n"
     ]
    }
   ],
   "source": [
    "train_reader = SingletonDataLoader('../examples/conll04/data/conll04.corp_1_train.corp')\n",
    "test_reader = SingletonDataLoader('../examples/conll04/data/conll04.corp_1_test.corp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['The', 'industry', 'group', 'said', 'methanol', 'would', 'be', 'the', 'most', 'likely', 'alternative', 'fuel', 'if', 'the', 'Bush', 'program', 'went', 'into', 'effect.'], 'postag': ['DT', 'NN', 'NN', 'VBD', 'NN', 'MD', 'VB', 'DT', 'RBS', 'JJ', 'JJ', 'NN', 'IN', 'DT', 'NNP', 'NN', 'VBD', 'IN', 'NN'], 'label': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'Peop', 'O', 'O', 'O', 'O'], 'relation': []}\n"
     ]
    }
   ],
   "source": [
    "print(list(iter(train_reader))[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined the keywords to be `tokens`, `postag`, `label`, `relation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Declaration\n",
    "\n",
    "In this section, we start by defining our sensors and required toolkits and then start connecting our sensors and learners to their right place in the graph.\n",
    "\n",
    "First, As we want to use `Spacy` to define the word features, we intialize a `Spacy` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# from spacy.lang.en import English\n",
    "nlp = spacy.load('en_core_web_sm') #English()\n",
    "\n",
    "FEATURE_DIM = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a classifier which we will use later in the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Classifier(torch.nn.Sequential):\n",
    "    def __init__(self, in_features) -> None:\n",
    "        linear = torch.nn.Linear(in_features, 2)\n",
    "        super().__init__(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we import a set of our predefined basic sensors which enables us to use the functionality of the DomiKnows declarative sensor and learner definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.sensor.pytorch.sensors import FunctionalSensor, JointSensor, ReaderSensor, FunctionalReaderSensor\n",
    "from regr.sensor.pytorch.learners import ModuleLearner\n",
    "from regr.sensor.pytorch.relation_sensors import CompositionCandidateSensor\n",
    "from regr.sensor.pytorch.query_sensor import DataNodeReaderSensor\n",
    "\n",
    "graph.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we start by Definign some **ReaderSensor**s to connect our DataLoader with appropriate properties in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase['text'] = ReaderSensor(keyword='tokens')\n",
    "phrase['postag'] = ReaderSensor(keyword='postag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the data about the Phrases, we also read the annotation of labels into the graph by using a customized **ReaderSensor** which we call **FunctionalReaderSensor**. In addition to having access to the DataLoader output, the **FunctionalReaderSensor** accepts a function as input at initialization which it will apply on the read data before generating the outputs. Remember to put `label=True` Whenever you are reading an annotation to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_label(label_type):\n",
    "        def find(data):\n",
    "            try:\n",
    "                label = torch.tensor([item==label_type for item in data])\n",
    "            except:\n",
    "                print(data)\n",
    "                raise\n",
    "            return label # torch.stack((~label, label), dim=1)\n",
    "        return find\n",
    "        raise\n",
    "phrase[people] = FunctionalReaderSensor(keyword='label', forward=find_label('Peop'), label=True)\n",
    "phrase[organization] = FunctionalReaderSensor(keyword='label', forward=find_label('Org'), label=True)\n",
    "phrase[location] = FunctionalReaderSensor(keyword='label', forward=find_label('Loc'), label=True)\n",
    "phrase[other] = FunctionalReaderSensor(keyword='label', forward=find_label('Other'), label=True)\n",
    "phrase[o] = FunctionalReaderSensor(keyword='label', forward=find_label('O'), label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, We define a word to vector sensor using a **FunctionalSensor** to generate the word representation from their string utilizing the spacy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(text):\n",
    "    texts = list(map(lambda x: ' '.join(x.split('/')), text))\n",
    "    tokens_list = list(nlp.pipe(texts))\n",
    "    return torch.tensor([tokens.vector for tokens in tokens_list])\n",
    "\n",
    "phrase['w2v'] = FunctionalSensor('text', forward=word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as our data included the phrases directly, we want to merge phrases in the same sentence to create the concept nodes for `sentence`. To generate a concept from another one, we have to use the edges defined on the graph between those two concepts. Here we use the `contains` edge defined on the graph and as the default relationship was defined from a sentence to a phrase, here we use the keyword `reversed` after the relationship variable to indicate the reverse direction of the same relationship. \n",
    "\n",
    "Whenever, you want to define the connection, you have to return a matric connecting the nodes from the source to the target concept in a form of 0 and 1s. Apart from that we also want to generate the feature `Text` containing the actual string feature for a sentence in the same sensor, because of that, we use a **JointSensor** which is able to connect one sensor to multiple proprties on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_phrase(phrase_text):\n",
    "    return [' '.join(phrase_text)], torch.ones((1, len(phrase_text)))\n",
    "sentence['text', rel_sentence_contains_phrase.reversed] = JointSensor(phrase['text'], forward=merge_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a set of learners on top of the phrases to decide about each phrase class. In this scenario, we are assigning independent boolean classifers for each phrase type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase[people] = ModuleLearner('w2v', module=Classifier(FEATURE_DIM))\n",
    "phrase[organization] = ModuleLearner('w2v', module=Classifier(FEATURE_DIM))\n",
    "phrase[location] = ModuleLearner('w2v', module=Classifier(FEATURE_DIM))\n",
    "phrase[other] = ModuleLearner('w2v', module=Classifier(FEATURE_DIM))\n",
    "phrase[o] = ModuleLearner('w2v', module=Classifier(FEATURE_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the pair concept and use the **ComposionCandidateSensor** to generate pair candidates based on our phrases. This sensor receives one instance of each argument at a time and return **True** to make a candidate pair for that combination or **False** to skip the combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair[rel_pair_phrase1.reversed, rel_pair_phrase2.reversed] = CompositionCandidateSensor(\n",
    "    phrase['w2v'],\n",
    "    relations=(rel_pair_phrase1.reversed, rel_pair_phrase2.reversed),\n",
    "    forward=lambda *_, **__: True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a property `emb` for the pair candidates based on the representation of their arguments. We use the relation links defined on the previous sensor to retrieve the `w2v` properties on each argument and concat them in the `forward` function of the **FunctionalSensor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair['emb'] = FunctionalSensor(\n",
    "    rel_pair_phrase1.reversed('w2v'), rel_pair_phrase2.reversed('w2v'),\n",
    "    forward=lambda arg1, arg2: torch.cat((arg1, arg2), dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define our classifiers on top of the pair `emb` properties to decide about the type of each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair[work_for] = ModuleLearner('emb', module=Classifier(FEATURE_DIM*2))\n",
    "pair[located_in] = ModuleLearner('emb', module=Classifier(FEATURE_DIM*2))\n",
    "pair[live_in] = ModuleLearner('emb', module=Classifier(FEATURE_DIM*2))\n",
    "pair[orgbase_on] = ModuleLearner('emb', module=Classifier(FEATURE_DIM*2))\n",
    "pair[kill] = ModuleLearner('emb', module=Classifier(FEATURE_DIM*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we read the annotation of each pair from the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relation(relation_type):\n",
    "    def find(arg1m, arg2m, data):\n",
    "        label = torch.zeros(arg1m.shape[0], dtype=torch.bool)\n",
    "        for rel, (arg1,*_), (arg2,*_) in data:\n",
    "            if rel == relation_type:\n",
    "                i, = (arg1m[:, arg1] * arg2m[:, arg2]).nonzero(as_tuple=True)\n",
    "                label[i] = True\n",
    "        return label # torch.stack((~label, label), dim=1)\n",
    "    return find\n",
    "pair[work_for] = FunctionalReaderSensor(pair[rel_pair_phrase1.reversed], pair[rel_pair_phrase2.reversed], keyword='relation', forward=find_relation('Work_For'), label=True)\n",
    "pair[located_in] = FunctionalReaderSensor(pair[rel_pair_phrase1.reversed], pair[rel_pair_phrase2.reversed], keyword='relation', forward=find_relation('Located_In'), label=True)\n",
    "pair[live_in] = FunctionalReaderSensor(pair[rel_pair_phrase1.reversed], pair[rel_pair_phrase2.reversed], keyword='relation', forward=find_relation('Live_In'), label=True)\n",
    "pair[orgbase_on] = FunctionalReaderSensor(pair[rel_pair_phrase1.reversed], pair[rel_pair_phrase2.reversed], keyword='relation', forward=find_relation('OrgBased_In'), label=True)\n",
    "pair[kill] = FunctionalReaderSensor(pair[rel_pair_phrase1.reversed], pair[rel_pair_phrase2.reversed], keyword='relation', forward=find_relation('Kill'), label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After connecting all the sensors and learners to the graph, we have to define a Program instance to be able to autoamtically train and test our models. Here, we use the **POIProgram**, which execute all the properties which have multiple assignment in the graph~(multiple sensors connect) and their dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.program import POIProgram, IMLProgram, SolverPOIProgram\n",
    "from regr.program.metric import MacroAverageTracker, PRF1Tracker, PRF1Tracker, DatanodeCMMetric\n",
    "from regr.program.loss import NBCrossEntropyLoss, NBCrossEntropyIMLoss\n",
    "\n",
    "program = POIProgram(graph, poi=(sentence, phrase), loss=MacroAverageTracker(NBCrossEntropyLoss()), metric=PRF1Tracker())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start training we can call the train method on the **POIProgram** instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:regr.program.program:Epoch: 0\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 0 Training: 100%|██████████| 2/2 [00:00<00:00, 19.67it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'people': tensor(0.8191), 'organization': tensor(0.3770), 'location': tensor(0.6421), 'other': tensor(0.8391), 'O': tensor(1.9077)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'people': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'organization': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'location': {'P': tensor(0.1111, device='cuda:1'), 'R': tensor(0.5000, device='cuda:1'), 'F1': tensor(0.1818, device='cuda:1')}, 'other': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'O': {'P': tensor(1., device='cuda:1'), 'R': tensor(0.0652, device='cuda:1'), 'F1': tensor(0.1224, device='cuda:1')}}\n",
      "INFO:regr.program.program:Epoch: 1\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 1 Training: 100%|██████████| 2/2 [00:00<00:00, 21.82it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'people': tensor(0.8134), 'organization': tensor(0.3740), 'location': tensor(0.6370), 'other': tensor(0.8288), 'O': tensor(1.8905)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'people': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'organization': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'location': {'P': tensor(0.1111, device='cuda:1'), 'R': tensor(0.5000, device='cuda:1'), 'F1': tensor(0.1818, device='cuda:1')}, 'other': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'O': {'P': tensor(1., device='cuda:1'), 'R': tensor(0.0652, device='cuda:1'), 'F1': tensor(0.1224, device='cuda:1')}}\n",
      "INFO:regr.program.program:Epoch: 2\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 2 Training: 100%|██████████| 2/2 [00:00<00:00, 21.71it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'people': tensor(0.8078), 'organization': tensor(0.3710), 'location': tensor(0.6320), 'other': tensor(0.8186), 'O': tensor(1.8735)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'people': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'organization': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'location': {'P': tensor(0.1176, device='cuda:1'), 'R': tensor(0.5000, device='cuda:1'), 'F1': tensor(0.1905, device='cuda:1')}, 'other': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'O': {'P': tensor(1., device='cuda:1'), 'R': tensor(0.0652, device='cuda:1'), 'F1': tensor(0.1224, device='cuda:1')}}\n",
      "INFO:regr.program.program:Epoch: 3\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 3 Training: 100%|██████████| 2/2 [00:00<00:00, 21.64it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'people': tensor(0.8023), 'organization': tensor(0.3681), 'location': tensor(0.6270), 'other': tensor(0.8085), 'O': tensor(1.8567)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'people': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'organization': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'location': {'P': tensor(0.1176, device='cuda:1'), 'R': tensor(0.5000, device='cuda:1'), 'F1': tensor(0.1905, device='cuda:1')}, 'other': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'O': {'P': tensor(1., device='cuda:1'), 'R': tensor(0.0652, device='cuda:1'), 'F1': tensor(0.1224, device='cuda:1')}}\n",
      "INFO:regr.program.program:Epoch: 4\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 4 Training: 100%|██████████| 2/2 [00:00<00:00, 21.14it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'people': tensor(0.7968), 'organization': tensor(0.3652), 'location': tensor(0.6221), 'other': tensor(0.7986), 'O': tensor(1.8400)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'people': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'organization': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'location': {'P': tensor(0.1176, device='cuda:1'), 'R': tensor(0.5000, device='cuda:1'), 'F1': tensor(0.1905, device='cuda:1')}, 'other': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'O': {'P': tensor(1., device='cuda:1'), 'R': tensor(0.0652, device='cuda:1'), 'F1': tensor(0.1224, device='cuda:1')}}\n",
      "INFO:regr.program.program:Epoch: 5\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 5 Training: 100%|██████████| 2/2 [00:00<00:00, 21.98it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'people': tensor(0.7914), 'organization': tensor(0.3624), 'location': tensor(0.6173), 'other': tensor(0.7889), 'O': tensor(1.8235)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'people': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'organization': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'location': {'P': tensor(0.0625, device='cuda:1'), 'R': tensor(0.2500, device='cuda:1'), 'F1': tensor(0.1000, device='cuda:1')}, 'other': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'O': {'P': tensor(1., device='cuda:1'), 'R': tensor(0.0652, device='cuda:1'), 'F1': tensor(0.1224, device='cuda:1')}}\n",
      "INFO:regr.program.program:Epoch: 6\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 6 Training: 100%|██████████| 2/2 [00:00<00:00, 21.20it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'people': tensor(0.7861), 'organization': tensor(0.3596), 'location': tensor(0.6125), 'other': tensor(0.7793), 'O': tensor(1.8072)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'people': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'organization': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'location': {'P': tensor(0.0625, device='cuda:1'), 'R': tensor(0.2500, device='cuda:1'), 'F1': tensor(0.1000, device='cuda:1')}, 'other': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'O': {'P': tensor(1., device='cuda:1'), 'R': tensor(0.0652, device='cuda:1'), 'F1': tensor(0.1224, device='cuda:1')}}\n",
      "INFO:regr.program.program:Epoch: 7\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 7 Training: 100%|██████████| 2/2 [00:00<00:00, 21.22it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'people': tensor(0.7809), 'organization': tensor(0.3568), 'location': tensor(0.6078), 'other': tensor(0.7698), 'O': tensor(1.7911)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'people': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'organization': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'location': {'P': tensor(0.0625, device='cuda:1'), 'R': tensor(0.2500, device='cuda:1'), 'F1': tensor(0.1000, device='cuda:1')}, 'other': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'O': {'P': tensor(1., device='cuda:1'), 'R': tensor(0.0652, device='cuda:1'), 'F1': tensor(0.1224, device='cuda:1')}}\n",
      "INFO:regr.program.program:Epoch: 8\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 8 Training: 100%|██████████| 2/2 [00:00<00:00, 22.00it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'people': tensor(0.7758), 'organization': tensor(0.3541), 'location': tensor(0.6032), 'other': tensor(0.7605), 'O': tensor(1.7751)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'people': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'organization': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'location': {'P': tensor(0.0625, device='cuda:1'), 'R': tensor(0.2500, device='cuda:1'), 'F1': tensor(0.1000, device='cuda:1')}, 'other': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'O': {'P': tensor(1., device='cuda:1'), 'R': tensor(0.0652, device='cuda:1'), 'F1': tensor(0.1224, device='cuda:1')}}\n",
      "INFO:regr.program.program:Epoch: 9\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 9 Training: 100%|██████████| 2/2 [00:00<00:00, 21.66it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'people': tensor(0.7707), 'organization': tensor(0.3514), 'location': tensor(0.5986), 'other': tensor(0.7513), 'O': tensor(1.7593)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'people': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'organization': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'location': {'P': tensor(0.0625, device='cuda:1'), 'R': tensor(0.2500, device='cuda:1'), 'F1': tensor(0.1000, device='cuda:1')}, 'other': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'O': {'P': tensor(1., device='cuda:1'), 'R': tensor(0.0652, device='cuda:1'), 'F1': tensor(0.1224, device='cuda:1')}}\n"
     ]
    }
   ],
   "source": [
    "program.train(list(iter(train_reader))[0:2], train_epoch_num=10, Optim=lambda param: torch.optim.SGD(param, lr=.0001), device='cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:regr.program.program:Testing:\n",
      "Testing: 100%|██████████| 20/20 [00:00<00:00, 21.97it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'people': tensor(0.7301), 'organization': tensor(0.7504), 'location': tensor(0.5720), 'other': tensor(0.4013), 'O': tensor(0.6909)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'people': {'P': tensor(0.0556, device='cuda:1'), 'R': tensor(0.5000, device='cuda:1'), 'F1': tensor(0.1000, device='cuda:1')}, 'organization': {'P': tensor(0.0056, device='cuda:1'), 'R': tensor(0.1000, device='cuda:1'), 'F1': tensor(0.0106, device='cuda:1')}, 'location': {'P': tensor(0.0339, device='cuda:1'), 'R': tensor(0.3077, device='cuda:1'), 'F1': tensor(0.0611, device='cuda:1')}, 'other': {'P': tensor(0., device='cuda:1'), 'R': tensor(0., device='cuda:1'), 'F1': tensor(0., device='cuda:1')}, 'O': {'P': tensor(0.9269, device='cuda:1'), 'R': tensor(0.5356, device='cuda:1'), 'F1': tensor(0.6789, device='cuda:1')}}\n"
     ]
    }
   ],
   "source": [
    "program.test(list(iter(test_reader))[0:20], device=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "reader = SingletonDataLoader('data/conll04.corp')\n",
    "\n",
    "for node in program.populate(reader, device='auto'):\n",
    "    assert node.ontologyNode is sentence\n",
    "    phrase_node = node.getChildDataNodes()[0]\n",
    "    assert phrase_node.ontologyNode is phrase\n",
    "\n",
    "    node.infer()\n",
    "\n",
    "    if phrase_node.getAttribute(people) is not None:\n",
    "        assert phrase_node.getAttribute(people, 'softmax') > 0\n",
    "        node.inferILPResults(fun=None)\n",
    "\n",
    "        ILPmetrics = node.getInferMetric()\n",
    "\n",
    "        print(\"ILP metrics Total %s\"%(ILPmetrics['Total']))\n",
    "\n",
    "        assert phrase_node.getAttribute(people, 'ILP') >= 0\n",
    "    else:\n",
    "        print(\"%s phrases have no values for attribute people\"%(node.getAttribute('text')))\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
