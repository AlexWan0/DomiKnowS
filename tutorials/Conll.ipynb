{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONLL Entity Relation Extraction Tutorial\n",
    "This tutorial is to show you how to make a very simple, yet thorough learning program that also utilizes knowledge integration to apply constraints on Entity Recognition and Relation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root Folder Absoloute path:  /home/hfaghihi/Framework/DomiKnowS\n"
     ]
    }
   ],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "root = os.path.dirname(currentdir)\n",
    "print(\"root Folder Absoloute path: \", root)\n",
    "\n",
    "import sys\n",
    "sys.path.append(root)\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Graph\n",
    "First we define the graph code that defines the domain knowledge for this problem.\n",
    "This graph defines a set of input side data structure in the subgraph of *linguistics* and define the output decision space in the subgraph of *application*. We encourage you to follow the same split for more readable graph declaration but the structure is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file for dataNode is in: /home/hfaghihi/Framework/DomiKnowS/tutorials/datanode.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('arg1', 'phrase'), ('arg2', 'phrase')]) is used.\n"
     ]
    }
   ],
   "source": [
    "from regr.graph import Graph, Concept, Relation\n",
    "from regr.graph.logicalConstrain import ifL, andL, nandL, V\n",
    "\n",
    "\n",
    "Graph.clear()\n",
    "Concept.clear()\n",
    "Relation.clear()\n",
    "\n",
    "with Graph('global') as graph:\n",
    "    with Graph('linguistic') as ling_graph:       \n",
    "        word = Concept(name='word')\n",
    "        phrase = Concept(name='phrase')\n",
    "        sentence = Concept(name='sentence')\n",
    "        (rel_sentence_contains_word,) = sentence.contains(word)\n",
    "        (rel_sentence_contains_phrase,) = sentence.contains(phrase)\n",
    "        (rel_phrase_contains_word,) = phrase.contains(word)\n",
    "\n",
    "        pair = Concept(name='pair')\n",
    "        (rel_pair_phrase1, rel_pair_phrase2) = pair.has_a(arg1=phrase, arg2=phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can use the graph structure as a background knowledge to introduce rules into the inference algorithms, you can specify the keyword *auto_constraint* to be **True** if you want us to generate automatic constraints based on the graph. You can disable the constraint generation for specific relationship definition by using the same keyword and making it equal to **False**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Graph('global') as graph:\n",
    "    with Graph('application', auto_constraint=True) as app_graph:\n",
    "        entity = phrase(name='entity')\n",
    "        people = entity(name='people', auto_constraint=True)\n",
    "        organization = entity(name='organization', auto_constraint=False)\n",
    "        location = entity(name='location', auto_constraint=None)\n",
    "        # auto_constraint->True due to its graph\n",
    "        other = entity(name='other')\n",
    "        o = entity(name='O')\n",
    "\n",
    "        work_for = pair(name='work_for')\n",
    "        \n",
    "        located_in = pair(name='located_in')\n",
    "        \n",
    "\n",
    "        live_in = pair(name='live_in')\n",
    "        # auto_constraint->True due to its graph\n",
    "\n",
    "        orgbase_on = pair(name='orgbase_on')\n",
    "        kill = pair(name='kill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **has_a** relationship is equivalant to having a many to many table structure between the arguments in the relation. So the *pair*, we are introducing a relationship between phrases. The **contains** relationship also implies a parent child structure which is a one-to-many relationship between the concept that contains the other one and the concept being contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Graph('global') as graph:\n",
    "    with Graph('application', auto_constraint=True) as app_graph:    \n",
    "        ifL(work_for, V(name='x'), andL(people, V(v=('x', rel_pair_phrase1.name)), organization, V(v=('x', rel_pair_phrase2.name))))\n",
    "#         work_for.has_a(people, organization, auto_constraint=True)\n",
    "\n",
    "#         ifL(located_in, V(name='x'), andL(location, V(v=('x', rel_pair_phrase1.name)), location, V(v=('x', rel_pair_phrase2.name))))\n",
    "        located_in.has_a(location, location, auto_constraint=True)\n",
    "        \n",
    "#         ifL(live_in, V(name='x'), andL(people, V(v=('x', rel_pair_phrase1.name)), location, V(v=('x', rel_pair_phrase2.name))))\n",
    "        live_in.has_a(people, location, auto_constraint=None)\n",
    "\n",
    "        #ifL(orgbase_on, ('x', 'y'), andL(organization, ('x',), location, ('y',)))\n",
    "        ifL(orgbase_on, V(name='x'), andL(organization, V(v=('x', rel_pair_phrase1.name)), location, V(v=('x', rel_pair_phrase2.name))))\n",
    "        \n",
    "        #ifL(kill, ('x', 'y'), andL(people, ('x',), people, ('y',)))\n",
    "        ifL(kill, V(name='x'), andL(people, V(v=('x', rel_pair_phrase1.name)), people, V(v=('x', rel_pair_phrase2.name))))\n",
    "        \n",
    "        nandL(people, organization, location, other, o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To introduce the domain range constraints for relationships, we can use either the **has_a** graph structure or directluy introduce a constraint by using our Constraint interface. Remember that if you use the **has_a** to introduce the rules for the domain and range of the arguments, you have to specify the auto_constraints to be *True*. If you put *auto_constraint=None* or do not add any *auto_constraint* input then the *auto_constraint* value will be inherited from the graph definition as all the nodes and relationships are defined inside the graph.\n",
    "\n",
    "The **nandL** constraint is also implying that the concept classes mentioned in the paranthesis are disjoint.\n",
    "\n",
    "For more information on how to write your own constraints, please refer to our constraint interface tutorials and documents!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Data Reader\n",
    "Here we use the Pytorch DataLoader to define our training and test instances. You can use your customized readers as long as the output for the reader class is an iterable object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from examples.conll04.conll.data.reader import Conll04CorpusReader\n",
    "\n",
    "class Conll04DataLoader(DataLoader):\n",
    "    def __init__(self, path, reader=None, **kwargs):\n",
    "        self.path = path\n",
    "        self.reader = reader or Conll04CorpusReader()\n",
    "        sentences_list, relations_list = self.reader(path)\n",
    "        samples = list(zip(sentences_list, relations_list))\n",
    "        super().__init__(samples, collate_fn=self._collate_fn, **kwargs)\n",
    "    \n",
    "    def _collate_fn(self, batch):\n",
    "        sentences, relations = zip(*batch)\n",
    "        # (tokens, pos, label)\n",
    "        # (relation_type, (src_index, src_token), (dst_index, dst_token))\n",
    "        tokens, postags, labels = zip(*sentences)\n",
    "        data_item = {\n",
    "            'sentence': [' '.join(token_list) for token_list in tokens],\n",
    "            'tokens': list(tokens),\n",
    "            'postag': list(postags),\n",
    "            'label': list(labels),\n",
    "            'relation': list(relations),\n",
    "        }\n",
    "        #import pdb; pdb.set_trace()\n",
    "        return data_item\n",
    "\n",
    "class SingletonDataLoader(Conll04DataLoader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, batch_size=1, **kwargs)\n",
    "\n",
    "    def _collate_fn(self, batch):\n",
    "        assert len(batch) == 1\n",
    "        sentences, relations = zip(*batch)\n",
    "        # (tokens, pos, label)\n",
    "        # (relation_type, (src_index, src_token), (dst_index, dst_token))\n",
    "        tokens, postags, labels = zip(*sentences)\n",
    "        data_item = {\n",
    "            #'sentence': [' '.join(token_list) for token_list in tokens],\n",
    "            'tokens': tokens[0],\n",
    "            'postag': postags[0],\n",
    "            'label': labels[0],\n",
    "            'relation': relations[0],\n",
    "        }\n",
    "        return data_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the output of the reader looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading Corpus:   0%|          | 0/114213 [00:00<?, ?it/s]\u001b[A\n",
      "Reading Corpus:  19%|█▊        | 21372/114213 [00:00<00:00, 213719.69it/s]\u001b[A\n",
      "Reading Corpus:  34%|███▍      | 39248/114213 [00:00<00:00, 201875.00it/s]\u001b[A\n",
      "Reading Corpus:  54%|█████▍    | 62017/114213 [00:00<00:00, 208980.67it/s]\u001b[A\n",
      "Reading Corpus:  74%|███████▍  | 84686/114213 [00:00<00:00, 213994.58it/s]\u001b[A\n",
      "Reading Corpus: 100%|██████████| 114213/114213 [00:00<00:00, 215766.85it/s]\u001b[A\n",
      "\n",
      "Reading Corpus:   0%|          | 0/28028 [00:00<?, ?it/s]\u001b[A\n",
      "Reading Corpus: 100%|██████████| 28028/28028 [00:00<00:00, 223191.67it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "train_reader = SingletonDataLoader('../examples/conll04/data/conll04.corp_1_train.corp')\n",
    "test_reader = SingletonDataLoader('../examples/conll04/data/conll04.corp_1_test.corp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['The', 'industry', 'group', 'said', 'methanol', 'would', 'be', 'the', 'most', 'likely', 'alternative', 'fuel', 'if', 'the', 'Bush', 'program', 'went', 'into', 'effect.'], 'postag': ['DT', 'NN', 'NN', 'VBD', 'NN', 'MD', 'VB', 'DT', 'RBS', 'JJ', 'JJ', 'NN', 'IN', 'DT', 'NNP', 'NN', 'VBD', 'IN', 'NN'], 'label': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'Peop', 'O', 'O', 'O', 'O'], 'relation': []}\n"
     ]
    }
   ],
   "source": [
    "print(list(iter(train_reader))[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined the keywords to be `tokens`, `postag`, `label`, `relation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Declaration\n",
    "\n",
    "In this section, we start by defining our sensors and required toolkits and then start connecting our sensors and learners to their right place in the graph.\n",
    "\n",
    "First, As we want to use `Spacy` to define the word features, we intialize a `Spacy` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# from spacy.lang.en import English\n",
    "nlp = spacy.load('en_core_web_sm') #English()\n",
    "\n",
    "FEATURE_DIM = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a classifier which we will use later in the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Classifier(torch.nn.Sequential):\n",
    "    def __init__(self, in_features) -> None:\n",
    "        linear = torch.nn.Linear(in_features, 2)\n",
    "        super().__init__(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we import a set of our predefined basic sensors which enables us to use the functionality of the DomiKnows declarative sensor and learner definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.sensor.pytorch.sensors import FunctionalSensor, JointSensor, ReaderSensor, FunctionalReaderSensor\n",
    "from regr.sensor.pytorch.learners import ModuleLearner\n",
    "from regr.sensor.pytorch.relation_sensors import CompositionCandidateSensor\n",
    "from regr.sensor.pytorch.query_sensor import DataNodeReaderSensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we start by Definign some **ReaderSensor**s to connect our DataLoader with appropriate properties in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase['text'] = ReaderSensor(keyword='tokens')\n",
    "phrase['postag'] = ReaderSensor(keyword='postag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the data about the Phrases, we also read the annotation of labels into the graph by using a customized **ReaderSensor** which we call **FunctionalReaderSensor**. In addition to having access to the DataLoader output, the **FunctionalReaderSensor** accepts a function as input at initialization which it will apply on the read data before generating the outputs. Remember to put `label=True` Whenever you are reading an annotation to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_label(label_type):\n",
    "    def find(data):\n",
    "        label = torch.tensor([item==label_type for item in data])\n",
    "        return label # torch.stack((~label, label), dim=1)\n",
    "    return find\n",
    "phrase[people] = FunctionalReaderSensor(keyword='label', forward=find_label('Peop'), label=True)\n",
    "phrase[organization] = FunctionalReaderSensor(keyword='label', forward=find_label('Org'), label=True)\n",
    "phrase[location] = FunctionalReaderSensor(keyword='label', forward=find_label('Loc'), label=True)\n",
    "phrase[other] = FunctionalReaderSensor(keyword='label', forward=find_label('Other'), label=True)\n",
    "phrase[o] = FunctionalReaderSensor(keyword='label', forward=find_label('O'), label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, We define a word to vector sensor using a **FunctionalSensor** to generate the word representation from their string utilizing the spacy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(text):\n",
    "    texts = list(map(lambda x: ' '.join(x.split('/')), text))\n",
    "    tokens_list = list(nlp.pipe(texts))\n",
    "    return torch.tensor([tokens.vector for tokens in tokens_list])\n",
    "\n",
    "phrase['w2v'] = FunctionalSensor('text', forward=word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as our data included the phrases directly, we want to merge phrases in the same sentence to create the concept nodes for `sentence`. To generate a concept from another one, we have to use the edges defined on the graph between those two concepts. Here we use the `contains` edge defined on the graph and as the default relationship was defined from a sentence to a phrase, here we use the keyword `reversed` after the relationship variable to indicate the reverse direction of the same relationship. \n",
    "\n",
    "Whenever, you want to define the connection, you have to return a matric connecting the nodes from the source to the target concept in a form of 0 and 1s. Apart from that we also want to generate the feature `Text` containing the actual string feature for a sentence in the same sensor, because of that, we use a **JointSensor** which is able to connect one sensor to multiple proprties on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_phrase(phrase_text):\n",
    "    return [' '.join(phrase_text)], torch.ones((1, len(phrase_text)))\n",
    "sentence['text', rel_sentence_contains_phrase.reversed] = JointSensor(phrase['text'], forward=merge_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a set of learners on top of the phrases to decide about each phrase class. In this scenario, we are assigning independent boolean classifers for each phrase type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase[people] = ModuleLearner('w2v', module=Classifier(FEATURE_DIM))\n",
    "phrase[organization] = ModuleLearner('w2v', module=Classifier(FEATURE_DIM))\n",
    "phrase[location] = ModuleLearner('w2v', module=Classifier(FEATURE_DIM))\n",
    "phrase[other] = ModuleLearner('w2v', module=Classifier(FEATURE_DIM))\n",
    "phrase[o] = ModuleLearner('w2v', module=Classifier(FEATURE_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the pair concept and use the **ComposionCandidateSensor** to generate pair candidates based on our phrases. This sensor receives one instance of each argument at a time and return **True** to make a candidate pair for that combination or **False** to skip the combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair[rel_pair_phrase1.reversed, rel_pair_phrase2.reversed] = CompositionCandidateSensor(\n",
    "    phrase['w2v'],\n",
    "    relations=(rel_pair_phrase1.reversed, rel_pair_phrase2.reversed),\n",
    "    forward=lambda *_, **__: True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a property `emb` for the pair candidates based on the representation of their arguments. We use the relation links defined on the previous sensor to retrieve the `w2v` properties on each argument and concat them in the `forward` function of the **FunctionalSensor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair['emb'] = FunctionalSensor(\n",
    "    rel_pair_phrase1.reversed('w2v'), rel_pair_phrase2.reversed('w2v'),\n",
    "    forward=lambda arg1, arg2: torch.cat((arg1, arg2), dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define our classifiers on top of the pair `emb` properties to decide about the type of each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair[work_for] = ModuleLearner('emb', module=Classifier(FEATURE_DIM*2))\n",
    "pair[located_in] = ModuleLearner('emb', module=Classifier(FEATURE_DIM*2))\n",
    "pair[live_in] = ModuleLearner('emb', module=Classifier(FEATURE_DIM*2))\n",
    "pair[orgbase_on] = ModuleLearner('emb', module=Classifier(FEATURE_DIM*2))\n",
    "pair[kill] = ModuleLearner('emb', module=Classifier(FEATURE_DIM*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we read the annotation of each pair from the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relation(relation_type):\n",
    "    def find(arg1m, arg2m, data):\n",
    "        label = torch.zeros(arg1m.shape[0], dtype=torch.bool)\n",
    "        for rel, (arg1,*_), (arg2,*_) in data:\n",
    "            if rel == relation_type:\n",
    "                i, = (arg1m[:, arg1] * arg2m[:, arg2]).nonzero(as_tuple=True)\n",
    "                label[i] = True\n",
    "        return label # torch.stack((~label, label), dim=1)\n",
    "    return find\n",
    "pair[work_for] = FunctionalReaderSensor(pair[rel_pair_phrase1.reversed], pair[rel_pair_phrase2.reversed], keyword='relation', forward=find_relation('Work_For'), label=True)\n",
    "pair[located_in] = FunctionalReaderSensor(pair[rel_pair_phrase1.reversed], pair[rel_pair_phrase2.reversed], keyword='relation', forward=find_relation('Located_In'), label=True)\n",
    "pair[live_in] = FunctionalReaderSensor(pair[rel_pair_phrase1.reversed], pair[rel_pair_phrase2.reversed], keyword='relation', forward=find_relation('Live_In'), label=True)\n",
    "pair[orgbase_on] = FunctionalReaderSensor(pair[rel_pair_phrase1.reversed], pair[rel_pair_phrase2.reversed], keyword='relation', forward=find_relation('OrgBased_In'), label=True)\n",
    "pair[kill] = FunctionalReaderSensor(pair[rel_pair_phrase1.reversed], pair[rel_pair_phrase2.reversed], keyword='relation', forward=find_relation('Kill'), label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After connecting all the sensors and learners to the graph, we have to define a Program instance to be able to autoamtically train and test our models. Here, we use the **POIProgram**, which execute all the properties which have multiple assignment in the graph~(multiple sensors connect) and their dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.program import POIProgram, IMLProgram\n",
    "from regr.program.metric import MacroAverageTracker, PRF1Tracker\n",
    "from regr.program.loss import NBCrossEntropyLoss, NBCrossEntropyIMLoss\n",
    "\n",
    "program = POIProgram(graph, poi=(phrase, sentence, pair), loss=MacroAverageTracker(NBCrossEntropyLoss()), metric=PRF1Tracker())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start training we can call the train method on the **POIProgram** instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:regr.program.program:Epoch: 0\n",
      "INFO:regr.program.program:Training:\n",
      "\n",
      "Epoch 0 Training:   0%|          | 0/4412 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during updating data item with sensor functionalreadersensor\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-20281a82b242>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprogram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_epoch_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/program/program.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_set, valid_set, test_set, device, train_epoch_num, Optim)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtraining_set\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Epoch {} Training'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' - loss:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/utils.py\u001b[0m in \u001b[0;36mconsume\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/program/program.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/program/model/pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data_item, build)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mdata_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"graph\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'READER'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mbuilder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataNodeBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;34m*\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mdatanode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetDataNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatanode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/program/model/pytorch.py\u001b[0m in \u001b[0;36mpopulate\u001b[0;34m(self, builder)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# make sure the sensors are evaluated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTorchSensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0msensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msensors\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_sensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOPULATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data_item)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_helper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error during updating data item with sensor {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36mupdate_context\u001b[0;34m(self, data_item, force, override)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_pre_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefine_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mdata_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36mforward_wrap\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConstantSensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConstantSensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# skip ConstantSensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwinputs)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwinputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwinputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-8b77abdbae95>\u001b[0m in \u001b[0;36mfind\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlabel_type\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;31m# torch.stack((~label, label), dim=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "program.train(train_reader, train_epoch_num=1, Optim=lambda param: torch.optim.SGD(param, lr=.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program.test(test_reader)\n",
    "\n",
    "reader = SingletonDataLoader('data/conll04.corp')\n",
    "\n",
    "for node in program.populate(reader, device='auto'):\n",
    "    assert node.ontologyNode is sentence\n",
    "    phrase_node = node.getChildDataNodes()[0]\n",
    "    assert phrase_node.ontologyNode is phrase\n",
    "\n",
    "    node.infer()\n",
    "\n",
    "    if phrase_node.getAttribute(people) is not None:\n",
    "        assert phrase_node.getAttribute(people, 'softmax') > 0\n",
    "        node.inferILPResults(fun=None)\n",
    "\n",
    "        ILPmetrics = node.getInferMetric()\n",
    "\n",
    "        print(\"ILP metrics Total %s\"%(ILPmetrics['Total']))\n",
    "\n",
    "        assert phrase_node.getAttribute(people, 'ILP') >= 0\n",
    "    else:\n",
    "        print(\"%s phrases have no values for attribute people\"%(node.getAttribute('text')))\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
