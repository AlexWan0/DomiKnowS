{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Spam detection\n",
    "This tutorial is to show you how to make a very simple learning program that also utilizes gorubi solver to apply constraints on a multiclass classification for two classes `spam` and `regular`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Users\\timlm\\Documents\\GitHub\\DomiKnowS\\tutorials\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "# Please change the root to an absolute or relative path to DomiKnowS root.\n",
    "# In case relative path is used, consider the printed `CWD` as current working directory.\n",
    "root = r'C:\\Users\\timlm\\Documents\\GitHub\\DomiKnowS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Graph\n",
    "First we define the graph code that defines the domain knowledge for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Log file for dataNode is in: c:\\Users\\timlm\\Documents\\GitHub\\DomiKnowS\\tutorials\\datanode.log\n",
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(root)\n",
    "\n",
    "from regr.graph import Graph, Concept # importing basic graph classes\n",
    "from regr.graph.logicalConstrain import orL, andL, notL # importing basic constraint classes\n",
    "\n",
    "Graph.clear()\n",
    "Concept.clear()\n",
    "\n",
    "with Graph('example') as graph:\n",
    "    email = Concept(name='email')\n",
    "\n",
    "    Spam = email(name='spam')\n",
    "\n",
    "    Regular = email(name='regular')\n",
    "\n",
    "    # The constraint of not having regular and spam together\n",
    "    orL(andL(notL(Spam, ('x', )), Regular, ('x', )), andL(notL(Regular, ('x', )), Spam, ('x', )))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Data Reader\n",
    "As our data is located in different text files and in different folders, we have to write a reader class that reads this entries into a list of dictionaries in python. Here we use the default Reader class of the Framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from regr.data.reader import RegrReader\n",
    "\n",
    "class EmailSpamReader(RegrReader):\n",
    "    def parse_file(self, ):\n",
    "        folder = self.file\n",
    "        data_spam = []\n",
    "        data_ham = []\n",
    "        for file in [f for f in os.listdir(folder + \"/spam\") if os.path.isfile(os.path.join(folder + \"/spam\", f)) and f.endswith('.txt')]:\n",
    "            with open(folder + \"/spam/\" + file, \"r\") as f:\n",
    "                x = []\n",
    "                for i in f:\n",
    "                    x.append(i)\n",
    "            data_spam.append(x)\n",
    "        for file in [f for f in os.listdir(folder + \"/ham\") if os.path.isfile(os.path.join(folder + \"/ham\", f)) and f.endswith('.txt')]:\n",
    "            with open(folder + \"/ham/\" + file, \"r\") as f:\n",
    "                x = []\n",
    "                for i in f:\n",
    "                    x.append(i)\n",
    "            data_ham.append(x)\n",
    "        final_data = []\n",
    "        for dat in data_spam:\n",
    "            item = {'subject': dat[0].split(\":\")[1]}\n",
    "            index = [i for i, v in enumerate(dat) if v.startswith('- - - - - - - - -')]\n",
    "            if len(index):\n",
    "                index = index[0]\n",
    "                item['body'] = \"\".join(dat[1:index])\n",
    "                sub = [(i, v) for i, v in enumerate(dat[index:]) if v.startswith('subject')][0]\n",
    "                item['forward_subject'] = sub[1].split(\":\")[1]\n",
    "                item['forward_body'] = \"\".join(dat[index + sub[0] + 1:])\n",
    "            else:\n",
    "                item['body'] = item['body'] = (\"\").join(dat[1:])\n",
    "            item['label'] = \"spam\"\n",
    "            final_data.append(item)\n",
    "\n",
    "        for dat in data_ham:\n",
    "            item = {'subject': dat[0].split(\":\")[1]}\n",
    "            index = [i for i, v in enumerate(dat) if v.startswith('- - - - - - - - -')]\n",
    "            if len(index):\n",
    "                index = index[0]\n",
    "                item['body'] = \"\".join(dat[1:index])\n",
    "                sub = [(i, v) for i, v in enumerate(dat[index:]) if v.startswith('subject')][0]\n",
    "                item['forward_subject'] = sub[1].split(\":\")[1]\n",
    "                item['forward_body'] = \"\".join(dat[index + sub[0] + 1:])\n",
    "            else:\n",
    "                item['body'] = item['body'] = (\"\").join(dat[1:])\n",
    "            item['label'] = \"ham\"\n",
    "            final_data.append(item)\n",
    "        return final_data\n",
    "\n",
    "    def getSubjectval(self, item):\n",
    "        return [item['subject']]\n",
    "\n",
    "    def getBodyval(self, item):\n",
    "        return [item['body']]\n",
    "\n",
    "    def getForwardSubjectval(self, item):\n",
    "        if 'forward_subject' in item:\n",
    "            return [item['forward_subject']]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def getForwardBodyval(self, item):\n",
    "        if 'forward_body' in item:\n",
    "            return [item['forward_body']]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def getSpamval(self, item):\n",
    "        if item['label'] == \"spam\":\n",
    "            return [1]\n",
    "        else:\n",
    "            return [0]\n",
    "\n",
    "    def getRegularval(self, item):\n",
    "        if item['label'] == \"ham\":\n",
    "            return [1]\n",
    "        else:\n",
    "            return [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class redefines the `parse_file` function to parse data into a list of dictionary and then defines some keywords to be used by `ReaderSensor` later in our program to connect data with our knowledge graph. Next we make an instance of this class on the training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_reader = EmailSpamReader(file=os.path.join(root, 'examples/Email_Spam/data/train'), type=\"folder\")\n",
    "test_reader = EmailSpamReader(file=os.path.join(root, 'examples/Email_Spam/data/test'), type=\"folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check your very first instance by calling `next` and your reader. \n",
    "! Make sure to re-initiate your reader if you do call `next` for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Body': [\"the lowest life insurance quotes\\nwithout the hassle !\\ncompare rates from the\\nnation ' s top insurance companies\\nshop ,\\ncompare and save\\nfill out the simple form ,\\nand you ' ll have the\\n15 best custom quotes in 1 minute .\\ncompare your current coverage\\nto these sample 10 - year level term monthly\\npremiums\\n( 20 year , 30 year and smoker rates also available )\\n$ 250 , 000\\n$ 500 , 000\\n$ 1 , 000 , 000\\nage\\nmale\\nfemale\\nmale\\nfemale\\nmale\\nfemale\\n30\\n$ 12\\n$ 11\\n$ 19\\n$ 15\\n$ 31\\n$ 27\\n40\\n$ 15\\n$ 13\\n$ 26\\n$ 21\\n$ 38\\n$ 37\\n50\\n$ 32\\n$ 24\\n$ 59\\n$ 43\\n$ 107\\n$ 78\\n60\\n$ 75\\n$ 46\\n$ 134\\n$ 87\\n$ 259\\n$ 161\\nclick here to compare !\\nit ' s fast , easy and free !\\n* all quotes shown are from insurance companies rated a - , a , a + or a + + by\\na . m . best company ( a registered rating service ) and include all fees and commissions .\\nactual premiums and coverage availability will vary depending upon age , sex , state\\navailability , health history and recent tobacco usage .\\nto unsubscribe , reply with unsubscribe in subject !\\n\"], 'ForwardBody': None, 'ForwardSubject': None, 'Regular': [0], 'Spam': [1], 'Subject': [' double your life insurance at no extra cost ! 29155\\n']}\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_reader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Declaration\n",
    "Now we start to connect the reader output data with our formatted domain knowledge defined in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.sensor.pytorch.sensors import ReaderSensor\n",
    "\n",
    "email['subject'] = ReaderSensor(keyword='Subject')\n",
    "email['body'] = ReaderSensor(keyword=\"Body\")\n",
    "email['forward_subject'] = ReaderSensor(keyword=\"ForwardSubject\")\n",
    "email['forward_body'] = ReaderSensor(keyword=\"ForwardBody\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we read the labels for the `spam` and `regular` concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "email[Spam] = ReaderSensor(keyword='Spam', label=True)\n",
    "email[Regular] = ReaderSensor(keyword='Regular', label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a new sensor\n",
    "Here we want to use spacy to define a new sensor which gives us an average glove embedding tensor for a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.sensor.pytorch.sensors import FunctionalSensor\n",
    "import spacy\n",
    "from typing import Any\n",
    "import torch\n",
    "\n",
    "class SentenceRepSensor(FunctionalSensor):\n",
    "    def __init__(self, *pres, edges=None, label=False):\n",
    "        super().__init__(*pres, edges=None, label=False)\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    def forward(self, text) -> Any:\n",
    "        email = list(self.nlp.pipe(text))\n",
    "        return torch.tensor([it.vector for it in email], device=self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to this sensor would be a sentence. You can find the usage of this sensor in the following sections.\n",
    "\n",
    "Next, we want to define a new sensor which gives us a tensor indicating whether the email has a forwarded message or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardPresenceSensor(FunctionalSensor):\n",
    "    def forward(self, forward_body) -> Any:\n",
    "        if forward_body:\n",
    "            return torch.ones(1,1).to(self.device)\n",
    "        else:\n",
    "            return torch.zeros(1,1).to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting new sensors to the graph \n",
    "We connect these sensors to the graph to make new properties on the concept `email`. We want to make new representations on the `subject` and `body` of the email and that why those properties are passed as input to the defined sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "email['subject_rep'] = SentenceRepSensor('subject')\n",
    "email['body_rep'] = SentenceRepSensor('body')\n",
    "email['forward_presence'] = ForwardPresenceSensor('forward_body')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing input features for the learner\n",
    "Now we concatenate all the generated features to make a new property on the graph which will provide input for the classifier of `spam` and `regular` concepts.\n",
    "We can use the `FunctionalSensor` and assign the concatination functionality to the `forward` parameter when initializing an instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(*x): \n",
    "    return torch.cat(x, dim=-1)\n",
    "email['features'] = FunctionalSensor('subject_rep', 'body_rep', 'forward_presence', forward=concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the learner\n",
    "Here we define a learner and connect it to the concepts of `spam` and `regular`. This learner is a simple pytorch module of linear neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.sensor.pytorch.learners import ModuleLearner\n",
    "from torch import nn\n",
    "\n",
    "email[Spam] = ModuleLearner('features', module=nn.Linear(193, 2))\n",
    "email[Regular] = ModuleLearner('features', module=nn.Linear(193, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the learning model from the updated graph\n",
    "Here we make an executable version of this graph that is able to trace the dependencies of the sensors and fill the data from the reader to run examples on the declared model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.program import LearningBasedProgram\n",
    "from regr.program.model.pytorch import PoiModel\n",
    "from regr.program.metric import MacroAverageTracker, PRF1Tracker\n",
    "from regr.program.loss import NBCrossEntropyLoss\n",
    "\n",
    "program = LearningBasedProgram(graph, PoiModel, loss=MacroAverageTracker(NBCrossEntropyLoss()), metric=PRF1Tracker())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the level of logging from the program using the following setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set logger level to see training and testing logs\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute The program to train\n",
    "We can use the `train` method to start training the model based on defined loss. We can specify the number of training epochs, the dataset and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:regr.program.program:Epoch: 0\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 0 Training: 100%|██████████| 10/10 [00:00<00:00, 10.84it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'spam': tensor(0.7192), 'regular': tensor(0.6869)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'spam': {'P': tensor(0.4667), 'R': tensor(0.7000), 'F1': tensor(0.5600)}, 'regular': {'P': tensor(0.6667), 'R': tensor(0.6000), 'F1': tensor(0.6316)}}\n",
      "INFO:regr.program.program:Epoch: 1\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 1 Training: 100%|██████████| 10/10 [00:00<00:00, 15.49it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'spam': tensor(0.6136), 'regular': tensor(0.5849)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'spam': {'P': tensor(0.6154), 'R': tensor(0.8000), 'F1': tensor(0.6957)}, 'regular': {'P': tensor(0.7500), 'R': tensor(0.9000), 'F1': tensor(0.8182)}}\n",
      "INFO:regr.program.program:Epoch: 2\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 2 Training: 100%|██████████| 10/10 [00:00<00:00, 12.67it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'spam': tensor(0.5517), 'regular': tensor(0.5256)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'spam': {'P': tensor(0.8182), 'R': tensor(0.9000), 'F1': tensor(0.8571)}, 'regular': {'P': tensor(0.7500), 'R': tensor(0.9000), 'F1': tensor(0.8182)}}\n",
      "INFO:regr.program.program:Epoch: 3\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 3 Training: 100%|██████████| 10/10 [00:00<00:00, 18.19it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'spam': tensor(0.5035), 'regular': tensor(0.4796)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'spam': {'P': tensor(0.8182), 'R': tensor(0.9000), 'F1': tensor(0.8571)}, 'regular': {'P': tensor(0.7500), 'R': tensor(0.9000), 'F1': tensor(0.8182)}}\n",
      "INFO:regr.program.program:Epoch: 4\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 4 Training: 100%|██████████| 10/10 [00:00<00:00, 19.51it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'spam': tensor(0.4644), 'regular': tensor(0.4424)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'spam': {'P': tensor(0.8182), 'R': tensor(0.9000), 'F1': tensor(0.8571)}, 'regular': {'P': tensor(0.9091), 'R': tensor(1.), 'F1': tensor(0.9524)}}\n",
      "INFO:regr.program.program:Epoch: 5\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 5 Training: 100%|██████████| 10/10 [00:00<00:00, 16.83it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'spam': tensor(0.4313), 'regular': tensor(0.4109)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'spam': {'P': tensor(0.8182), 'R': tensor(0.9000), 'F1': tensor(0.8571)}, 'regular': {'P': tensor(0.9091), 'R': tensor(1.), 'F1': tensor(0.9524)}}\n",
      "INFO:regr.program.program:Epoch: 6\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 6 Training: 100%|██████████| 10/10 [00:00<00:00, 18.58it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'spam': tensor(0.4025), 'regular': tensor(0.3835)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'spam': {'P': tensor(0.9000), 'R': tensor(0.9000), 'F1': tensor(0.9000)}, 'regular': {'P': tensor(0.9091), 'R': tensor(1.), 'F1': tensor(0.9524)}}\n",
      "INFO:regr.program.program:Epoch: 7\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 7 Training: 100%|██████████| 10/10 [00:00<00:00, 20.46it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'spam': tensor(0.3769), 'regular': tensor(0.3591)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'spam': {'P': tensor(0.9000), 'R': tensor(0.9000), 'F1': tensor(0.9000)}, 'regular': {'P': tensor(0.9091), 'R': tensor(1.), 'F1': tensor(0.9524)}}\n",
      "INFO:regr.program.program:Epoch: 8\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 8 Training: 100%|██████████| 10/10 [00:00<00:00, 19.77it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'spam': tensor(0.3538), 'regular': tensor(0.3372)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'spam': {'P': tensor(1.), 'R': tensor(0.9000), 'F1': tensor(0.9474)}, 'regular': {'P': tensor(0.9091), 'R': tensor(1.), 'F1': tensor(0.9524)}}\n",
      "INFO:regr.program.program:Epoch: 9\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 9 Training: 100%|██████████| 10/10 [00:00<00:00, 16.79it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'spam': tensor(0.3330), 'regular': tensor(0.3174)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'spam': {'P': tensor(1.), 'R': tensor(0.9000), 'F1': tensor(0.9474)}, 'regular': {'P': tensor(0.9091), 'R': tensor(1.), 'F1': tensor(0.9524)}}\n"
     ]
    }
   ],
   "source": [
    "program.train(train_reader, train_epoch_num=10, Optim=torch.optim.Adam, device='auto')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the performance on any dataset with the trained model, we should call `test` on the program and pass the dataset instance to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:regr.program.program:Testing:\n",
      "Testing: 100%|██████████| 10/10 [00:00<00:00, 11.96it/s]\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'spam': tensor(0.6098), 'regular': tensor(0.6298)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program:{'spam': {'P': tensor(0.5455), 'R': tensor(0.6000), 'F1': tensor(0.5714)}, 'regular': {'P': tensor(0.5000), 'R': tensor(0.6000), 'F1': tensor(0.5455)}}\n"
     ]
    }
   ],
   "source": [
    "program.test(test_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the graph\n",
    "Here we use populate to run the graph with the defined data from the reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "email 0\n",
      "email 0\n",
      "email 0\n",
      "email 0\n",
      "email 0\n",
      "email 0\n",
      "email 0\n",
      "email 0\n",
      "email 0\n",
      "email 0\n"
     ]
    }
   ],
   "source": [
    "for datanode in program.populate(dataset=train_reader):\n",
    "    print(datanode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "datanode: email 0\n",
      "Spam: tensor([0.5562, 0.4438])\n",
      "Regular: tensor([0.4286, 0.5714])\n",
      "Log file for ilpOntSolver is in: c:\\Users\\timlm\\Documents\\GitHub\\DomiKnowS\\tutorials\\ilpOntSolver.log\n",
      "Academic license - for non-commercial use only - expires 2021-04-13\n",
      "C:\\Users\\timlm\\Documents\\GitHub\\DomiKnowS\\regr\\solver\\gurobiILPBooleanMethods.py:61: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "  if self.ifLog: self.myLogger.debug(\"%s constrain already created - doing nothing\"(logicMethodName))\n",
      "INFO:gurobipy.gurobipy:Academic license - for non-commercial use only - expires 2021-04-13\n",
      "Using license file C:\\Users\\timlm\\gurobi.lic\n",
      "INFO:gurobipy.gurobipy:Using license file C:\\Users\\timlm\\gurobi.lic\n",
      "inference spam: tensor([0.], dtype=torch.float64)\n",
      "inference regular: tensor([1.], dtype=torch.float64)\n",
      "datanode: email 0\n",
      "Spam: tensor([0.2690, 0.7310])\n",
      "Regular: tensor([0.6692, 0.3308])\n",
      "inference spam: tensor([1.], dtype=torch.float64)\n",
      "inference regular: tensor([0.], dtype=torch.float64)\n",
      "datanode: email 0\n",
      "Spam: tensor([0.3849, 0.6151])\n",
      "Regular: tensor([0.6318, 0.3682])\n",
      "inference spam: tensor([1.], dtype=torch.float64)\n",
      "inference regular: tensor([0.], dtype=torch.float64)\n",
      "datanode: email 0\n",
      "Spam: tensor([0.5146, 0.4854])\n",
      "Regular: tensor([0.5120, 0.4880])\n",
      "inference spam: tensor([0.], dtype=torch.float64)\n",
      "inference regular: tensor([1.], dtype=torch.float64)\n",
      "datanode: email 0\n",
      "Spam: tensor([0.5434, 0.4566])\n",
      "Regular: tensor([0.4380, 0.5620])\n",
      "inference spam: tensor([0.], dtype=torch.float64)\n",
      "inference regular: tensor([1.], dtype=torch.float64)\n",
      "datanode: email 0\n",
      "Spam: tensor([0.4019, 0.5981])\n",
      "Regular: tensor([0.5339, 0.4661])\n",
      "inference spam: tensor([1.], dtype=torch.float64)\n",
      "inference regular: tensor([0.], dtype=torch.float64)\n",
      "datanode: email 0\n",
      "Spam: tensor([0.6365, 0.3635])\n",
      "Regular: tensor([0.4346, 0.5654])\n",
      "inference spam: tensor([0.], dtype=torch.float64)\n",
      "inference regular: tensor([1.], dtype=torch.float64)\n",
      "datanode: email 0\n",
      "Spam: tensor([0.4648, 0.5352])\n",
      "Regular: tensor([0.5066, 0.4934])\n",
      "inference spam: tensor([1.], dtype=torch.float64)\n",
      "inference regular: tensor([0.], dtype=torch.float64)\n",
      "datanode: email 0\n",
      "Spam: tensor([0.6933, 0.3067])\n",
      "Regular: tensor([0.3547, 0.6453])\n",
      "inference spam: tensor([0.], dtype=torch.float64)\n",
      "inference regular: tensor([1.], dtype=torch.float64)\n",
      "datanode: email 0\n",
      "Spam: tensor([0.6166, 0.3834])\n",
      "Regular: tensor([0.4603, 0.5397])\n",
      "inference spam: tensor([0.], dtype=torch.float64)\n",
      "inference regular: tensor([1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for datanode in program.populate(dataset=test_reader):\n",
    "    print('datanode:', datanode)\n",
    "    print('Spam:', datanode.getAttribute(Spam).softmax(-1))\n",
    "    print('Regular:', datanode.getAttribute(Regular).softmax(-1))\n",
    "    datanode.inferILPConstrains(fun=lambda val: torch.tensor(val).softmax(dim=-1).detach().cpu().numpy().tolist(), epsilon=None)\n",
    "    print('inference spam:', datanode.getAttribute(Spam, 'ILP'))\n",
    "    print('inference regular:', datanode.getAttribute(Regular, 'ILP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Graph.pdf'"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "from graphviz import Graph\n",
    "#for datanode in program.populate(dataset=test_reader):\n",
    "dot = Graph()\n",
    "dot.node('Email', str(datanode))\n",
    "dot.attr('node', shape = 'square') \n",
    "dot.node('Spam', 'Spam: '+str(datanode.getAttribute('subject')[0]))\n",
    "dot.node('Regular', 'Regular: '+str(datanode.getAttribute(Regular).softmax(-1)))\n",
    "dot.edge('Email', 'Spam', constraint = 'false')\n",
    "dot.edge('Email', 'Regular', constraing = 'false')\n",
    "dot.render('Graph', view = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "9325eec6905a088ba82da474100e49935bac0b345bf7f41978729eb35abfe505"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}