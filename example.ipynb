{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! find . -name \"*.pyc\" -exec rm -f {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.graph import Graph\n",
    "from regr.entity import Entity\n",
    "from regr.relation import Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(name='global', what={'entities': [],\n",
       " 'subgraphs': [Graph(name='linguistic', what={'entities': [Entity(name='word', what={'rels': {}}),\n",
       "              Entity(name='phrase', what={'rels': {Entity(name='word'): set([Have(name='have', what={'dst': Entity(name='word'),\n",
       " 'src': Entity(name='phrase')})])}}),\n",
       "              Entity(name='sentence', what={'rels': {Entity(name='phrase'): set([Have(name='have-1', what={'dst': Entity(name='phrase'),\n",
       " 'src': Entity(name='sentence')})])}})],\n",
       " 'subgraphs': [],\n",
       " 'supergraph': Graph(name='global')}),\n",
       "               Graph(name='application', what={'entities': [Entity(name='entity', what={'rels': {Entity(name='phrase'): set([Be(name='be', what={'dst': Entity(name='phrase'),\n",
       " 'src': Entity(name='entity')})])}}),\n",
       "              Entity(name='pair', what={'rels': {Entity(name='entity'): set([Be(name='be-1', what={'dst': (Entity(name='entity'),\n",
       "         Entity(name='entity')),\n",
       " 'src': Entity(name='pair')})])}}),\n",
       "              Entity(name='people', what={'rels': {Entity(name='entity'): set([Be(name='be-2', what={'dst': Entity(name='entity'),\n",
       " 'src': Entity(name='people')})])}}),\n",
       "              Entity(name='organization', what={'rels': {Entity(name='entity'): set([Be(name='be-3', what={'dst': Entity(name='entity'),\n",
       " 'src': Entity(name='organization')})])}}),\n",
       "              Entity(name='other', what={'rels': {Entity(name='entity'): set([Be(name='be-4', what={'dst': Entity(name='entity'),\n",
       " 'src': Entity(name='other')})])}}),\n",
       "              Entity(name='work-for', what={'rels': {Entity(name='pair'): set([Be(name='be-6', what={'dst': Entity(name='pair'),\n",
       " 'src': Entity(name='work-for')})]),\n",
       "          Entity(name='organization'): set([Be(name='be-5', what={'dst': {'employee': Entity(name='people'),\n",
       "         'employer': Entity(name='organization')},\n",
       " 'src': Entity(name='work-for')})]),\n",
       "          Entity(name='people'): set([Be(name='be-5', what={'dst': {'employee': Entity(name='people'),\n",
       "         'employer': Entity(name='organization')},\n",
       " 'src': Entity(name='work-for')})])}})],\n",
       " 'subgraphs': [],\n",
       " 'supergraph': Graph(name='global')})],\n",
       " 'supergraph': None})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Graph('global') as graph:\n",
    "    with Graph('linguistic') as ling_graph:\n",
    "        # linguistic layer\n",
    "        word = Entity(name='word')\n",
    "        phrase = Entity(name='phrase')\n",
    "        sentence = Entity(name='sentence')\n",
    "        phrase.have(word)\n",
    "        sentence.have(phrase)\n",
    "\n",
    "    with Graph('application') as app_graph:\n",
    "        # application nodes\n",
    "        entity = Entity(name='entity')\n",
    "        entity.be(phrase)\n",
    "        pair = Entity(name='pair')\n",
    "        pair.be((entity, entity))\n",
    "\n",
    "        people = Entity(name='people')\n",
    "        organization = Entity(name='organization')\n",
    "        other = Entity(name='other')\n",
    "        people.be(entity)\n",
    "        organization.be(entity)\n",
    "        other.be(entity)\n",
    "\n",
    "        work_for = Entity(name='work-for')\n",
    "        work_for.be({'employee':people, 'employer':organization})\n",
    "        work_for.be(pair)\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'linguistic': 1, 'global': 1, 'application': 1})\n",
      "Counter({'word': 1, 'people': 1, 'sentence': 1, 'work-for': 1, 'entity': 1, 'other': 1, 'organization': 1, 'pair': 1, 'phrase': 1})\n",
      "Counter({'be': 7, 'have': 2, 'have-1': 1, 'be-1': 1, 'be-2': 1, 'be-3': 1, 'be-4': 1, 'be-5': 1, 'be-6': 1})\n"
     ]
    }
   ],
   "source": [
    "print Graph._names\n",
    "print Entity._names\n",
    "print Relation._names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_len: (2,), int64\n",
      "mask: (2, 10), bool\n",
      "bword: (2, 10), float64\n",
      "rword: (2, 10, 16), float64\n",
      "tokenizor: (2, 5, 10), bool\n",
      "phrase_mask: (2, 5), bool\n",
      "sentence_rel: (2, 5), bool\n",
      "entity_pred: (2, 5), bool\n",
      "entity_clas: (2, 5, 3), float64\n",
      "relation_mask: (2, 5, 5), bool\n",
      "relation_clas: (2, 5, 5, 2), float64\n"
     ]
    }
   ],
   "source": [
    "# pytorch something\n",
    "# numpy for example\n",
    "\n",
    "import numpy as np\n",
    "from regr.utils import extract_args\n",
    "\n",
    "\n",
    "def np_debug(mat, show_value=False):\n",
    "    args = extract_args(_stack_back_level_=1)\n",
    "    for k, v in args.items():\n",
    "        v = np.array(v)\n",
    "        print('{}: {}, {}'.format(k, v.shape, v.dtype))\n",
    "        if show_value:\n",
    "            print(v)\n",
    "\n",
    "\n",
    "def mask_expand(mask_len, max_len):\n",
    "    mask_len = np.array(mask_len)\n",
    "    expanded = np.tile(np.expand_dims(\n",
    "        np.arange(max_len), axis=0), mask_len.shape + (1,))\n",
    "    return expanded < np.expand_dims(mask_len, axis=-1)\n",
    "\n",
    "\n",
    "def softmax(x): return np.exp(x) / np.exp(x).sum(axis=-1, keepdims=True)\n",
    "\n",
    "\n",
    "# config and data\n",
    "batch_size = 2\n",
    "max_len = 10\n",
    "max_phrase = 5\n",
    "mask_len = np.random.randint(max_len / 4, max_len, size=batch_size)\n",
    "np_debug(mask_len)\n",
    "repr_size = 16\n",
    "\n",
    "entity_types = 3\n",
    "relation_types = 2\n",
    "\n",
    "mask = mask_expand(mask_len, max_len)\n",
    "np_debug(mask)  # (batch, word,)\n",
    "\n",
    "# belief layer\n",
    "bword = np.ones((batch_size, max_len)) * mask\n",
    "np_debug(bword)  # (batch, word,)\n",
    "# embedding layer\n",
    "rword = np.random.random((batch_size, max_len, repr_size)) * \\\n",
    "    np.expand_dims(mask, axis=-1)  # (batch, batch, repr)\n",
    "np_debug(rword)\n",
    "\n",
    "# links\n",
    "# phrase -.-> word\n",
    "tokenizor = np.random.random(\n",
    "    (batch_size, max_phrase, max_len)) * np.expand_dims(mask, axis=1)\n",
    "tokenizor = (tokenizor == tokenizor.max(axis=1, keepdims=True)\n",
    "             ) & np.expand_dims(mask, axis=1)\n",
    "np_debug(tokenizor)  # (batch, prhase, word,)\n",
    "\n",
    "phrase_mask = tokenizor.sum(axis=-1).astype(np.bool)\n",
    "np_debug(phrase_mask)  # (batch, prhase,)\n",
    "\n",
    "# sentence -.-> phrase\n",
    "sentence_rel = np.ones((batch_size, max_phrase), dtype=np.bool) * phrase_mask\n",
    "np_debug(sentence_rel)  # (batch, prhase,)\n",
    "\n",
    "# entity ---> phrase\n",
    "entity_pred = np.random.choice(\n",
    "    [False, True], (batch_size, max_phrase)) * phrase_mask\n",
    "np_debug(entity_pred)  # (batch, prhase,)\n",
    "\n",
    "# people|organization|other ---> entity\n",
    "entity_clas = np.random.randn(batch_size, max_phrase, entity_types)\n",
    "entity_clas = softmax(entity_clas) * np.expand_dims(phrase_mask, axis=-1)\n",
    "np_debug(entity_clas)  # (batch, prhase, entity_type,)\n",
    "\n",
    "relation_mask = np.matmul(np.expand_dims(\n",
    "    phrase_mask, axis=2), np.expand_dims(phrase_mask, axis=1))\n",
    "np_debug(relation_mask)  # (batch, prhase, prhase,)\n",
    "\n",
    "# work_for ---> pair\n",
    "relation_clas = np.random.randn(\n",
    "    batch_size, max_phrase, max_phrase, relation_types)\n",
    "relation_clas = softmax(relation_clas) * np.expand_dims(relation_mask, axis=-1)\n",
    "np_debug(relation_clas)  # (batch, prhase, prhase, relation_type,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-295b17354f03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'belief'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/root/workspace/repos/pyregr/regr/entity.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, prop, value)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     '''\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "word['belief'] = bword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
