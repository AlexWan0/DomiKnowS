{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! find . -name \"*.pyc\" -exec rm -f {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr import Graph, Concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, {'employee': Concept(name='people', what={'rels': {Concept(name='entity'): set([Be(name='(people)-be-(0:entity)', what={'dst': OrderedDict([(0, Concept(name='entity'))]),\n",
      " 'src': Concept(name='people')})])}}), 'employer': Concept(name='organization', what={'rels': {Concept(name='entity'): set([Be(name='(organization)-be-(0:entity)', what={'dst': OrderedDict([(0, Concept(name='entity'))]),\n",
      " 'src': Concept(name='organization')})])}})} is used.\n",
      "regr/relation.py:13: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, {'employee': Concept(name='people', what={'rels': {Concept(name='entity'): set([Be(name='(people)-be-(0:entity)', what={'dst': OrderedDict([(0, Concept(name='entity'))]),\n",
      " 'src': Concept(name='people')})])}}), 'employer': Concept(name='organization', what={'rels': {Concept(name='entity'): set([Be(name='(organization)-be-(0:entity)', what={'dst': OrderedDict([(0, Concept(name='entity'))]),\n",
      " 'src': Concept(name='organization')})])}})} is used.\n",
      "  self.dst = dst\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graph(name='global', what={'concepts': [],\n",
       " 'subgraphs': [Graph(name='linguistic', what={'concepts': [Concept(name='word', what={'rels': {}}),\n",
       "              Concept(name='phrase', what={'rels': {Concept(name='word'): set([Have(name='(phrase)-have-(0:word)', what={'dst': OrderedDict([(0, Concept(name='word'))]),\n",
       " 'src': Concept(name='phrase')})])}}),\n",
       "              Concept(name='sentence', what={'rels': {Concept(name='phrase'): set([Have(name='(sentence)-have-(0:phrase)', what={'dst': OrderedDict([(0, Concept(name='phrase'))]),\n",
       " 'src': Concept(name='sentence')})])}})],\n",
       " 'subgraphs': [],\n",
       " 'supergraph': Graph(name='global')}),\n",
       "               Graph(name='application', what={'concepts': [Concept(name='entity', what={'rels': {Concept(name='phrase'): set([Be(name='(entity)-be-(0:phrase)', what={'dst': OrderedDict([(0, Concept(name='phrase'))]),\n",
       " 'src': Concept(name='entity')})])}}),\n",
       "              Concept(name='pair', what={'rels': {Concept(name='entity'): set([Be(name='(pair)-be-(0:entity,1:entity)', what={'dst': OrderedDict([(0, Concept(name='entity')), (1, Concept(name='entity'))]),\n",
       " 'src': Concept(name='pair')})])}}),\n",
       "              Concept(name='people', what={'rels': {Concept(name='entity'): set([Be(name='(people)-be-(0:entity)', what={'dst': OrderedDict([(0, Concept(name='entity'))]),\n",
       " 'src': Concept(name='people')})])}}),\n",
       "              Concept(name='organization', what={'rels': {Concept(name='entity'): set([Be(name='(organization)-be-(0:entity)', what={'dst': OrderedDict([(0, Concept(name='entity'))]),\n",
       " 'src': Concept(name='organization')})])}}),\n",
       "              Concept(name='other', what={'rels': {Concept(name='entity'): set([Be(name='(other)-be-(0:entity)', what={'dst': OrderedDict([(0, Concept(name='entity'))]),\n",
       " 'src': Concept(name='other')})])}}),\n",
       "              Concept(name='work-for', what={'rels': {Concept(name='pair'): set([Be(name='(work-for)-be-(0:pair)', what={'dst': OrderedDict([(0, Concept(name='pair'))]),\n",
       " 'src': Concept(name='work-for')})]),\n",
       "          Concept(name='people'): set([Be(name='(work-for)-be-(employee:people,employer:organization)', what={'dst': OrderedDict([('employee', Concept(name='people')), ('employer', Concept(name='organization'))]),\n",
       " 'src': Concept(name='work-for')})]),\n",
       "          Concept(name='organization'): set([Be(name='(work-for)-be-(employee:people,employer:organization)', what={'dst': OrderedDict([('employee', Concept(name='people')), ('employer', Concept(name='organization'))]),\n",
       " 'src': Concept(name='work-for')})])}})],\n",
       " 'subgraphs': [],\n",
       " 'supergraph': Graph(name='global')})],\n",
       " 'supergraph': None})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Graph('global') as graph:\n",
    "    with Graph('linguistic') as ling_graph:\n",
    "        # linguistic layer\n",
    "        word = Concept(name='word')\n",
    "        phrase = Concept(name='phrase')\n",
    "        sentence = Concept(name='sentence')\n",
    "        phrase.have(word)\n",
    "        sentence.have(phrase)\n",
    "\n",
    "    with Graph('application') as app_graph:\n",
    "        # application nodes\n",
    "        entity = Concept(name='entity')\n",
    "        entity.be(phrase)\n",
    "        pair = Concept(name='pair')\n",
    "        pair.be((entity, entity))\n",
    "\n",
    "        people = Concept(name='people')\n",
    "        organization = Concept(name='organization')\n",
    "        other = Concept(name='other')\n",
    "        people.be(entity)\n",
    "        organization.be(entity)\n",
    "        other.be(entity)\n",
    "\n",
    "        work_for = Concept(name='work-for')\n",
    "        work_for.be({'employee':people, 'employer':organization})\n",
    "        work_for.be(pair)\n",
    "\n",
    "graph\n",
    "\n",
    "# some other sample of planed graph API, hopefully make sense towards turing completeness\n",
    "#\n",
    "# two.be((people, people))\n",
    "# colleague.be(two)\n",
    "# friend.be(two)\n",
    "# meet.be(two)\n",
    "# beer.be(two)\n",
    "# argue.be(two)\n",
    "# (colleague or friend).be(meet)\n",
    "# (colleague and friend).be(beer)\n",
    "# (colleague and not friend).be(argue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'linguistic': 1, 'global': 1, 'application': 1})\n",
      "Counter({'word': 1, 'people': 1, 'sentence': 1, 'work-for': 1, 'entity': 1, 'other': 1, 'organization': 1, 'pair': 1, 'phrase': 1})\n"
     ]
    }
   ],
   "source": [
    "print Graph._names\n",
    "print Concept._names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_len: (2,), int64\n",
      "mask: (2, 10), bool\n",
      "bword: (2, 10), float64\n",
      "rword: (2, 10, 16), float64\n",
      "tokenizor: (2, 5, 10), bool\n",
      "phrase_mask: (2, 5), bool\n",
      "sentence_rel: (2, 5), bool\n",
      "entity_pred: (2, 5), bool\n",
      "entity_clas: (2, 5, 3), float64\n",
      "relation_mask: (2, 5, 5), bool\n",
      "relation_clas: (2, 5, 5, 2), float64\n"
     ]
    }
   ],
   "source": [
    "# pytorch something\n",
    "# numpy for example\n",
    "\n",
    "import numpy as np\n",
    "from regr.utils import extract_args\n",
    "\n",
    "\n",
    "def np_debug(mat, show_value=False):\n",
    "    args = extract_args(_stack_back_level_=1)\n",
    "    for k, v in args.items():\n",
    "        v = np.array(v)\n",
    "        print('{}: {}, {}'.format(k, v.shape, v.dtype))\n",
    "        if show_value:\n",
    "            print(v)\n",
    "\n",
    "\n",
    "def mask_expand(mask_len, max_len):\n",
    "    mask_len = np.array(mask_len)\n",
    "    expanded = np.tile(np.expand_dims(\n",
    "        np.arange(max_len), axis=0), mask_len.shape + (1,))\n",
    "    return expanded < np.expand_dims(mask_len, axis=-1)\n",
    "\n",
    "\n",
    "def softmax(x): return np.exp(x) / np.exp(x).sum(axis=-1, keepdims=True)\n",
    "\n",
    "\n",
    "# config and data\n",
    "batch_size = 2\n",
    "max_len = 10\n",
    "max_phrase = 5\n",
    "mask_len = np.random.randint(max_len / 4, max_len, size=batch_size)\n",
    "np_debug(mask_len)\n",
    "repr_size = 16\n",
    "\n",
    "entity_types = 3\n",
    "relation_types = 2\n",
    "\n",
    "mask = mask_expand(mask_len, max_len)\n",
    "np_debug(mask)  # (batch, word,)\n",
    "\n",
    "# belief layer\n",
    "bword = np.ones((batch_size, max_len)) * mask\n",
    "np_debug(bword)  # (batch, word,)\n",
    "# embedding layer\n",
    "rword = np.random.random((batch_size, max_len, repr_size)) * \\\n",
    "    np.expand_dims(mask, axis=-1)  # (batch, batch, repr)\n",
    "np_debug(rword)\n",
    "\n",
    "# links\n",
    "# phrase -.-> word\n",
    "tokenizor = np.random.random(\n",
    "    (batch_size, max_phrase, max_len)) * np.expand_dims(mask, axis=1)\n",
    "tokenizor = (tokenizor == tokenizor.max(axis=1, keepdims=True)\n",
    "             ) & np.expand_dims(mask, axis=1)\n",
    "np_debug(tokenizor)  # (batch, prhase, word,)\n",
    "\n",
    "phrase_mask = tokenizor.sum(axis=-1).astype(np.bool)\n",
    "np_debug(phrase_mask)  # (batch, prhase,)\n",
    "\n",
    "# sentence -.-> phrase\n",
    "sentence_rel = np.ones((batch_size, max_phrase), dtype=np.bool) * phrase_mask\n",
    "np_debug(sentence_rel)  # (batch, prhase,)\n",
    "\n",
    "# entity ---> phrase\n",
    "entity_pred = np.random.choice(\n",
    "    [False, True], (batch_size, max_phrase)) * phrase_mask\n",
    "np_debug(entity_pred)  # (batch, prhase,)\n",
    "\n",
    "# people|organization|other ---> entity\n",
    "entity_clas = np.random.randn(batch_size, max_phrase, entity_types)\n",
    "entity_clas = softmax(entity_clas) * np.expand_dims(phrase_mask, axis=-1)\n",
    "np_debug(entity_clas)  # (batch, prhase, entity_type,)\n",
    "\n",
    "relation_mask = np.matmul(np.expand_dims(\n",
    "    phrase_mask, axis=2), np.expand_dims(phrase_mask, axis=1))\n",
    "np_debug(relation_mask)  # (batch, prhase, prhase,)\n",
    "\n",
    "# work_for ---> pair\n",
    "relation_clas = np.random.randn(\n",
    "    batch_size, max_phrase, max_phrase, relation_types)\n",
    "relation_clas = softmax(relation_clas) * np.expand_dims(relation_mask, axis=-1)\n",
    "np_debug(relation_clas)  # (batch, prhase, prhase, relation_type,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'entity_gt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ddac0b7d3224>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mentity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'belief'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentity_gt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'belief'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentity_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'entity_gt' is not defined"
     ]
    }
   ],
   "source": [
    "entity['belief', 1.0] = entity_gt\n",
    "entity['belief'] = entity_pred\n",
    "\n",
    "word['feature'] = rword\n",
    "\n",
    "JJ['belief'] = lr(w2c(word['feature']))[:,:,0]\n",
    "NN['belief'] = lr(w2c(word['feature']))[:,:,1]\n",
    "\n",
    "work_for['belief'] = isworkfor(pair['feature'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
