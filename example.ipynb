{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! find . -name \"*.pyc\" -exec rm -f {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"UserWarning\", UserWarning)\n",
    "\n",
    "#with warnings.catch_warnings():\n",
    "warnings.simplefilter(\"default\")\n",
    "#fxn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.graph import Graph\n",
    "from regr.entity import Entity\n",
    "from regr.relation import Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, {'employee': Entity(name='people', what={'rels': {Entity(name='entity'): set([Be(name='(people)-be-(0:entity)', what={'dst': OrderedDict([(0, Entity(name='entity'))]),\n",
      " 'src': Entity(name='people')})])}}), 'employer': Entity(name='organization', what={'rels': {Entity(name='entity'): set([Be(name='(organization)-be-(0:entity)', what={'dst': OrderedDict([(0, Entity(name='entity'))]),\n",
      " 'src': Entity(name='organization')})])}})} is used.\n",
      "regr/relation.py:11: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, {'employee': Entity(name='people', what={'rels': {Entity(name='entity'): set([Be(name='(people)-be-(0:entity)', what={'dst': OrderedDict([(0, Entity(name='entity'))]),\n",
      " 'src': Entity(name='people')})])}}), 'employer': Entity(name='organization', what={'rels': {Entity(name='entity'): set([Be(name='(organization)-be-(0:entity)', what={'dst': OrderedDict([(0, Entity(name='entity'))]),\n",
      " 'src': Entity(name='organization')})])}})} is used.\n",
      "  self.dst = dst\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graph(name='global', what={'entities': [],\n",
       " 'subgraphs': [Graph(name='linguistic', what={'entities': [Entity(name='word', what={'rels': {}}),\n",
       "              Entity(name='phrase', what={'rels': {Entity(name='word'): set([Have(name='(phrase)-have-(0:word)', what={'dst': OrderedDict([(0, Entity(name='word'))]),\n",
       " 'src': Entity(name='phrase')})])}}),\n",
       "              Entity(name='sentence', what={'rels': {Entity(name='phrase'): set([Have(name='(sentence)-have-(0:phrase)', what={'dst': OrderedDict([(0, Entity(name='phrase'))]),\n",
       " 'src': Entity(name='sentence')})])}})],\n",
       " 'subgraphs': [],\n",
       " 'supergraph': Graph(name='global')}),\n",
       "               Graph(name='application', what={'entities': [Entity(name='entity', what={'rels': {Entity(name='phrase'): set([Be(name='(entity)-be-(0:phrase)', what={'dst': OrderedDict([(0, Entity(name='phrase'))]),\n",
       " 'src': Entity(name='entity')})])}}),\n",
       "              Entity(name='pair', what={'rels': {Entity(name='entity'): set([Be(name='(pair)-be-(0:entity,1:entity)', what={'dst': OrderedDict([(0, Entity(name='entity')), (1, Entity(name='entity'))]),\n",
       " 'src': Entity(name='pair')})])}}),\n",
       "              Entity(name='people', what={'rels': {Entity(name='entity'): set([Be(name='(people)-be-(0:entity)', what={'dst': OrderedDict([(0, Entity(name='entity'))]),\n",
       " 'src': Entity(name='people')})])}}),\n",
       "              Entity(name='organization', what={'rels': {Entity(name='entity'): set([Be(name='(organization)-be-(0:entity)', what={'dst': OrderedDict([(0, Entity(name='entity'))]),\n",
       " 'src': Entity(name='organization')})])}}),\n",
       "              Entity(name='other', what={'rels': {Entity(name='entity'): set([Be(name='(other)-be-(0:entity)', what={'dst': OrderedDict([(0, Entity(name='entity'))]),\n",
       " 'src': Entity(name='other')})])}}),\n",
       "              Entity(name='work-for', what={'rels': {Entity(name='pair'): set([Be(name='(work-for)-be-(0:pair)', what={'dst': OrderedDict([(0, Entity(name='pair'))]),\n",
       " 'src': Entity(name='work-for')})]),\n",
       "          Entity(name='people'): set([Be(name='(work-for)-be-(employee:people,employer:organization)', what={'dst': OrderedDict([('employee', Entity(name='people')), ('employer', Entity(name='organization'))]),\n",
       " 'src': Entity(name='work-for')})]),\n",
       "          Entity(name='organization'): set([Be(name='(work-for)-be-(employee:people,employer:organization)', what={'dst': OrderedDict([('employee', Entity(name='people')), ('employer', Entity(name='organization'))]),\n",
       " 'src': Entity(name='work-for')})])}})],\n",
       " 'subgraphs': [],\n",
       " 'supergraph': Graph(name='global')})],\n",
       " 'supergraph': None})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Graph('global') as graph:\n",
    "    with Graph('linguistic') as ling_graph:\n",
    "        # linguistic layer\n",
    "        word = Entity(name='word')\n",
    "        phrase = Entity(name='phrase')\n",
    "        sentence = Entity(name='sentence')\n",
    "        phrase.have(word)\n",
    "        sentence.have(phrase)\n",
    "\n",
    "    with Graph('application') as app_graph:\n",
    "        # application nodes\n",
    "        entity = Entity(name='entity')\n",
    "        entity.be(phrase)\n",
    "        pair = Entity(name='pair')\n",
    "        pair.be((entity, entity))\n",
    "\n",
    "        people = Entity(name='people')\n",
    "        organization = Entity(name='organization')\n",
    "        other = Entity(name='other')\n",
    "        people.be(entity)\n",
    "        organization.be(entity)\n",
    "        other.be(entity)\n",
    "\n",
    "        work_for = Entity(name='work-for')\n",
    "        work_for.be({'employee':people, 'employer':organization})\n",
    "        work_for.be(pair)\n",
    "\n",
    "graph\n",
    "\n",
    "# some other sample of planed graph API, hopefully make sense towards turing completeness\n",
    "#\n",
    "# two.be((people, people))\n",
    "# colleague.be(two)\n",
    "# friend.be(two)\n",
    "# meet.be(two)\n",
    "# beer.be(two)\n",
    "# argue.be(two)\n",
    "# (colleague or friend).be(meet)\n",
    "# (colleague and friend).be(beer)\n",
    "# (colleague and not friend).be(argue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'linguistic': 1, 'global': 1, 'application': 1})\n",
      "Counter({'word': 1, 'people': 1, 'sentence': 1, 'work-for': 1, 'entity': 1, 'other': 1, 'organization': 1, 'pair': 1, 'phrase': 1})\n",
      "Counter({'(pair)-be-(0:entity,1:entity)': 1, '(work-for)-be-(0:pair)': 1, '(other)-be-(0:entity)': 1, '(phrase)-have-(0:word)': 1, '(sentence)-have-(0:phrase)': 1, '(people)-be-(0:entity)': 1, '(organization)-be-(0:entity)': 1, '(entity)-be-(0:phrase)': 1, '(work-for)-be-(employee:people,employer:organization)': 1})\n"
     ]
    }
   ],
   "source": [
    "print Graph._names\n",
    "print Entity._names\n",
    "print Relation._names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_len: (2,), int64\n",
      "mask: (2, 10), bool\n",
      "bword: (2, 10), float64\n",
      "rword: (2, 10, 16), float64\n",
      "tokenizor: (2, 5, 10), bool\n",
      "phrase_mask: (2, 5), bool\n",
      "sentence_rel: (2, 5), bool\n",
      "entity_pred: (2, 5), bool\n",
      "entity_clas: (2, 5, 3), float64\n",
      "relation_mask: (2, 5, 5), bool\n",
      "relation_clas: (2, 5, 5, 2), float64\n"
     ]
    }
   ],
   "source": [
    "# pytorch something\n",
    "# numpy for example\n",
    "\n",
    "import numpy as np\n",
    "from regr.utils import extract_args\n",
    "\n",
    "\n",
    "def np_debug(mat, show_value=False):\n",
    "    args = extract_args(_stack_back_level_=1)\n",
    "    for k, v in args.items():\n",
    "        v = np.array(v)\n",
    "        print('{}: {}, {}'.format(k, v.shape, v.dtype))\n",
    "        if show_value:\n",
    "            print(v)\n",
    "\n",
    "\n",
    "def mask_expand(mask_len, max_len):\n",
    "    mask_len = np.array(mask_len)\n",
    "    expanded = np.tile(np.expand_dims(\n",
    "        np.arange(max_len), axis=0), mask_len.shape + (1,))\n",
    "    return expanded < np.expand_dims(mask_len, axis=-1)\n",
    "\n",
    "\n",
    "def softmax(x): return np.exp(x) / np.exp(x).sum(axis=-1, keepdims=True)\n",
    "\n",
    "\n",
    "# config and data\n",
    "batch_size = 2\n",
    "max_len = 10\n",
    "max_phrase = 5\n",
    "mask_len = np.random.randint(max_len / 4, max_len, size=batch_size)\n",
    "np_debug(mask_len)\n",
    "repr_size = 16\n",
    "\n",
    "entity_types = 3\n",
    "relation_types = 2\n",
    "\n",
    "mask = mask_expand(mask_len, max_len)\n",
    "np_debug(mask)  # (batch, word,)\n",
    "\n",
    "# belief layer\n",
    "bword = np.ones((batch_size, max_len)) * mask\n",
    "np_debug(bword)  # (batch, word,)\n",
    "# embedding layer\n",
    "rword = np.random.random((batch_size, max_len, repr_size)) * \\\n",
    "    np.expand_dims(mask, axis=-1)  # (batch, batch, repr)\n",
    "np_debug(rword)\n",
    "\n",
    "# links\n",
    "# phrase -.-> word\n",
    "tokenizor = np.random.random(\n",
    "    (batch_size, max_phrase, max_len)) * np.expand_dims(mask, axis=1)\n",
    "tokenizor = (tokenizor == tokenizor.max(axis=1, keepdims=True)\n",
    "             ) & np.expand_dims(mask, axis=1)\n",
    "np_debug(tokenizor)  # (batch, prhase, word,)\n",
    "\n",
    "phrase_mask = tokenizor.sum(axis=-1).astype(np.bool)\n",
    "np_debug(phrase_mask)  # (batch, prhase,)\n",
    "\n",
    "# sentence -.-> phrase\n",
    "sentence_rel = np.ones((batch_size, max_phrase), dtype=np.bool) * phrase_mask\n",
    "np_debug(sentence_rel)  # (batch, prhase,)\n",
    "\n",
    "# entity ---> phrase\n",
    "entity_pred = np.random.choice(\n",
    "    [False, True], (batch_size, max_phrase)) * phrase_mask\n",
    "np_debug(entity_pred)  # (batch, prhase,)\n",
    "\n",
    "# people|organization|other ---> entity\n",
    "entity_clas = np.random.randn(batch_size, max_phrase, entity_types)\n",
    "entity_clas = softmax(entity_clas) * np.expand_dims(phrase_mask, axis=-1)\n",
    "np_debug(entity_clas)  # (batch, prhase, entity_type,)\n",
    "\n",
    "relation_mask = np.matmul(np.expand_dims(\n",
    "    phrase_mask, axis=2), np.expand_dims(phrase_mask, axis=1))\n",
    "np_debug(relation_mask)  # (batch, prhase, prhase,)\n",
    "\n",
    "# work_for ---> pair\n",
    "relation_clas = np.random.randn(\n",
    "    batch_size, max_phrase, max_phrase, relation_types)\n",
    "relation_clas = softmax(relation_clas) * np.expand_dims(relation_mask, axis=-1)\n",
    "np_debug(relation_clas)  # (batch, prhase, prhase, relation_type,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'entity_gt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9c6c71eaf949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mentity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'confidence'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentity_gt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'confidence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentity_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'entity_gt' is not defined"
     ]
    }
   ],
   "source": [
    "entity['confidence', 1.0] = entity_gt\n",
    "entity['confidence'] = entity_pred\n",
    "\n",
    "word['feature'] = rword\n",
    "\n",
    "JJ['confidence'] = lr(w2c(word['feature']))[:,:,0]\n",
    "NN['confidence'] = lr(w2c(word['feature']))[:,:,1]\n",
    "\n",
    "work_for['confidence'] = isworkfor(pair['feature'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
