{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hfaghihi/Framework/DomiKnowS/examples/Propara\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "# Please change the root to an absolute or relative path to DomiKnowS root.\n",
    "# In case relative path is used, consider the printed `CWD` as current working directory.\n",
    "root = '/home/hfaghihi/Framework/DomiKnowS'\n",
    "import sys\n",
    "sys.path.append(root)\n",
    "from typing import Any, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '37',\n",
       " 'entities': ['plant; animal'],\n",
       " 'steps': ['A plant of animal dies in a watery environment.',\n",
       "  'Is buried in mud and silt.',\n",
       "  'Soft tissues quickly decompose leaving behind hard bones or shells.',\n",
       "  'Over time sediment builds over the top and hardens into rock.',\n",
       "  'As the bone decays mineral seeps in replacing it.',\n",
       "  'Fossils are formed.'],\n",
       " 'entity_step': [[0.9683084487915039,\n",
       "   0.029291482642292976,\n",
       "   0.0024000774137675762],\n",
       "  [0.012266993522644043, 0.002779645612463355, 0.9849532842636108],\n",
       "  [0.006055360194295645, 0.0023835168685764074, 0.9915611147880554],\n",
       "  [0.0024350169114768505, 0.0022026486694812775, 0.9953623414039612],\n",
       "  [0.0015909943031147122, 0.0026168148033320904, 0.9957921504974365],\n",
       "  [0.0015094410628080368, 0.002839647000655532, 0.9956509470939636],\n",
       "  [0.0016313738888129592, 0.0032306257635354996, 0.9951379895210266]]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"updated_test_data.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.data.reader import RegrReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProparaReader(RegrReader):\n",
    "    def getprocedureIDval(self, item):\n",
    "        return [item['id']]\n",
    "    def getentitiesval(self, item):\n",
    "        return item['entities']\n",
    "    def getstepsval(self, item):\n",
    "        num_steps = len(item['steps']) + 1\n",
    "        rel = torch.ones(num_steps,1)\n",
    "        sentences = [\"step 0 information\"]\n",
    "        sentences.extend(item['steps'])\n",
    "        return rel, sentences\n",
    "    \n",
    "    def getnon_existenceval(self, item):\n",
    "        values = []\n",
    "        for step in range(len(item['steps']) + 1):\n",
    "            values.append([1 - item['entity_step'][step][2], item['entity_step'][step][2]])\n",
    "        return torch.tensor(values)\n",
    "            \n",
    "    def getknownval(self, item):\n",
    "        values = []\n",
    "        for step in range(len(item['steps']) + 1):\n",
    "            values.append([1 - item['entity_step'][step][0], item['entity_step'][step][0]])\n",
    "        return torch.tensor(values)\n",
    "    \n",
    "    def getunkownval(self, item):\n",
    "        values = []\n",
    "        for step in range(len(item['steps']) + 1):\n",
    "            values.append([1 - item['entity_step'][step][1], item['entity_step'][step][1]])\n",
    "        return torch.tensor(values)\n",
    "    \n",
    "    def getactionval(self, item):\n",
    "        action1s = torch.diag(torch.ones(len(item['steps']) + 1) )[:-1]\n",
    "        action2s = torch.diag(torch.ones(len(item['steps']) + 1) )[1:]\n",
    "        raw = torch.zeros(len(item['steps']))\n",
    "        return action1s, action2s\n",
    "    \n",
    "    def getcreateval(self, item):\n",
    "        actions = []\n",
    "        prev_state = item['entity_step'][0]\n",
    "        for sid, step in enumerate(item['steps']):\n",
    "            o = 0\n",
    "            c = 0\n",
    "            d = 0\n",
    "            o += (prev_state[0] * item['entity_step'][sid+1][0])\n",
    "            o += (prev_state[0] * item['entity_step'][sid+1][1])\n",
    "            o += (prev_state[1] * item['entity_step'][sid+1][0])\n",
    "            o += (prev_state[1] * item['entity_step'][sid+1][1])\n",
    "            o += (prev_state[2] * item['entity_step'][sid+1][2])\n",
    "            d += (prev_state[0] * item['entity_step'][sid+1][2])\n",
    "            d += (prev_state[1] * item['entity_step'][sid+1][2])\n",
    "            c += (prev_state[2] * item['entity_step'][sid+1][1])\n",
    "            c += (prev_state[2] * item['entity_step'][sid+1][0])\n",
    "            actions.append([1-c, c])\n",
    "            prev_state = item['entity_step'][sid+1]\n",
    "        \n",
    "        return torch.tensor(actions)\n",
    "                    \n",
    "    def getdestroyval(self, item):\n",
    "        actions = []\n",
    "        prev_state = item['entity_step'][0]\n",
    "        for sid, step in enumerate(item['steps']):\n",
    "            o = 0\n",
    "            c = 0\n",
    "            d = 0\n",
    "            o += (prev_state[0] * item['entity_step'][sid+1][0])\n",
    "            o += (prev_state[0] * item['entity_step'][sid+1][1])\n",
    "            o += (prev_state[1] * item['entity_step'][sid+1][0])\n",
    "            o += (prev_state[1] * item['entity_step'][sid+1][1])\n",
    "            o += (prev_state[2] * item['entity_step'][sid+1][2])\n",
    "            d += (prev_state[0] * item['entity_step'][sid+1][2])\n",
    "            d += (prev_state[1] * item['entity_step'][sid+1][2])\n",
    "            c += (prev_state[2] * item['entity_step'][sid+1][1])\n",
    "            c += (prev_state[2] * item['entity_step'][sid+1][0])\n",
    "            actions.append([1-d, d])\n",
    "            prev_state = item['entity_step'][sid+1]\n",
    "        return torch.tensor(actions)\n",
    "    \n",
    "    def getotherval(self, item):\n",
    "        actions = []\n",
    "        prev_state = item['entity_step'][0]\n",
    "        for sid, step in enumerate(item['steps']):\n",
    "            o = 0\n",
    "            c = 0\n",
    "            d = 0\n",
    "            o += (prev_state[0] * item['entity_step'][sid+1][0])\n",
    "            o += (prev_state[0] * item['entity_step'][sid+1][1])\n",
    "            o += (prev_state[1] * item['entity_step'][sid+1][0])\n",
    "            o += (prev_state[1] * item['entity_step'][sid+1][1])\n",
    "            o += (prev_state[2] * item['entity_step'][sid+1][2])\n",
    "            d += (prev_state[0] * item['entity_step'][sid+1][2])\n",
    "            d += (prev_state[1] * item['entity_step'][sid+1][2])\n",
    "            c += (prev_state[2] * item['entity_step'][sid+1][1])\n",
    "            c += (prev_state[2] * item['entity_step'][sid+1][0])\n",
    "            actions.append([1-o, o])\n",
    "            prev_state = item['entity_step'][sid+1]\n",
    "        return torch.tensor(actions)\n",
    "    \n",
    "    def getbeforeval(self, item):\n",
    "        b1s = []\n",
    "        b2s = []\n",
    "        for step in range(len(item['steps']) + 1):\n",
    "            b1 = torch.zeros(len(item['steps']) + 1)\n",
    "            b1[step] = 1\n",
    "            for step1 in range(len(item['steps']) + 1):\n",
    "                b2 = torch.zeros(len(item['steps']) + 1)\n",
    "                b2[step1] = 1\n",
    "                b1s.append(b1)\n",
    "                b2s.append(b2)\n",
    "        return torch.stack(b1s), torch.stack(b2s)\n",
    "    \n",
    "    def getbefore_trueval(self, item):\n",
    "        num_steps = len(item['steps']) + 1\n",
    "        values = torch.zeros(num_steps * num_steps)\n",
    "        for step in range(len(item['steps']) + 1):\n",
    "            for step1 in range(step + 1, len(item['steps']) + 1):\n",
    "                values[(step*num_steps)+step1] = 1\n",
    "        return values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': (tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.]]),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.]])),\n",
       " 'before_true': tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "         1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'before': (tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.]]),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.]])),\n",
       " 'create': tensor([[9.9996e-01, 3.6113e-05],\n",
       "         [9.9169e-01, 8.3119e-03],\n",
       "         [9.9540e-01, 4.5985e-03],\n",
       "         [9.9581e-01, 4.1883e-03],\n",
       "         [9.9567e-01, 4.3308e-03],\n",
       "         [9.9516e-01, 4.8409e-03]]),\n",
       " 'destroy': tensor([[0.0174, 0.9826],\n",
       "         [0.9851, 0.0149],\n",
       "         [0.9916, 0.0084],\n",
       "         [0.9954, 0.0046],\n",
       "         [0.9958, 0.0042],\n",
       "         [0.9957, 0.0043]]),\n",
       " 'entities': ['plant; animal'],\n",
       " 'known': tensor([[0.0317, 0.9683],\n",
       "         [0.9877, 0.0123],\n",
       "         [0.9939, 0.0061],\n",
       "         [0.9976, 0.0024],\n",
       "         [0.9984, 0.0016],\n",
       "         [0.9985, 0.0015],\n",
       "         [0.9984, 0.0016]]),\n",
       " 'non_existence': tensor([[0.9976, 0.0024],\n",
       "         [0.0150, 0.9850],\n",
       "         [0.0084, 0.9916],\n",
       "         [0.0046, 0.9954],\n",
       "         [0.0042, 0.9958],\n",
       "         [0.0043, 0.9957],\n",
       "         [0.0049, 0.9951]]),\n",
       " 'other': tensor([[0.9826, 0.0174],\n",
       "         [0.0232, 0.9768],\n",
       "         [0.0130, 0.9870],\n",
       "         [0.0088, 0.9912],\n",
       "         [0.0085, 0.9915],\n",
       "         [0.0092, 0.9908]]),\n",
       " 'procedureID': ['37'],\n",
       " 'steps': (tensor([[1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.]]),\n",
       "  ['step 0 information',\n",
       "   'A plant of animal dies in a watery environment.',\n",
       "   'Is buried in mud and silt.',\n",
       "   'Soft tissues quickly decompose leaving behind hard bones or shells.',\n",
       "   'Over time sediment builds over the top and hardens into rock.',\n",
       "   'As the bone decays mineral seeps in replacing it.',\n",
       "   'Fossils are formed.']),\n",
       " 'unkown': tensor([[0.9707, 0.0293],\n",
       "         [0.9972, 0.0028],\n",
       "         [0.9976, 0.0024],\n",
       "         [0.9978, 0.0022],\n",
       "         [0.9974, 0.0026],\n",
       "         [0.9972, 0.0028],\n",
       "         [0.9968, 0.0032]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReaderObjectsIterator = ProparaReader(\"updated_test_data.json\")\n",
    "next(iter(ReaderObjectsIterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file for dataNode is in: /home/hfaghihi/Framework/DomiKnowS/examples/Propara/datanode.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('arg1', 'step'), ('arg2', 'step')]) is used.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('arg1', 'step'), ('arg2', 'step')]) is used.\n"
     ]
    }
   ],
   "source": [
    "from regr.graph import Graph, Concept, Relation\n",
    "from regr.graph.logicalConstrain import orL, andL, existsL, notL, atLeastL, atMostL, ifL, nandL, eqL\n",
    "\n",
    "Graph.clear()\n",
    "Concept.clear()\n",
    "Relation.clear()\n",
    "\n",
    "with Graph('global') as graph:\n",
    "    procedure = Concept(\"procedure\")\n",
    "    step = Concept(\"step\")\n",
    "    (procedure_contain_step, ) = procedure.contains(step)\n",
    "#     entity = Concept(\"entity\")\n",
    "    non_existence = step(\"non_existence\")\n",
    "    unknown_loc = step(\"unknown_location\")\n",
    "    known_loc = step(\"known_location\")\n",
    "    before = Concept(\"before\")\n",
    "    (before_arg1, before_arg2) = before.has_a(arg1=step, arg2=step)\n",
    "    action = Concept(\"action\")\n",
    "    (action_arg1, action_arg2) = action.has_a(arg1=step, arg2=step)\n",
    "    create = action(name=\"create\")\n",
    "    destroy = action(name=\"destroy\")\n",
    "    other = action(name=\"other\")\n",
    "\n",
    "    #LC1 : An action can not be create, destroy and other at the same time\n",
    "    nandL(create, destroy, other)\n",
    "    \n",
    "    #LC2 : An action should at least be one of the create, destroy or other\n",
    "    orL(create, destroy, other)\n",
    "    \n",
    "    #LC3 : A step can not be known_loc, unknown_loc and non_existence at the same time\n",
    "    nandL(known_loc, unknown_loc, non_existence)\n",
    "    \n",
    "    #LC4 : A step should at least be one of known_loc, unknown_loc or non_existence\n",
    "    orL(known_loc, unknown_loc, non_existence)\n",
    "    \n",
    "    #LC5 : If action is create then the first step should be non_existence and the second step can be either known_loc or unknown_loc\n",
    "    ifL(create, (\"x\", \"y\", ), andL(non_existence, (\"x\", ), orL(known_loc, (\"y\", ), unknown_loc, (\"y\", ))))\n",
    "    \n",
    "    #LC 6 : If action is destroy, then first step should be either known_loc,or unknown_loc and the next step should be non_existence \n",
    "    ifL(destroy, (\"x\", \"y\", ), andL(orL(known_loc, (\"x\", ), unknown_loc, (\"x\", )), non_existence, (\"y\", )))\n",
    "    \n",
    "    #LC7 : There should be at most 1 create\n",
    "    atMostL(1, (\"x\", ), create, (\"x\", ))\n",
    "    \n",
    "    #LC8 : There should be at most one destroy\n",
    "    atMostL(1, (\"x\", ), destroy, (\"x\", ))\n",
    "    \n",
    "    #LC9 : If (x1,x2) is create and (y1, y2) is destroy, then the pair(x2,y2) if before should have the property \"check\" equal to 1.\n",
    "    # I will have to check if this eqL works if not will update it\n",
    "    ifL(andL(create, (\"x1\", \"x2\"), destroy, (\"y1\", \"y2\")), eqL(before, \"check\", 1), (\"x2\", \"y2\"))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.sensor.pytorch.sensors import ReaderSensor, JointSensor\n",
    "from regr.sensor.pytorch.relation_sensors import EdgeSensor\n",
    "\n",
    "class EdgeReaderSensor(EdgeSensor, ReaderSensor):\n",
    "    def __init__(self, *pres, relation, mode=\"forward\", keyword=None, **kwargs):\n",
    "        super().__init__(*pres, relation=relation, mode=mode, **kwargs)\n",
    "        self.keyword = keyword\n",
    "        self.data = None\n",
    "        \n",
    "# class JoinReaderSensor(JointSensor, ReaderSensor):\n",
    "#     pass\n",
    "            \n",
    "# class JoinEdgeReaderSensor(JointSensor, EdgeReaderSensor):\n",
    "#     pass\n",
    "\n",
    "class JoinReaderSensor(JointSensor, ReaderSensor):\n",
    "    pass\n",
    "\n",
    "class JoinEdgeReaderSensor(JoinReaderSensor, EdgeSensor):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.sensor.pytorch.sensors import ReaderSensor\n",
    "from regr.program import LearningBasedProgram\n",
    "from regr.program.model.pytorch import PoiModel\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def model_declaration():\n",
    "\n",
    "    graph.detach()\n",
    "\n",
    "    # --- City\n",
    "    procedure['id'] = ReaderSensor(keyword='procedureID')\n",
    "    step[procedure_contain_step.forward, 'text'] = JoinReaderSensor(procedure['id'], keyword='steps')\n",
    "    # word[step_contains_word, 'raw'] = ReaderSensor(keyword='words')\n",
    "#     entity['raw'] = ReaderSensor(keyword='entities')\n",
    "\n",
    "    step[non_existence] = ReaderSensor(procedure_contain_step.forward, 'text', keyword='non_existence')\n",
    "    step[unknown_loc] = ReaderSensor(procedure_contain_step.forward, 'text', keyword='known')\n",
    "    step[known_loc] = ReaderSensor(procedure_contain_step.forward, 'text', keyword='unkown')\n",
    "    \n",
    "    step[non_existence] = ReaderSensor(keyword='non_existence', label=True)\n",
    "    step[unknown_loc] = ReaderSensor(keyword='known', label=True)\n",
    "    step[known_loc] = ReaderSensor(keyword='unkown', label=True)\n",
    "    \n",
    "    action[action_arg1.backward, action_arg2.backward] = JoinReaderSensor(step['text'], keyword='action')\n",
    "    \n",
    "    action[create] = ReaderSensor(action_arg1.backward, action_arg2.backward, keyword='create')\n",
    "    action[destroy] = ReaderSensor(action_arg1.backward, action_arg2.backward, keyword='destroy')\n",
    "    action[other] = ReaderSensor(action_arg1.backward, action_arg2.backward, keyword='other')\n",
    "    \n",
    "    action[create] = ReaderSensor(keyword='create', label=True)\n",
    "    action[destroy] = ReaderSensor(keyword='destroy', label=True)\n",
    "    action[other] = ReaderSensor(keyword='other', label=True)\n",
    "    \n",
    "    before[before_arg1.backward, before_arg2.backward] = JoinReaderSensor(step['text'], keyword=\"before\")\n",
    "    \n",
    "    before[\"check\"] = ReaderSensor(before_arg1.backward, before_arg2.backward, keyword=\"before_true\")\n",
    "    before[\"check\"] = ReaderSensor(keyword=\"before_true\", label=True)\n",
    "    \n",
    "    program = LearningBasedProgram(graph, **{\n",
    "        'Model': PoiModel,\n",
    "#         'poi': (known_loc, unknown_loc, non_existence, other, destroy, create),\n",
    "        'loss': None,\n",
    "        'metric': None,\n",
    "    })\n",
    "    return program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # set logger level to see training and testing logs\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    lbp = model_declaration()\n",
    "\n",
    "    dataset = ProparaReader(file='updated_test_data.json')  # Adding the info on the reader\n",
    "\n",
    "#     lbp.test(dataset, device='auto')\n",
    "\n",
    "    for datanode in lbp.populate(dataset, device=\"cpu\"):\n",
    "        print('datanode:', datanode)\n",
    "        data1 = datanode.findDatanodes(select = step)[0].getAttribute(\"text\")\n",
    "        print(data1)\n",
    "        data1 = datanode.findDatanodes(select = step)[0].getAttribute(non_existence)\n",
    "        print(data1)\n",
    "        data1 = datanode.findDatanodes(select = before)[0].getAttribute(\"check\")\n",
    "        print(data1)\n",
    "        data1 = datanode.findDatanodes(select = action)[0].getAttribute(create)\n",
    "        print(data1)\n",
    "#         datanode.inferILPConstrains(create, destroy, other, non_existence, known_loc, unknown_loc, fun=None)\n",
    "#         print('datanode:', datanode)\n",
    "#         print('inference spam:', datanode.getAttribute(Spam, 'ILP'))\n",
    "#         print('inference regular:', datanode.getAttribute(Regular, 'ILP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datanode: procedure 0\n",
      "step 0 information\n",
      "tensor([0.9976, 0.0024])\n",
      "tensor(0.)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-7874105c9dd9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatanode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindDatanodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAttribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"check\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatanode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindDatanodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAttribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#         datanode.inferILPConstrains(create, destroy, other, non_existence, known_loc, unknown_loc, fun=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hfaghihi/Framework/DomiKnowS/regr/sensor/pytorch/sensors.py:196: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.data, device=self.device)\n"
     ]
    }
   ],
   "source": [
    "from regr.graph import DataNodeBuilder\n",
    "from regr.sensor.sensor import Sensor\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "lbp = model_declaration()\n",
    "dataset = ProparaReader(file='updated_test_data.json')\n",
    "for datanode in lbp.populate(list(dataset)[0:1], device=\"cpu\"):\n",
    "    pass\n",
    "dataset = ProparaReader(file='updated_test_data.json')\n",
    "context = {\"graph\": graph}\n",
    "context.update(next(iter(dataset)))\n",
    "data_item = DataNodeBuilder(context)\n",
    "# data_item\n",
    "for sensor in procedure['id'].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in step['text'].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in step[procedure_contain_step.forward].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in step[known_loc].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in step[unknown_loc].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in step[non_existence].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in action[action_arg1.backward].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in action[action_arg2.backward].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in action[destroy].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in action[create].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in action[other].find(Sensor):\n",
    "    sensor(data_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'graph': Graph(name='global', fullname='global'),\n",
       " 'action': (tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.]]),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.]])),\n",
       " 'before_true': tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "         1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'before': (tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.]]),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.]])),\n",
       " 'create': tensor([[9.9996e-01, 3.6113e-05],\n",
       "         [9.9169e-01, 8.3119e-03],\n",
       "         [9.9540e-01, 4.5985e-03],\n",
       "         [9.9581e-01, 4.1883e-03],\n",
       "         [9.9567e-01, 4.3308e-03],\n",
       "         [9.9516e-01, 4.8409e-03]]),\n",
       " 'destroy': tensor([[0.0174, 0.9826],\n",
       "         [0.9851, 0.0149],\n",
       "         [0.9916, 0.0084],\n",
       "         [0.9954, 0.0046],\n",
       "         [0.9958, 0.0042],\n",
       "         [0.9957, 0.0043]]),\n",
       " 'entities': ['plant; animal'],\n",
       " 'known': tensor([[0.0317, 0.9683],\n",
       "         [0.9877, 0.0123],\n",
       "         [0.9939, 0.0061],\n",
       "         [0.9976, 0.0024],\n",
       "         [0.9984, 0.0016],\n",
       "         [0.9985, 0.0015],\n",
       "         [0.9984, 0.0016]]),\n",
       " 'non_existence': tensor([[0.9976, 0.0024],\n",
       "         [0.0150, 0.9850],\n",
       "         [0.0084, 0.9916],\n",
       "         [0.0046, 0.9954],\n",
       "         [0.0042, 0.9958],\n",
       "         [0.0043, 0.9957],\n",
       "         [0.0049, 0.9951]]),\n",
       " 'other': tensor([[0.9826, 0.0174],\n",
       "         [0.0232, 0.9768],\n",
       "         [0.0130, 0.9870],\n",
       "         [0.0088, 0.9912],\n",
       "         [0.0085, 0.9915],\n",
       "         [0.0092, 0.9908]]),\n",
       " 'procedureID': ['37'],\n",
       " 'steps': (tensor([[1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.]]),\n",
       "  ['step 0 information',\n",
       "   'A plant of animal dies in a watery environment.',\n",
       "   'Is buried in mud and silt.',\n",
       "   'Soft tissues quickly decompose leaving behind hard bones or shells.',\n",
       "   'Over time sediment builds over the top and hardens into rock.',\n",
       "   'As the bone decays mineral seeps in replacing it.',\n",
       "   'Fossils are formed.']),\n",
       " 'unkown': tensor([[0.9707, 0.0293],\n",
       "         [0.9972, 0.0028],\n",
       "         [0.9976, 0.0024],\n",
       "         [0.9978, 0.0022],\n",
       "         [0.9974, 0.0026],\n",
       "         [0.9972, 0.0028],\n",
       "         [0.9968, 0.0032]]),\n",
       " 'Counter_setitem': 35,\n",
       " 'Counter/global/procedure/id/readersensor': {('37',): {'counter': 1,\n",
       "   'recent': True}},\n",
       " 'dataNode': [procedure 0,\n",
       "  action 0,\n",
       "  action 1,\n",
       "  action 2,\n",
       "  action 3,\n",
       "  action 4,\n",
       "  action 5,\n",
       "  action 0,\n",
       "  action 1,\n",
       "  action 2,\n",
       "  action 3,\n",
       "  action 4,\n",
       "  action 5,\n",
       "  action 0,\n",
       "  action 1,\n",
       "  action 2,\n",
       "  action 3,\n",
       "  action 4,\n",
       "  action 5,\n",
       "  action 0,\n",
       "  action 1,\n",
       "  action 2,\n",
       "  action 3,\n",
       "  action 4,\n",
       "  action 5],\n",
       " 'global/procedure/index': [procedure 0],\n",
       " ReaderSensor(name='readersensor', fullname='global/procedure/id/readersensor'): ['37'],\n",
       " 'DataNodeTime': 0.009783744812011719,\n",
       " Property(name='id', fullname='global/procedure/id'): ['37'],\n",
       " JoinReaderSensor(name='joinreadersensor', fullname='global/step/(Contains(name='procedure-contains-0-step', fullname='global/procedure-contains-0-step').forward, 'text')/joinreadersensor'): (tensor([[1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.]]),\n",
       "  ['step 0 information',\n",
       "   'A plant of animal dies in a watery environment.',\n",
       "   'Is buried in mud and silt.',\n",
       "   'Soft tissues quickly decompose leaving behind hard bones or shells.',\n",
       "   'Over time sediment builds over the top and hardens into rock.',\n",
       "   'As the bone decays mineral seeps in replacing it.',\n",
       "   'Fossils are formed.']),\n",
       " 'Counter/global/step/text/functionalsensor': {('step 0 information',\n",
       "   'A plant of animal dies in a watery environment.',\n",
       "   'Is buried in mud and silt.',\n",
       "   'Soft tissues quickly decompose leaving behind hard bones or shells.',\n",
       "   'Over time sediment builds over the top and hardens into rock.',\n",
       "   'As the bone decays mineral seeps in replacing it.',\n",
       "   'Fossils are formed.'): {'counter': 1, 'recent': True}},\n",
       " 'global/step/index': [[step 0,\n",
       "   step 1,\n",
       "   step 2,\n",
       "   step 3,\n",
       "   step 4,\n",
       "   step 5,\n",
       "   step 6]],\n",
       " FunctionalSensor(name='functionalsensor', fullname='global/step/text/functionalsensor'): ['step 0 information',\n",
       "  'A plant of animal dies in a watery environment.',\n",
       "  'Is buried in mud and silt.',\n",
       "  'Soft tissues quickly decompose leaving behind hard bones or shells.',\n",
       "  'Over time sediment builds over the top and hardens into rock.',\n",
       "  'As the bone decays mineral seeps in replacing it.',\n",
       "  'Fossils are formed.'],\n",
       " Property(name='text', fullname='global/step/text'): ['step 0 information',\n",
       "  'A plant of animal dies in a watery environment.',\n",
       "  'Is buried in mud and silt.',\n",
       "  'Soft tissues quickly decompose leaving behind hard bones or shells.',\n",
       "  'Over time sediment builds over the top and hardens into rock.',\n",
       "  'As the bone decays mineral seeps in replacing it.',\n",
       "  'Fossils are formed.'],\n",
       " 'Counter/global/step/procedure-contains-0-step.forward/edgesensor': {tensor([[1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.]]): {'counter': 1, 'recent': True}},\n",
       " EdgeSensor(name='edgesensor', fullname='global/step/procedure-contains-0-step.forward/edgesensor'): tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " Property(name='procedure-contains-0-step.forward', fullname='global/step/procedure-contains-0-step.forward'): tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " 'Counter/global/step/<known_location>/readersensor-3': {tensor([[0.9707, 0.0293],\n",
       "          [0.9972, 0.0028],\n",
       "          [0.9976, 0.0024],\n",
       "          [0.9978, 0.0022],\n",
       "          [0.9974, 0.0026],\n",
       "          [0.9972, 0.0028],\n",
       "          [0.9968, 0.0032]]): {'counter': 1, 'recent': True}},\n",
       " ReaderSensor(name='readersensor-3', fullname='global/step/<known_location>/readersensor-3'): tensor([[0.9707, 0.0293],\n",
       "         [0.9972, 0.0028],\n",
       "         [0.9976, 0.0024],\n",
       "         [0.9978, 0.0022],\n",
       "         [0.9974, 0.0026],\n",
       "         [0.9972, 0.0028],\n",
       "         [0.9968, 0.0032]]),\n",
       " Property(name='known_location', fullname='global/step/<known_location>'): tensor([[0.9707, 0.0293],\n",
       "         [0.9972, 0.0028],\n",
       "         [0.9976, 0.0024],\n",
       "         [0.9978, 0.0022],\n",
       "         [0.9974, 0.0026],\n",
       "         [0.9972, 0.0028],\n",
       "         [0.9968, 0.0032]]),\n",
       " 'Counter/global/step/<known_location>/readersensor-6': {tensor([[0.9707, 0.0293],\n",
       "          [0.9972, 0.0028],\n",
       "          [0.9976, 0.0024],\n",
       "          [0.9978, 0.0022],\n",
       "          [0.9974, 0.0026],\n",
       "          [0.9972, 0.0028],\n",
       "          [0.9968, 0.0032]]): {'counter': 1, 'recent': True}},\n",
       " ReaderSensor(name='readersensor-6', fullname='global/step/<known_location>/readersensor-6'): tensor([[0.9707, 0.0293],\n",
       "         [0.9972, 0.0028],\n",
       "         [0.9976, 0.0024],\n",
       "         [0.9978, 0.0022],\n",
       "         [0.9974, 0.0026],\n",
       "         [0.9972, 0.0028],\n",
       "         [0.9968, 0.0032]]),\n",
       " 'Counter/global/step/<unknown_location>/readersensor-2': {tensor([[0.0317, 0.9683],\n",
       "          [0.9877, 0.0123],\n",
       "          [0.9939, 0.0061],\n",
       "          [0.9976, 0.0024],\n",
       "          [0.9984, 0.0016],\n",
       "          [0.9985, 0.0015],\n",
       "          [0.9984, 0.0016]]): {'counter': 1, 'recent': True}},\n",
       " ReaderSensor(name='readersensor-2', fullname='global/step/<unknown_location>/readersensor-2'): tensor([[0.0317, 0.9683],\n",
       "         [0.9877, 0.0123],\n",
       "         [0.9939, 0.0061],\n",
       "         [0.9976, 0.0024],\n",
       "         [0.9984, 0.0016],\n",
       "         [0.9985, 0.0015],\n",
       "         [0.9984, 0.0016]]),\n",
       " Property(name='unknown_location', fullname='global/step/<unknown_location>'): tensor([[0.0317, 0.9683],\n",
       "         [0.9877, 0.0123],\n",
       "         [0.9939, 0.0061],\n",
       "         [0.9976, 0.0024],\n",
       "         [0.9984, 0.0016],\n",
       "         [0.9985, 0.0015],\n",
       "         [0.9984, 0.0016]]),\n",
       " 'Counter/global/step/<unknown_location>/readersensor-5': {tensor([[0.0317, 0.9683],\n",
       "          [0.9877, 0.0123],\n",
       "          [0.9939, 0.0061],\n",
       "          [0.9976, 0.0024],\n",
       "          [0.9984, 0.0016],\n",
       "          [0.9985, 0.0015],\n",
       "          [0.9984, 0.0016]]): {'counter': 1, 'recent': True}},\n",
       " ReaderSensor(name='readersensor-5', fullname='global/step/<unknown_location>/readersensor-5'): tensor([[0.0317, 0.9683],\n",
       "         [0.9877, 0.0123],\n",
       "         [0.9939, 0.0061],\n",
       "         [0.9976, 0.0024],\n",
       "         [0.9984, 0.0016],\n",
       "         [0.9985, 0.0015],\n",
       "         [0.9984, 0.0016]]),\n",
       " 'Counter/global/step/<non_existence>/readersensor-1': {tensor([[0.9976, 0.0024],\n",
       "          [0.0150, 0.9850],\n",
       "          [0.0084, 0.9916],\n",
       "          [0.0046, 0.9954],\n",
       "          [0.0042, 0.9958],\n",
       "          [0.0043, 0.9957],\n",
       "          [0.0049, 0.9951]]): {'counter': 1, 'recent': True}},\n",
       " ReaderSensor(name='readersensor-1', fullname='global/step/<non_existence>/readersensor-1'): tensor([[0.9976, 0.0024],\n",
       "         [0.0150, 0.9850],\n",
       "         [0.0084, 0.9916],\n",
       "         [0.0046, 0.9954],\n",
       "         [0.0042, 0.9958],\n",
       "         [0.0043, 0.9957],\n",
       "         [0.0049, 0.9951]]),\n",
       " Property(name='non_existence', fullname='global/step/<non_existence>'): tensor([[0.9976, 0.0024],\n",
       "         [0.0150, 0.9850],\n",
       "         [0.0084, 0.9916],\n",
       "         [0.0046, 0.9954],\n",
       "         [0.0042, 0.9958],\n",
       "         [0.0043, 0.9957],\n",
       "         [0.0049, 0.9951]]),\n",
       " 'Counter/global/step/<non_existence>/readersensor-4': {tensor([[0.9976, 0.0024],\n",
       "          [0.0150, 0.9850],\n",
       "          [0.0084, 0.9916],\n",
       "          [0.0046, 0.9954],\n",
       "          [0.0042, 0.9958],\n",
       "          [0.0043, 0.9957],\n",
       "          [0.0049, 0.9951]]): {'counter': 1, 'recent': True}},\n",
       " ReaderSensor(name='readersensor-4', fullname='global/step/<non_existence>/readersensor-4'): tensor([[0.9976, 0.0024],\n",
       "         [0.0150, 0.9850],\n",
       "         [0.0084, 0.9916],\n",
       "         [0.0046, 0.9954],\n",
       "         [0.0042, 0.9958],\n",
       "         [0.0043, 0.9957],\n",
       "         [0.0049, 0.9951]]),\n",
       " JoinReaderSensor(name='joinreadersensor-1', fullname='global/action/(HasA(name='arg1-1', fullname='global/arg1-1').backward, HasA(name='arg2-1', fullname='global/arg2-1').backward)/joinreadersensor-1'): (tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.]]),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.]])),\n",
       " 'Counter/global/action/arg1-1.backward/edgesensor-1': {tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.]]): {'counter': 1, 'recent': True}},\n",
       " 'global/action/index': [action 0,\n",
       "  action 1,\n",
       "  action 2,\n",
       "  action 3,\n",
       "  action 4,\n",
       "  action 5],\n",
       " 'actionRelationAttrsCache': {'arg1-1': tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.]]),\n",
       "  'arg2-1': tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.]])},\n",
       " EdgeSensor(name='edgesensor-1', fullname='global/action/arg1-1.backward/edgesensor-1'): tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0.]]),\n",
       " Property(name='arg1-1.backward', fullname='global/action/arg1-1.backward'): tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0.]]),\n",
       " 'Counter/global/action/arg2-1.backward/edgesensor-2': {tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.]]): {'counter': 1, 'recent': True}},\n",
       " EdgeSensor(name='edgesensor-2', fullname='global/action/arg2-1.backward/edgesensor-2'): tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1.]]),\n",
       " Property(name='arg2-1.backward', fullname='global/action/arg2-1.backward'): tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1.]]),\n",
       " 'Counter/global/action/<destroy>/readersensor-8': {tensor([[0.0174, 0.9826],\n",
       "          [0.9851, 0.0149],\n",
       "          [0.9916, 0.0084],\n",
       "          [0.9954, 0.0046],\n",
       "          [0.9958, 0.0042],\n",
       "          [0.9957, 0.0043]]): {'counter': 1, 'recent': True}},\n",
       " ReaderSensor(name='readersensor-8', fullname='global/action/<destroy>/readersensor-8'): tensor([[0.0174, 0.9826],\n",
       "         [0.9851, 0.0149],\n",
       "         [0.9916, 0.0084],\n",
       "         [0.9954, 0.0046],\n",
       "         [0.9958, 0.0042],\n",
       "         [0.9957, 0.0043]]),\n",
       " Property(name='destroy', fullname='global/action/<destroy>'): tensor([[0.0174, 0.9826],\n",
       "         [0.9851, 0.0149],\n",
       "         [0.9916, 0.0084],\n",
       "         [0.9954, 0.0046],\n",
       "         [0.9958, 0.0042],\n",
       "         [0.9957, 0.0043]]),\n",
       " 'Counter/global/action/<destroy>/readersensor-11': {tensor([[0.0174, 0.9826],\n",
       "          [0.9851, 0.0149],\n",
       "          [0.9916, 0.0084],\n",
       "          [0.9954, 0.0046],\n",
       "          [0.9958, 0.0042],\n",
       "          [0.9957, 0.0043]]): {'counter': 1, 'recent': True}},\n",
       " ReaderSensor(name='readersensor-11', fullname='global/action/<destroy>/readersensor-11'): tensor([[0.0174, 0.9826],\n",
       "         [0.9851, 0.0149],\n",
       "         [0.9916, 0.0084],\n",
       "         [0.9954, 0.0046],\n",
       "         [0.9958, 0.0042],\n",
       "         [0.9957, 0.0043]]),\n",
       " 'Counter/global/action/<create>/readersensor-7': {tensor([[9.9996e-01, 3.6113e-05],\n",
       "          [9.9169e-01, 8.3119e-03],\n",
       "          [9.9540e-01, 4.5985e-03],\n",
       "          [9.9581e-01, 4.1883e-03],\n",
       "          [9.9567e-01, 4.3308e-03],\n",
       "          [9.9516e-01, 4.8409e-03]]): {'counter': 1, 'recent': True}},\n",
       " ReaderSensor(name='readersensor-7', fullname='global/action/<create>/readersensor-7'): tensor([[9.9996e-01, 3.6113e-05],\n",
       "         [9.9169e-01, 8.3119e-03],\n",
       "         [9.9540e-01, 4.5985e-03],\n",
       "         [9.9581e-01, 4.1883e-03],\n",
       "         [9.9567e-01, 4.3308e-03],\n",
       "         [9.9516e-01, 4.8409e-03]]),\n",
       " Property(name='create', fullname='global/action/<create>'): tensor([[9.9996e-01, 3.6113e-05],\n",
       "         [9.9169e-01, 8.3119e-03],\n",
       "         [9.9540e-01, 4.5985e-03],\n",
       "         [9.9581e-01, 4.1883e-03],\n",
       "         [9.9567e-01, 4.3308e-03],\n",
       "         [9.9516e-01, 4.8409e-03]]),\n",
       " 'Counter/global/action/<create>/readersensor-10': {tensor([[9.9996e-01, 3.6113e-05],\n",
       "          [9.9169e-01, 8.3119e-03],\n",
       "          [9.9540e-01, 4.5985e-03],\n",
       "          [9.9581e-01, 4.1883e-03],\n",
       "          [9.9567e-01, 4.3308e-03],\n",
       "          [9.9516e-01, 4.8409e-03]]): {'counter': 1, 'recent': True}},\n",
       " ReaderSensor(name='readersensor-10', fullname='global/action/<create>/readersensor-10'): tensor([[9.9996e-01, 3.6113e-05],\n",
       "         [9.9169e-01, 8.3119e-03],\n",
       "         [9.9540e-01, 4.5985e-03],\n",
       "         [9.9581e-01, 4.1883e-03],\n",
       "         [9.9567e-01, 4.3308e-03],\n",
       "         [9.9516e-01, 4.8409e-03]]),\n",
       " 'Counter/global/action/<other>/readersensor-9': {tensor([[0.9826, 0.0174],\n",
       "          [0.0232, 0.9768],\n",
       "          [0.0130, 0.9870],\n",
       "          [0.0088, 0.9912],\n",
       "          [0.0085, 0.9915],\n",
       "          [0.0092, 0.9908]]): {'counter': 1, 'recent': True}},\n",
       " ReaderSensor(name='readersensor-9', fullname='global/action/<other>/readersensor-9'): tensor([[0.9826, 0.0174],\n",
       "         [0.0232, 0.9768],\n",
       "         [0.0130, 0.9870],\n",
       "         [0.0088, 0.9912],\n",
       "         [0.0085, 0.9915],\n",
       "         [0.0092, 0.9908]]),\n",
       " Property(name='other', fullname='global/action/<other>'): tensor([[0.9826, 0.0174],\n",
       "         [0.0232, 0.9768],\n",
       "         [0.0130, 0.9870],\n",
       "         [0.0088, 0.9912],\n",
       "         [0.0085, 0.9915],\n",
       "         [0.0092, 0.9908]]),\n",
       " 'Counter/global/action/<other>/readersensor-12': {tensor([[0.9826, 0.0174],\n",
       "          [0.0232, 0.9768],\n",
       "          [0.0130, 0.9870],\n",
       "          [0.0088, 0.9912],\n",
       "          [0.0085, 0.9915],\n",
       "          [0.0092, 0.9908]]): {'counter': 1, 'recent': True}},\n",
       " ReaderSensor(name='readersensor-12', fullname='global/action/<other>/readersensor-12'): tensor([[0.9826, 0.0174],\n",
       "         [0.0232, 0.9768],\n",
       "         [0.0130, 0.9870],\n",
       "         [0.0088, 0.9912],\n",
       "         [0.0085, 0.9915],\n",
       "         [0.0092, 0.9908]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procedure 0\n"
     ]
    }
   ],
   "source": [
    "datanode = data_item.getDataNode()\n",
    "print(datanode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 information\n",
      "tensor([0.0317, 0.9683])\n",
      "tensor([0.9707, 0.0293])\n",
      "tensor([0.9976, 0.0024])\n"
     ]
    }
   ],
   "source": [
    "data1 = datanode.findDatanodes(select = step)[0].getAttribute(\"text\")\n",
    "print(data1)\n",
    "data1 = datanode.findDatanodes(select = step)[0].getAttribute(unknown_loc)\n",
    "print(data1)\n",
    "data1 = datanode.findDatanodes(select = step)[0].getAttribute(known_loc)\n",
    "print(data1)\n",
    "data1 = datanode.findDatanodes(select = step)[0].getAttribute(non_existence)\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "tensor([9.9996e-01, 3.6113e-05])\n",
      "tensor([0.0174, 0.9826])\n",
      "tensor([0.9826, 0.0174])\n"
     ]
    }
   ],
   "source": [
    "data1 = len(datanode.findDatanodes(select = action))\n",
    "print(data1)\n",
    "data1 = datanode.findDatanodes(select = action)[0].getAttribute(create)\n",
    "print(data1)\n",
    "data1 = datanode.findDatanodes(select = action)[0].getAttribute(destroy)\n",
    "print(data1)\n",
    "data1 = datanode.findDatanodes(select = action)[0].getAttribute(other)\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file for ilpOntSolver is in: /home/hfaghihi/Framework/DomiKnowS/examples/Propara/ilpOntSolver.log\n",
      "Using license file /home/hfaghihi/gurobi.lic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gurobipy:Using license file /home/hfaghihi/gurobi.lic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gurobipy:Academic license - for non-commercial use only\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'ilpKey' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a35d1901c9e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatanode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferILPConstrains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestroy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_existence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munknown_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/graph/dataNode.py\u001b[0m in \u001b[0;36minferILPConstrains\u001b[0;34m(self, fun, epsilon, minimizeObjective, *_conceptsRelations)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0mtokenResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtripleResult\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mmyilpOntSolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculateILPSelection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfer_candidatesID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphResultsForPhraseToken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphResultsForPhraseRelation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphResultsForTripleRelations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimizeObjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimizeObjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhardConstrains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhardConstrains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/solver/gurobiILPOntSolver.py\u001b[0m in \u001b[0;36mcalculateILPSelection\u001b[0;34m(self, phrase, graphResultsForPhraseToken, graphResultsForPhraseRelation, graphResultsForPhraseTripleRelation, minimizeObjective, hardConstrains)\u001b[0m\n\u001b[1;32m   1637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m                 \u001b[0;31m# Add constraints to the copy model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__addLogicalConstrains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcepts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhardConstrains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhardConstrains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1640\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyLogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Optimizing model for logical constraints with probabilities %s with %i variables and %i constrains'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumVars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumConstrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/solver/gurobiILPOntSolver.py\u001b[0m in \u001b[0;36m__addLogicalConstrains\u001b[0;34m(self, lcs, m, concepts, tokens, x, y, z, hardConstrains)\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlcs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyLogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Processing Logical Constrain %s - %s - %s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlcName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__constructLogicalConstrains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyIlpBooleanProcessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcepts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhardConstrains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhardConstrains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadLC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyLogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Successfully added Logical Constrain %s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlcName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/solver/gurobiILPOntSolver.py\u001b[0m in \u001b[0;36m__constructLogicalConstrains\u001b[0;34m(self, lc, booleanProcesor, m, concepts, tokens, x, y, z, hardConstrains, resultVariableNames, headLC)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbooleanProcesor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlcVariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresultVariableNames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresultVariableNames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadConstrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheadLC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_typeOfConcept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/graph/logicalConstrain.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, model, myIlpBooleanProcessor, v, resultVariableNames, headConstrain)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyIlpBooleanProcessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresultVariableNames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadConstrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateILPConstrains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Nand'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyIlpBooleanProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnandVar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresultVariableNames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadConstrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mifL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogicalConstrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/graph/logicalConstrain.py\u001b[0m in \u001b[0;36mcreateILPConstrains\u001b[0;34m(self, lcName, lcFun, model, v, resultVariableNames, headConstrain)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# Output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0milpV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0milpKey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzVars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'ilpKey' referenced before assignment"
     ]
    }
   ],
   "source": [
    "datanode.inferILPConstrains(create, destroy, other, non_existence, known_loc, unknown_loc, fun=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
