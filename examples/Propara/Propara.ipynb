{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hfaghihi/Framework/DomiKnowS/examples/Propara\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "# Please change the root to an absolute or relative path to DomiKnowS root.\n",
    "# In case relative path is used, consider the printed `CWD` as current working directory.\n",
    "root = '/home/hfaghihi/Framework/DomiKnowS'\n",
    "import sys\n",
    "sys.path.append(root)\n",
    "from typing import Any, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '37',\n",
       " 'entities': ['plant; animal'],\n",
       " 'steps': ['A plant of animal dies in a watery environment.',\n",
       "  'Is buried in mud and silt.',\n",
       "  'Soft tissues quickly decompose leaving behind hard bones or shells.',\n",
       "  'Over time sediment builds over the top and hardens into rock.',\n",
       "  'As the bone decays mineral seeps in replacing it.',\n",
       "  'Fossils are formed.'],\n",
       " 'entity_step': [[0.9683084487915039,\n",
       "   0.029291482642292976,\n",
       "   0.0024000774137675762],\n",
       "  [0.012266993522644043, 0.002779645612463355, 0.9849532842636108],\n",
       "  [0.006055360194295645, 0.0023835168685764074, 0.9915611147880554],\n",
       "  [0.0024350169114768505, 0.0022026486694812775, 0.9953623414039612],\n",
       "  [0.0015909943031147122, 0.0026168148033320904, 0.9957921504974365],\n",
       "  [0.0015094410628080368, 0.002839647000655532, 0.9956509470939636],\n",
       "  [0.0016313738888129592, 0.0032306257635354996, 0.9951379895210266]]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"updated_test_data.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.data.reader import RegrReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProparaReader(RegrReader):\n",
    "    def getprocedureIDval(self, item):\n",
    "        return [item['id']]\n",
    "    def getentitiesval(self, item):\n",
    "        return item['entities']\n",
    "    def getstepsval(self, item):\n",
    "        num_steps = len(item['steps']) + 1\n",
    "        rel = torch.ones(num_steps,1)\n",
    "        sentences = [\"step 0 information\"]\n",
    "        sentences.extend(item['steps'])\n",
    "        return rel, sentences\n",
    "    \n",
    "    def getnon_existenceval(self, item):\n",
    "        values = []\n",
    "        for step in range(len(item['steps']) + 1):\n",
    "            values.append([1 - item['entity_step'][step][2], item['entity_step'][step][2]])\n",
    "        return torch.tensor(values)\n",
    "            \n",
    "    def getknownval(self, item):\n",
    "        values = []\n",
    "        for step in range(len(item['steps']) + 1):\n",
    "            values.append([1 - item['entity_step'][step][0], item['entity_step'][step][0]])\n",
    "        return torch.tensor(values)\n",
    "    \n",
    "    def getunkownval(self, item):\n",
    "        values = []\n",
    "        for step in range(len(item['steps']) + 1):\n",
    "            values.append([1 - item['entity_step'][step][1], item['entity_step'][step][1]])\n",
    "        return torch.tensor(values)\n",
    "    \n",
    "    def getactionval(self, item):\n",
    "        action1s = torch.diag(torch.ones(len(item['steps']) + 1) )[:-1]\n",
    "        action2s = torch.diag(torch.ones(len(item['steps']) + 1) )[1:]\n",
    "        raw = torch.zeros(len(item['steps']))\n",
    "        return action1s, action2s, raw\n",
    "    \n",
    "    def getcreateval(self, item):\n",
    "        actions = []\n",
    "        for sid, step in enumerate(item['steps']):\n",
    "            o = 0\n",
    "            c = 0\n",
    "            d = 0\n",
    "            if sid == 0:\n",
    "                prev_state = item['entity_step'][sid]\n",
    "                continue\n",
    "            else:\n",
    "                o += (prev_state[0] * item['entity_step'][sid][0])\n",
    "                o += (prev_state[0] * item['entity_step'][sid][1])\n",
    "                o += (prev_state[1] * item['entity_step'][sid][0])\n",
    "                o += (prev_state[1] * item['entity_step'][sid][1])\n",
    "                o += (prev_state[2] * item['entity_step'][sid][2])\n",
    "                d += (prev_state[0] * item['entity_step'][sid][2])\n",
    "                d += (prev_state[1] * item['entity_step'][sid][2])\n",
    "                c += (prev_state[2] * item['entity_step'][sid][1])\n",
    "                c += (prev_state[2] * item['entity_step'][sid][0])\n",
    "                actions.append([1-c, c])\n",
    "                prev_state = item['entity_step'][sid]\n",
    "        return actions\n",
    "                    \n",
    "    def getdestroyval(self, item):\n",
    "        actions = []\n",
    "        for sid, step in enumerate(item['steps']):\n",
    "            o = 0\n",
    "            c = 0\n",
    "            d = 0\n",
    "            if sid == 0:\n",
    "                prev_state = item['entity_step'][sid]\n",
    "                continue\n",
    "            else:\n",
    "                o += (prev_state[0] * item['entity_step'][sid][0])\n",
    "                o += (prev_state[0] * item['entity_step'][sid][1])\n",
    "                o += (prev_state[1] * item['entity_step'][sid][0])\n",
    "                o += (prev_state[1] * item['entity_step'][sid][1])\n",
    "                o += (prev_state[2] * item['entity_step'][sid][2])\n",
    "                d += (prev_state[0] * item['entity_step'][sid][2])\n",
    "                d += (prev_state[1] * item['entity_step'][sid][2])\n",
    "                c += (prev_state[2] * item['entity_step'][sid][1])\n",
    "                c += (prev_state[2] * item['entity_step'][sid][0])\n",
    "                actions.append([1-d, d])\n",
    "                prev_state = item['entity_step'][sid]\n",
    "        return actions\n",
    "    \n",
    "    def getotherval(self, item):\n",
    "        actions = []\n",
    "        for sid, step in enumerate(item['steps']):\n",
    "            o = 0\n",
    "            c = 0\n",
    "            d = 0\n",
    "            if sid == 0:\n",
    "                prev_state = item['entity_step'][sid]\n",
    "                continue\n",
    "            else:\n",
    "                o += (prev_state[0] * item['entity_step'][sid][0])\n",
    "                o += (prev_state[0] * item['entity_step'][sid][1])\n",
    "                o += (prev_state[1] * item['entity_step'][sid][0])\n",
    "                o += (prev_state[1] * item['entity_step'][sid][1])\n",
    "                o += (prev_state[2] * item['entity_step'][sid][2])\n",
    "                d += (prev_state[0] * item['entity_step'][sid][2])\n",
    "                d += (prev_state[1] * item['entity_step'][sid][2])\n",
    "                c += (prev_state[2] * item['entity_step'][sid][1])\n",
    "                c += (prev_state[2] * item['entity_step'][sid][0])\n",
    "                actions.append([1-o, o])\n",
    "                prev_state = item['entity_step'][sid]\n",
    "        return actions\n",
    "    \n",
    "    def getbeforeval(self, item):\n",
    "        b1s = []\n",
    "        b2s = []\n",
    "        for step in range(len(item['steps']) + 1):\n",
    "            b1 = torch.zeros(len(item['steps']) + 1)\n",
    "            b1[step] = 1\n",
    "            for step1 in range(len(item['steps']) + 1):\n",
    "                b2 = torch.zeros(len(item['steps']) + 1)\n",
    "                b2[step1] = 1\n",
    "                b1s.append(b1)\n",
    "                b2s.append(b2)\n",
    "        return torch.stack(b1s), torch.stack(b2s)\n",
    "    \n",
    "    def getbefore_trueval(self, item):\n",
    "        num_steps = len(item['steps']) + 1\n",
    "        values = torch.zeros(num_steps * num_steps)\n",
    "        for step in range(len(item['steps']) + 1):\n",
    "            for step1 in range(step + 1, len(item['steps']) + 1):\n",
    "                values[(step*num_steps)+step1] = 1\n",
    "        return values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': (tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.]]),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.]]),\n",
       "  tensor([0., 0., 0., 0., 0., 0.])),\n",
       " 'before_true': tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "         1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'before': (tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.]]),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.]])),\n",
       " 'create': [[0.9999638869012587, 3.6113098741282564e-05],\n",
       "  [0.9916881003214273, 0.008311899678572682],\n",
       "  [0.995401471146531, 0.004598528853469036],\n",
       "  [0.9958117052756262, 0.004188294724373799],\n",
       "  [0.9956692122445809, 0.004330787755419119]],\n",
       " 'destroy': [[0.017410671153128776, 0.9825893288468712],\n",
       "  [0.9850803377253793, 0.014919662274620674],\n",
       "  [0.9916002595678794, 0.008399740432120509],\n",
       "  [0.9953818490178498, 0.0046181509821502376],\n",
       "  [0.9958104908779757, 0.004189509122024364]],\n",
       " 'entities': ['plant; animal'],\n",
       " 'known': tensor([[0.0317, 0.9683],\n",
       "         [0.9877, 0.0123],\n",
       "         [0.9939, 0.0061],\n",
       "         [0.9976, 0.0024],\n",
       "         [0.9984, 0.0016],\n",
       "         [0.9985, 0.0015],\n",
       "         [0.9984, 0.0016]]),\n",
       " 'non_existence': tensor([[0.9976, 0.0024],\n",
       "         [0.0150, 0.9850],\n",
       "         [0.0084, 0.9916],\n",
       "         [0.0046, 0.9954],\n",
       "         [0.0042, 0.9958],\n",
       "         [0.0043, 0.9957],\n",
       "         [0.0049, 0.9951]]),\n",
       " 'other': [[0.9826255096993305, 0.017374490300669513],\n",
       "  [0.02323164670354705, 0.976768353296453],\n",
       "  [0.012998270449742777, 0.9870017295502572],\n",
       "  [0.0088064791177217, 0.9911935208822783],\n",
       "  [0.008520302116134415, 0.9914796978838656]],\n",
       " 'procedureID': ['37'],\n",
       " 'steps': (tensor([[1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.]]),\n",
       "  ['step 0 information',\n",
       "   'A plant of animal dies in a watery environment.',\n",
       "   'Is buried in mud and silt.',\n",
       "   'Soft tissues quickly decompose leaving behind hard bones or shells.',\n",
       "   'Over time sediment builds over the top and hardens into rock.',\n",
       "   'As the bone decays mineral seeps in replacing it.',\n",
       "   'Fossils are formed.']),\n",
       " 'unkown': tensor([[0.9707, 0.0293],\n",
       "         [0.9972, 0.0028],\n",
       "         [0.9976, 0.0024],\n",
       "         [0.9978, 0.0022],\n",
       "         [0.9974, 0.0026],\n",
       "         [0.9972, 0.0028],\n",
       "         [0.9968, 0.0032]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReaderObjectsIterator = ProparaReader(\"updated_test_data.json\")\n",
    "next(iter(ReaderObjectsIterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file for dataNode is in: /home/hfaghihi/Framework/DomiKnowS/examples/Propara/datanode.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('arg1', 'step'), ('arg2', 'step')]) is used.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('arg1', 'step'), ('arg2', 'step')]) is used.\n"
     ]
    }
   ],
   "source": [
    "from regr.graph import Graph, Concept, Relation\n",
    "from regr.graph.logicalConstrain import orL, andL, existsL, notL, atLeastL, atMostL, ifL, nandL, eqL\n",
    "\n",
    "Graph.clear()\n",
    "Concept.clear()\n",
    "Relation.clear()\n",
    "\n",
    "with Graph('global') as graph:\n",
    "    procedure = Concept(\"procedure\")\n",
    "    step = Concept(\"step\")\n",
    "    (procedure_contain_step, ) = procedure.contains(step)\n",
    "#     entity = Concept(\"entity\")\n",
    "    non_existence = step(\"non_existence\")\n",
    "    unknown_loc = step(\"unknown_location\")\n",
    "    known_loc = step(\"known_location\")\n",
    "    before = Concept(\"before\")\n",
    "    (before_arg1, before_arg2) = before.has_a(arg1=step, arg2=step)\n",
    "    action = Concept(\"action\")\n",
    "    (action_arg1, action_arg2) = action.has_a(arg1=step, arg2=step)\n",
    "    create = action(name=\"create\")\n",
    "    destroy = action(name=\"destroy\")\n",
    "    other = action(name=\"other\")\n",
    "\n",
    "    #LC1 : An action can not be create, destroy and other at the same time\n",
    "    nandL(create, destroy, other)\n",
    "    \n",
    "    #LC2 : An action should at least be one of the create, destroy or other\n",
    "    #Don't know how to write LC2\n",
    "    \n",
    "    #LC3 : A step can not be known_loc, unknown_loc and non_existence at the same time\n",
    "    nandL(known_loc, unknown_loc, non_existence)\n",
    "    \n",
    "    #LC4 : A step should at least be one of known_loc, unknown_loc or non_existence\n",
    "    #Don't know how to write LC4\n",
    "    \n",
    "    #LC5 : If action is create then the first step should be non_existence and the second step can be either known_loc or unknown_loc\n",
    "    ifL(create, (\"x\", \"y\", ), andL(non_existence, (\"x\", ), orL(known_loc, (\"y\", ), unknown_loc, (\"y\", ))))\n",
    "    \n",
    "    #LC 6 : If action is destroy, then first step should be either known_loc,or unknown_loc and the next step should be non_existence \n",
    "    ifL(destroy, (\"x\", \"y\", ), andL(orL(known_loc, (\"x\", ), unknown_loc, (\"x\", )), non_existence, (\"y\", )))\n",
    "    \n",
    "    #LC7 : There should be at most 1 create\n",
    "    atMostL(1, (\"x\", ), create, (\"x\", ))\n",
    "    \n",
    "    #LC8 : There should be at most one destroy\n",
    "    atMostL(1, (\"x\", ), destroy, (\"x\", ))\n",
    "    \n",
    "    #LC9 : If (x1,x2) is create and (y1, y2) is destroy, then the pair(x2,y2) if before should have the property \"check\" equal to 1.\n",
    "    ifL(andL(create, (\"x1\", \"x2\", ), destroy, (\"y1\", \"y2\", )), eqL(before, \"check\", 1), (\"x2\", \"y2\", ))\n",
    "    \n",
    "    # No entity_step\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.sensor.pytorch.sensors import ReaderSensor, JointSensor\n",
    "from regr.sensor.pytorch.relation_sensors import EdgeSensor\n",
    "\n",
    "class EdgeReaderSensor(EdgeSensor, ReaderSensor):\n",
    "    def __init__(self, *pres, relation, mode=\"forward\", keyword=None, **kwargs):\n",
    "        super().__init__(*pres, relation=relation, mode=mode, **kwargs)\n",
    "        self.keyword = keyword\n",
    "        self.data = None\n",
    "        \n",
    "class JoinReaderSensor(JointSensor, ReaderSensor):\n",
    "    pass\n",
    "            \n",
    "class JoinEdgeReaderSensor(JointSensor, EdgeReaderSensor):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.sensor.pytorch.sensors import ReaderSensor\n",
    "from regr.program import LearningBasedProgram\n",
    "from regr.program.model.pytorch import PoiModel\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def model_declaration():\n",
    "\n",
    "    graph.detach()\n",
    "\n",
    "    # --- City\n",
    "    procedure['id'] = ReaderSensor(keyword='procedureID')\n",
    "    step[procedure_contain_step.forward, 'text'] = JoinEdgeReaderSensor(procedure['id'], keyword='steps', relation=procedure_contain_step, mode=\"forward\")\n",
    "    # word[step_contains_word, 'raw'] = ReaderSensor(keyword='words')\n",
    "#     entity['raw'] = ReaderSensor(keyword='entities')\n",
    "\n",
    "    step[non_existence] = ReaderSensor(procedure_contain_step.forward, 'text', keyword='non_existence')\n",
    "    step[unknown_loc] = ReaderSensor(procedure_contain_step.forward, 'text', keyword='known')\n",
    "    step[known_loc] = ReaderSensor(procedure_contain_step.forward, 'text', keyword='unkown')\n",
    "    \n",
    "    step[non_existence] = ReaderSensor(procedure_contain_step.forward, 'text', keyword='non_existence')\n",
    "    step[unknown_loc] = ReaderSensor(procedure_contain_step.forward, 'text', keyword='known')\n",
    "    step[known_loc] = ReaderSensor(procedure_contain_step.forward, 'text', keyword='unkown')\n",
    "    \n",
    "    action[action_arg1.forward, action_arg2.forward, 'raw'] = JoinReaderSensor(step['text'], keyword='action')\n",
    "    \n",
    "    action[create] = ReaderSensor(action_arg1.forward, action_arg2.forward, 'raw', keyword='create')\n",
    "    action[destroy] = ReaderSensor(action_arg1.forward, action_arg2.forward, 'raw', keyword='destroy')\n",
    "    action[other] = ReaderSensor(action_arg1.forward, action_arg2.forward, 'raw', keyword='other')\n",
    "    \n",
    "    action[create] = ReaderSensor(keyword='create')\n",
    "    action[destroy] = ReaderSensor(keyword='destroy')\n",
    "    action[other] = ReaderSensor(keyword='other')\n",
    "    \n",
    "    before[before_arg1.forward, before_arg2.forward] = JoinReaderSensor(step['text'], keyword=\"before\")\n",
    "    \n",
    "    before[\"check\"] = ReaderSensor(before_arg1.forward, before_arg2.forward, keyword=\"before_true\")\n",
    "    before[\"check\"] = ReaderSensor(before_arg1.forward, before_arg2.forward, keyword=\"before_true\")\n",
    "    \n",
    "    program = LearningBasedProgram(graph, **{\n",
    "        'Model': PoiModel,\n",
    "#         'poi': (known_loc, unknown_loc, non_existence, other, destroy, create),\n",
    "        'loss': None,\n",
    "        'metric': None,\n",
    "    })\n",
    "    return program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # set logger level to see training and testing logs\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    lbp = model_declaration()\n",
    "\n",
    "    dataset = ProparaReader(file='updated_test_data.json')  # Adding the info on the reader\n",
    "\n",
    "#     lbp.test(dataset, device='auto')\n",
    "\n",
    "    for datanode in lbp.populate(dataset, device=\"cpu\"):\n",
    "        print('datanode:', datanode)\n",
    "        data1 = datanode.findDatanodes(select = step)[0].getAttribute(\"text\")\n",
    "        print(data1)\n",
    "        data1 = datanode.findDatanodes(select = step)[0].getAttribute(non_existence)\n",
    "        print(data1)\n",
    "        data1 = datanode.findDatanodes(select = action)[0].getAttribute(\"check\")\n",
    "        print(data1)\n",
    "#         datanode.inferILPConstrains(create, destroy, other, non_existence, known_loc, unknown_loc, fun=None)\n",
    "#         print('datanode:', datanode)\n",
    "#         print('inference spam:', datanode.getAttribute(Spam, 'ILP'))\n",
    "#         print('inference regular:', datanode.getAttribute(Regular, 'ILP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datanode: procedure 0\n",
      "step 0 information\n",
      "tensor([0.9976, 0.0024])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-5332d7bb219e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatanode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindDatanodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAttribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_existence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatanode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindDatanodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAttribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"check\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#         datanode.inferILPConstrains(create, destroy, other, non_existence, known_loc, unknown_loc, fun=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.graph import DataNodeBuilder\n",
    "from regr.sensor.sensor import Sensor\n",
    "\n",
    "dataset = ProparaReader(file='updated_test_data.json')\n",
    "context = {\"graph\": graph}\n",
    "context.update(next(iter(dataset)))\n",
    "data_item = DataNodeBuilder(context)\n",
    "data_item\n",
    "for sensor in action['raw'].find(Sensor):\n",
    "    sensor(data_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'graph': Graph(name='global', fullname='global'),\n",
       " 'action': (tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.]]),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.]]),\n",
       "  tensor([0., 0., 0., 0., 0., 0.])),\n",
       " 'before_true': tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "         1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'before': (tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.]]),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.]])),\n",
       " 'create': [[0.9999638869012587, 3.6113098741282564e-05],\n",
       "  [0.9916881003214273, 0.008311899678572682],\n",
       "  [0.995401471146531, 0.004598528853469036],\n",
       "  [0.9958117052756262, 0.004188294724373799],\n",
       "  [0.9956692122445809, 0.004330787755419119]],\n",
       " 'destroy': [[0.017410671153128776, 0.9825893288468712],\n",
       "  [0.9850803377253793, 0.014919662274620674],\n",
       "  [0.9916002595678794, 0.008399740432120509],\n",
       "  [0.9953818490178498, 0.0046181509821502376],\n",
       "  [0.9958104908779757, 0.004189509122024364]],\n",
       " 'entities': ['plant; animal'],\n",
       " 'known': tensor([[0.0317, 0.9683],\n",
       "         [0.9877, 0.0123],\n",
       "         [0.9939, 0.0061],\n",
       "         [0.9976, 0.0024],\n",
       "         [0.9984, 0.0016],\n",
       "         [0.9985, 0.0015],\n",
       "         [0.9984, 0.0016]]),\n",
       " 'non_existence': tensor([[0.9976, 0.0024],\n",
       "         [0.0150, 0.9850],\n",
       "         [0.0084, 0.9916],\n",
       "         [0.0046, 0.9954],\n",
       "         [0.0042, 0.9958],\n",
       "         [0.0043, 0.9957],\n",
       "         [0.0049, 0.9951]]),\n",
       " 'other': [[0.9826255096993305, 0.017374490300669513],\n",
       "  [0.02323164670354705, 0.976768353296453],\n",
       "  [0.012998270449742777, 0.9870017295502572],\n",
       "  [0.0088064791177217, 0.9911935208822783],\n",
       "  [0.008520302116134415, 0.9914796978838656]],\n",
       " 'procedureID': ['37'],\n",
       " 'steps': (tensor([[1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.]]),\n",
       "  ['step 0 information',\n",
       "   'A plant of animal dies in a watery environment.',\n",
       "   'Is buried in mud and silt.',\n",
       "   'Soft tissues quickly decompose leaving behind hard bones or shells.',\n",
       "   'Over time sediment builds over the top and hardens into rock.',\n",
       "   'As the bone decays mineral seeps in replacing it.',\n",
       "   'Fossils are formed.']),\n",
       " 'unkown': tensor([[0.9707, 0.0293],\n",
       "         [0.9972, 0.0028],\n",
       "         [0.9976, 0.0024],\n",
       "         [0.9978, 0.0022],\n",
       "         [0.9974, 0.0026],\n",
       "         [0.9972, 0.0028],\n",
       "         [0.9968, 0.0032]]),\n",
       " 'Counter_setitem': 8,\n",
       " 'Counter/global/procedure/id/readersensor': {('37',): {'counter': 1,\n",
       "   'recent': True}},\n",
       " 'dataNode': [procedure 0],\n",
       " 'global/procedure/index': [procedure 0],\n",
       " ReaderSensor(name='readersensor', fullname='global/procedure/id/readersensor'): ['37'],\n",
       " 'DataNodeTime': 0.0023179054260253906,\n",
       " Property(name='id', fullname='global/procedure/id'): ['37'],\n",
       " JoinEdgeReaderSensor(name='joinedgereadersensor', fullname='global/step/(Contains(name='procedure-contains-0-step', fullname='global/procedure-contains-0-step').forward, 'text')/joinedgereadersensor'): (tensor([[1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.]]),\n",
       "  ['step 0 information',\n",
       "   'A plant of animal dies in a watery environment.',\n",
       "   'Is buried in mud and silt.',\n",
       "   'Soft tissues quickly decompose leaving behind hard bones or shells.',\n",
       "   'Over time sediment builds over the top and hardens into rock.',\n",
       "   'As the bone decays mineral seeps in replacing it.',\n",
       "   'Fossils are formed.']),\n",
       " 'Counter/global/step/text/functionalsensor': {('step 0 information',\n",
       "   'A plant of animal dies in a watery environment.',\n",
       "   'Is buried in mud and silt.',\n",
       "   'Soft tissues quickly decompose leaving behind hard bones or shells.',\n",
       "   'Over time sediment builds over the top and hardens into rock.',\n",
       "   'As the bone decays mineral seeps in replacing it.',\n",
       "   'Fossils are formed.'): {'counter': 1, 'recent': True}},\n",
       " FunctionalSensor(name='functionalsensor', fullname='global/step/text/functionalsensor'): ['step 0 information',\n",
       "  'A plant of animal dies in a watery environment.',\n",
       "  'Is buried in mud and silt.',\n",
       "  'Soft tissues quickly decompose leaving behind hard bones or shells.',\n",
       "  'Over time sediment builds over the top and hardens into rock.',\n",
       "  'As the bone decays mineral seeps in replacing it.',\n",
       "  'Fossils are formed.'],\n",
       " Property(name='text', fullname='global/step/text'): ['step 0 information',\n",
       "  'A plant of animal dies in a watery environment.',\n",
       "  'Is buried in mud and silt.',\n",
       "  'Soft tissues quickly decompose leaving behind hard bones or shells.',\n",
       "  'Over time sediment builds over the top and hardens into rock.',\n",
       "  'As the bone decays mineral seeps in replacing it.',\n",
       "  'Fossils are formed.'],\n",
       " JoinReaderSensor(name='joinreadersensor', fullname='global/action/(HasA(name='arg1-1', fullname='global/arg1-1').forward, HasA(name='arg2-1', fullname='global/arg2-1').forward, 'raw')/joinreadersensor'): (tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.]]),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.]]),\n",
       "  tensor([0., 0., 0., 0., 0., 0.])),\n",
       " 'Counter/global/action/raw/functionalsensor-1': {tensor([0., 0., 0., 0., 0., 0.]): {'counter': 1,\n",
       "   'recent': True}},\n",
       " FunctionalSensor(name='functionalsensor-1', fullname='global/action/raw/functionalsensor-1'): tensor([0., 0., 0., 0., 0., 0.]),\n",
       " Property(name='raw', fullname='global/action/raw'): tensor([0., 0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
