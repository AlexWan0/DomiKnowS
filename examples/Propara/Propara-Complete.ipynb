{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "# Please change the root to an absolute or relative path to DomiKnowS root.\n",
    "# In case relative path is used, consider the printed `CWD` as current working directory.\n",
    "root = '/home/hfaghihi/Framework/DomiKnowS'\n",
    "import sys\n",
    "sys.path.append(root)\n",
    "from typing import Any, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"updated_test_data.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.data.reader import RegrReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProparaReader(RegrReader):\n",
    "    def parse_file(self):\n",
    "        with open(self.file, 'r') as f:\n",
    "            lines = []\n",
    "            for line in f:\n",
    "                try:\n",
    "                    if line != \"\\n\":\n",
    "                        lines.append(json.loads(str(line)))\n",
    "                except:\n",
    "                    raise\n",
    "        items = lines\n",
    "        final_dict = []\n",
    "        for item in items:\n",
    "            for i in range(len(item['participants'])):\n",
    "                instance = item.copy()\n",
    "                instance['participants'] = [item['participants'][i]]\n",
    "                instance['states'] = item['states'][i]\n",
    "                final_dict.append(instance)\n",
    "                \n",
    "        return final_dict\n",
    "    \n",
    "#     def getDataval(self, item):\n",
    "#         return item\n",
    "                \n",
    "    def getParaIDval(self, item):\n",
    "        return [item['para_id']]\n",
    "    \n",
    "    def getSentencesval(self, item):\n",
    "        data = ['step 0 goes here']\n",
    "        data.extend(item['sentence_texts'])\n",
    "        return data\n",
    "    \n",
    "    def getEntityval(self, item):\n",
    "        return item['participants']\n",
    "    \n",
    "    def getnon_existenceval(self, item):\n",
    "        values = []\n",
    "        for value in item['states']:\n",
    "            if value == \"-\":\n",
    "                values.append(1)\n",
    "            else:\n",
    "                values.append(0)\n",
    "        return values\n",
    "    \n",
    "    def getunknownval(self, item):\n",
    "        values = []\n",
    "        for value in item['states']:\n",
    "            if value == \"?\":\n",
    "                values.append(1)\n",
    "            else:\n",
    "                values.append(0)\n",
    "        return values\n",
    "    \n",
    "    def getlocationval(self, item):\n",
    "        values = []\n",
    "        for value in item['states']:\n",
    "            if value != \"?\" and value != \"-\":\n",
    "                values.append(1)\n",
    "            else:\n",
    "                values.append(0)\n",
    "        return values\n",
    "    \n",
    "    def getLocationTextval(self, item):\n",
    "        values = []\n",
    "        for value in item['states']:\n",
    "            if value != \"?\" and value != \"-\":\n",
    "                values.append(value)\n",
    "            else:\n",
    "                values.append(\"NAN\")\n",
    "        return values\n",
    "    \n",
    "    \n",
    "    \n",
    "#     def getstepsval(self, item):\n",
    "#         num_steps = len(item['steps']) + 1\n",
    "#         rel = torch.ones(num_steps,1)\n",
    "#         sentences = [\"step 0 information\"]\n",
    "#         sentences.extend(item['steps'])\n",
    "#         return rel, sentences\n",
    "    \n",
    "#     def getnon_existenceval(self, item):\n",
    "#         values = []\n",
    "#         for step in range(len(item['steps']) + 1):\n",
    "#             values.append([1 - item['entity_step'][step][2], item['entity_step'][step][2]])\n",
    "#         return torch.tensor(values)\n",
    "            \n",
    "#     def getknownval(self, item):\n",
    "#         values = []\n",
    "#         for step in range(len(item['steps']) + 1):\n",
    "#             values.append([1 - item['entity_step'][step][0], item['entity_step'][step][0]])\n",
    "#         return torch.tensor(values)\n",
    "    \n",
    "#     def getunknownval(self, item):\n",
    "#         values = []\n",
    "#         for step in range(len(item['steps']) + 1):\n",
    "#             values.append([1 - item['entity_step'][step][1], item['entity_step'][step][1]])\n",
    "#         return torch.tensor(values)\n",
    "    \n",
    "#     def getactionval(self, item):\n",
    "#         action1s = torch.diag(torch.ones(len(item['steps']) + 1) )[:-1]\n",
    "#         action2s = torch.diag(torch.ones(len(item['steps']) + 1) )[1:]\n",
    "#         raw = torch.zeros(len(item['steps']))\n",
    "#         return action1s, action2s\n",
    "    \n",
    "#     def getcreateval(self, item):\n",
    "#         actions = []\n",
    "#         prev_state = item['entity_step'][0]\n",
    "#         for sid, step in enumerate(item['steps']):\n",
    "#             o = 0\n",
    "#             c = 0\n",
    "#             d = 0\n",
    "#             o += (prev_state[0] * item['entity_step'][sid+1][0])\n",
    "#             o += (prev_state[0] * item['entity_step'][sid+1][1])\n",
    "#             o += (prev_state[1] * item['entity_step'][sid+1][0])\n",
    "#             o += (prev_state[1] * item['entity_step'][sid+1][1])\n",
    "#             o += (prev_state[2] * item['entity_step'][sid+1][2])\n",
    "#             d += (prev_state[0] * item['entity_step'][sid+1][2])\n",
    "#             d += (prev_state[1] * item['entity_step'][sid+1][2])\n",
    "#             c += (prev_state[2] * item['entity_step'][sid+1][1])\n",
    "#             c += (prev_state[2] * item['entity_step'][sid+1][0])\n",
    "#             actions.append([1-c, c])\n",
    "#             prev_state = item['entity_step'][sid+1]\n",
    "        \n",
    "#         return torch.tensor(actions)\n",
    "                    \n",
    "#     def getdestroyval(self, item):\n",
    "#         actions = []\n",
    "#         prev_state = item['entity_step'][0]\n",
    "#         for sid, step in enumerate(item['steps']):\n",
    "#             o = 0\n",
    "#             c = 0\n",
    "#             d = 0\n",
    "#             o += (prev_state[0] * item['entity_step'][sid+1][0])\n",
    "#             o += (prev_state[0] * item['entity_step'][sid+1][1])\n",
    "#             o += (prev_state[1] * item['entity_step'][sid+1][0])\n",
    "#             o += (prev_state[1] * item['entity_step'][sid+1][1])\n",
    "#             o += (prev_state[2] * item['entity_step'][sid+1][2])\n",
    "#             d += (prev_state[0] * item['entity_step'][sid+1][2])\n",
    "#             d += (prev_state[1] * item['entity_step'][sid+1][2])\n",
    "#             c += (prev_state[2] * item['entity_step'][sid+1][1])\n",
    "#             c += (prev_state[2] * item['entity_step'][sid+1][0])\n",
    "#             actions.append([1-d, d])\n",
    "#             prev_state = item['entity_step'][sid+1]\n",
    "#         return torch.tensor(actions)\n",
    "    \n",
    "#     def getotherval(self, item):\n",
    "#         actions = []\n",
    "#         prev_state = item['entity_step'][0]\n",
    "#         for sid, step in enumerate(item['steps']):\n",
    "#             o = 0\n",
    "#             c = 0\n",
    "#             d = 0\n",
    "#             o += (prev_state[0] * item['entity_step'][sid+1][0])\n",
    "#             o += (prev_state[0] * item['entity_step'][sid+1][1])\n",
    "#             o += (prev_state[1] * item['entity_step'][sid+1][0])\n",
    "#             o += (prev_state[1] * item['entity_step'][sid+1][1])\n",
    "#             o += (prev_state[2] * item['entity_step'][sid+1][2])\n",
    "#             d += (prev_state[0] * item['entity_step'][sid+1][2])\n",
    "#             d += (prev_state[1] * item['entity_step'][sid+1][2])\n",
    "#             c += (prev_state[2] * item['entity_step'][sid+1][1])\n",
    "#             c += (prev_state[2] * item['entity_step'][sid+1][0])\n",
    "#             actions.append([1-o, o])\n",
    "#             prev_state = item['entity_step'][sid+1]\n",
    "#         return torch.tensor(actions)\n",
    "    \n",
    "    def getbeforeval(self, item):\n",
    "        b1s = []\n",
    "        b2s = []\n",
    "        for step in range(len(item['states']) + 1):\n",
    "            b1 = torch.zeros(len(item['states']) + 1)\n",
    "            b1[step] = 1\n",
    "            for step1 in range(len(item['states']) + 1):\n",
    "                b2 = torch.zeros(len(item['states']) + 1)\n",
    "                b2[step1] = 1\n",
    "                b1s.append(b1)\n",
    "                b2s.append(b2)\n",
    "        return torch.stack(b1s), torch.stack(b2s)\n",
    "    \n",
    "    def getbefore_trueval(self, item):\n",
    "        num_steps = len(item['states']) + 1\n",
    "        values = torch.zeros(num_steps * num_steps)\n",
    "        for step in range(len(item['states']) + 1):\n",
    "            for step1 in range(step + 1, len(item['states']) + 1):\n",
    "                values[(step*num_steps)+step1] = 1\n",
    "        return values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReaderObjectsIterator = ProparaReader(\"emnlp18/grids.v1.train.json\", 'parse')\n",
    "list(iter(ReaderObjectsIterator))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.graph import Graph, Concept, Relation\n",
    "from regr.graph.logicalConstrain import orL, andL, existsL, notL, atLeastL, atMostL, ifL, nandL, eqL\n",
    "\n",
    "Graph.clear()\n",
    "Concept.clear()\n",
    "Relation.clear()\n",
    "\n",
    "with Graph('global') as graph:\n",
    "    procedure = Concept(\"procedure\")\n",
    "    text = Concept(\"text\")\n",
    "    entity = Concept(\"entity\")\n",
    "    (procedure_text, procedure_entity) = procedure.has_a(arg1=text, arg2=entity)\n",
    "    step = Concept(\"step\")\n",
    "    (text_contain_step, ) = text.contains(step)\n",
    "    \n",
    "    pair = Concept(\"pair\")\n",
    "    (pair_entity, pair_step) = pair.has_a(entity, step)\n",
    "    \n",
    "    word = Concept(\"word\")\n",
    "    (pair_contains_words, ) = pair.contains(word)\n",
    "    \n",
    "    word1 = Concept(\"word1\")\n",
    "    \n",
    "    non_existence = pair(\"non_existence\")\n",
    "    unknown_loc = pair(\"unknown_location\")\n",
    "    known_loc = pair(\"known_location\")\n",
    "    \n",
    "    triplet = Concept(\"triplet\")\n",
    "    (triplet_entity, triplet_step, triplet_word) = triplet.has_a(entity, step, word)\n",
    "    \n",
    "    before = Concept(\"before\")\n",
    "    (before_arg1, before_arg2) = before.has_a(arg1=step, arg2=step)\n",
    "    \n",
    "#     action = Concept(\"action\")\n",
    "#     (action_arg1, action_arg2) = action.has_a(arg1=step, arg2=step)\n",
    "#     create = action(name=\"create\")\n",
    "#     destroy = action(name=\"destroy\")\n",
    "#     other = action(name=\"other\")\n",
    "    \n",
    "    #LC5 : If action is create then the first step should be non_existence and the second step can be either known_loc or unknown_loc\n",
    "#     ifL(create, (\"x\", \"y\", ), andL(non_existence, (\"x\", ), orL(known_loc, (\"y\", ), unknown_loc, (\"y\", ))))\n",
    "    \n",
    "#     #LC 6 : If action is destroy, then first step should be either known_loc,or unknown_loc and the next step should be non_existence \n",
    "#     ifL(destroy, (\"x\", \"y\", ), andL(orL(known_loc, (\"x\", ), unknown_loc, (\"x\", )), non_existence, (\"y\", )))\n",
    "    \n",
    "#     #LC7 : There should be at most 1 create\n",
    "#     atMostL(1, (\"x\", ), create, (\"x\", ))\n",
    "    \n",
    "#     #LC8 : There should be at most one destroy\n",
    "#     atMostL(1, (\"x\", ), destroy, (\"x\", ))\n",
    "    \n",
    "#     #LC9 : If (x1,x2) is create and (y1, y2) is destroy, then the pair(x2,y2) in before should have the property \"check\" equal to 1.\n",
    "#     # I will have to check if this eqL works if not will update it\n",
    "#     ifL(andL(create, (\"x1\", \"x2\"), destroy, (\"y1\", \"y2\")), eqL(before, \"check\", 1), (\"x2\", \"y2\"))\n",
    "    \n",
    "#     #LC1 : An action can not be create, destroy and other at the same time\n",
    "#     nandL(create, destroy, other)\n",
    "    \n",
    "#     #LC2 : An action should at least be one of the create, destroy or other\n",
    "#     orL(create, destroy, other)\n",
    "    \n",
    "#     #LC3 : A step can not be known_loc, unknown_loc and non_existence at the same time\n",
    "#     nandL(known_loc, unknown_loc, non_existence)\n",
    "    \n",
    "#     #LC4 : A step should at least be one of known_loc, unknown_loc or non_existence\n",
    "#     orL(known_loc, unknown_loc, non_existence)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.sensor.pytorch.sensors import ReaderSensor, JointSensor\n",
    "from regr.sensor.pytorch.relation_sensors import EdgeSensor\n",
    "\n",
    "class EdgeReaderSensor(EdgeSensor, ReaderSensor):\n",
    "    def __init__(self, *pres, relation, mode=\"forward\", keyword=None, **kwargs):\n",
    "        super().__init__(*pres, relation=relation, mode=mode, **kwargs)\n",
    "        self.keyword = keyword\n",
    "        self.data = None\n",
    "        \n",
    "# class JoinReaderSensor(JointSensor, ReaderSensor):\n",
    "#     pass\n",
    "            \n",
    "# class JoinEdgeReaderSensor(JointSensor, EdgeReaderSensor):\n",
    "#     pass\n",
    "\n",
    "class JoinReaderSensor(JointSensor, ReaderSensor):\n",
    "    pass\n",
    "\n",
    "class JoinEdgeReaderSensor(JoinReaderSensor, EdgeSensor):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.sensor.pytorch.sensors import ReaderSensor, FunctionalSensor, JointSensor\n",
    "from regr.sensor.pytorch.learners import TorchLearner, ModuleLearner\n",
    "from regr.program import LearningBasedProgram\n",
    "from regr.program.model.pytorch import PoiModel\n",
    "import torch\n",
    "from torch import nn\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "def model_declaration():\n",
    "\n",
    "    graph.detach()\n",
    "\n",
    "    procedure['id'] = ReaderSensor(keyword='ParaID')\n",
    "    entity['raw'] = ReaderSensor(keyword='Entity')\n",
    "    text['raw'] = ReaderSensor(keyword=\"Sentences\")\n",
    "    word1['raw'] = ReaderSensor(keyword=\"LocationText\")\n",
    "    \n",
    "    def sentence_parser(text):\n",
    "        sentence = \"\"\n",
    "        for item in text[1:-1]:\n",
    "            sentence += str(item) + \" </s> \"\n",
    "        sentence += str(text[-1])\n",
    "        return [sentence]\n",
    "    \n",
    "    text['ready'] = FunctionalSensor(text['raw'], forward=sentence_parser)\n",
    "    \n",
    "    def boundary_finder(*inputs):\n",
    "        import re\n",
    "        output = []\n",
    "        for sentences in inputs[0]:\n",
    "            boundaries = []\n",
    "            start = 0\n",
    "            for m in re.finditer('/s'.lower(), sentences.lower()):\n",
    "                boundaries.append((start, m.start()-2))\n",
    "                start = m.end() + 2\n",
    "            boundaries.append((start, len(sentences)))\n",
    "            output.append(boundaries)\n",
    "        return output\n",
    "            \n",
    "        \n",
    "    text['boundaries'] = FunctionalSensor(text['ready'], forward=boundary_finder)\n",
    "    \n",
    "    def find_spans(*inputs):\n",
    "        import re\n",
    "        import inflect\n",
    "        engine = inflect.engine()\n",
    "        sentences = inputs[1][0]\n",
    "        boundaries = inputs[2][0]\n",
    "        prev_loc = \"\"\n",
    "        annotations = []\n",
    "        for time, loc in enumerate(inputs[0]):\n",
    "#             print(\"searching for: \", time, loc)\n",
    "            if \"'\" in loc:\n",
    "                loc = loc.replace(\" '\", \"'\")\n",
    "            all_loc = []\n",
    "            final_loc = (0, 0)\n",
    "            if loc == \"NAN\":\n",
    "                loc = \"-\"\n",
    "            elif loc != \"NAN\":\n",
    "                if loc == prev_loc:\n",
    "                    final_loc = annotations[-1][1]\n",
    "                    annotations.append((loc, final_loc))\n",
    "                    prev_loc = loc\n",
    "                    continue\n",
    "                for m in re.finditer(\" \" + loc.lower(), sentences.lower()):\n",
    "                    start = m.start()\n",
    "                    if sentences[m.start()] == \" \":\n",
    "                        start = m.start() + 1\n",
    "                    all_loc.append((start, m.end()))\n",
    "\n",
    "                if len(all_loc) == 0:\n",
    "                    for m in re.finditer(loc.lower(), sentences.lower()):\n",
    "                        start = m.start()\n",
    "                        if sentences[m.start()] == \" \":\n",
    "                            start = m.start() + 1\n",
    "                        all_loc.append((start, m.end()))\n",
    "#                 if len(all_loc) == 0:\n",
    "#                     final_loc = final_loc\n",
    "                if len(all_loc) == 0 and \"recycle\" in loc:\n",
    "                    for m in re.finditer(\" \" + loc.replace(\"recycle\", \"recycling\").lower(), sentences.lower()):\n",
    "                        start = m.start()\n",
    "                        if sentences[m.start()] == \" \":\n",
    "                            start = m.start() + 1\n",
    "                        all_loc.append((start, m.end()))\n",
    "                if len(all_loc) == 0:\n",
    "                    if loc == \"alveolus\":\n",
    "                        loc = \"alveoli\"\n",
    "                    if loc == \"sew machine\":\n",
    "                        loc = \"machine\"\n",
    "                    if loc == \"cool tower\":\n",
    "                        loc = \"cooling tower\"\n",
    "                    if loc == \"cart or on a conveyor belt\":\n",
    "                        loc = \"carts or on a conveyor belt\"\n",
    "                    if loc == \"bee leg\":\n",
    "                        loc = \"bees legs\"\n",
    "                    if loc == \"bottom of river and ocean\":\n",
    "                        loc = \"bottom of rivers and oceans\"\n",
    "                    if loc == \"body of water\":\n",
    "                        loc = \"bodies of water\"\n",
    "                    if loc == \"crack in rock\":\n",
    "                        loc = \"cracks in rocks\"\n",
    "                    if loc == \"dry ingredient .\":\n",
    "                        loc = \"dry ingredients\"\n",
    "                    if loc == \"grease cake pan\":\n",
    "                        loc = \"greased cake pan\"\n",
    "                    if loc == \"release from the atom\":\n",
    "                        loc = \"released from the atom\"\n",
    "                    if loc == \"bottom of ocean , riverbed or swamp\":\n",
    "                        loc = \"bottom of oceans, riverbeds or swamps\"\n",
    "                    if loc == \"opposite end of the cell\" or loc == \"opposite pole of the cell\":\n",
    "                        loc = \"opposite poles of the cell\"\n",
    "                    if loc == \"fat , muscle and liver cell\":\n",
    "                        loc = \"fat, muscle and liver cells\"\n",
    "                    if loc == \"turn mechanisms\":\n",
    "                        loc = \"turning mechanism\"\n",
    "                    if loc == \"surround rocks\":\n",
    "                        loc = \"sorrounding rocks\"\n",
    "                    for m in re.finditer(\" \" + loc.lower(), sentences.lower()):\n",
    "                        start = m.start()\n",
    "                        if sentences[m.start()] == \" \":\n",
    "                            start = m.start() + 1\n",
    "                        all_loc.append((start, m.end()))\n",
    "                if len(all_loc) == 0:\n",
    "                    loc = loc.replace(\" , \", \", \")\n",
    "                    for m in re.finditer(\" \" + loc.lower(), sentences.lower()):\n",
    "                        start = m.start()\n",
    "                        if sentences[m.start()] == \" \":\n",
    "                            start = m.start() + 1\n",
    "                        all_loc.append((start, m.end()))\n",
    "                if len(all_loc) == 0:\n",
    "                    loc = loc.replace(\" , \", \", \")\n",
    "                    stri = loc.split(\",\")\n",
    "                    stri_f = \"\"\n",
    "                    for item in stri:\n",
    "                        if not engine.singular_noun(item):\n",
    "                            item = engine.plural(item)\n",
    "                        stri_f += \",\" + item\n",
    "                    loc = stri_f[1:]\n",
    "                    for m in re.finditer(\" \" + loc.lower(), sentences.lower()):\n",
    "                        start = m.start()\n",
    "                        if sentences[m.start()] == \" \":\n",
    "                            start = m.start() + 1\n",
    "                        all_loc.append((start, m.end()))\n",
    "                    if len(all_loc) == 0:\n",
    "                        for m in re.finditer(loc.lower(), sentences.lower()):\n",
    "                            start = m.start()\n",
    "                            if sentences[m.start()] == \" \":\n",
    "                                start = m.start() + 1\n",
    "                            all_loc.append((start, m.end()))\n",
    "                    if len(all_loc) == 0:\n",
    "                        stri = loc.split(\"and\")\n",
    "                        stri_f = \"\"\n",
    "                        for item in stri:\n",
    "                            if not engine.singular_noun(item):\n",
    "                                item = engine.plural(item)\n",
    "                            stri_f += \"and\" + item\n",
    "                        loc = stri_f[3:]\n",
    "                        for m in re.finditer(\" \" + loc.lower(), sentences.lower()):\n",
    "                            start = m.start()\n",
    "                            if sentences[m.start()] == \" \":\n",
    "                                start = m.start() + 1\n",
    "                            all_loc.append((start, m.end()))\n",
    "                    if len(all_loc) == 0:\n",
    "                        for m in re.finditer(loc.lower(), sentences.lower()):\n",
    "                            start = m.start()\n",
    "                            if sentences[m.start()] == \" \":\n",
    "                                start = m.start() + 1\n",
    "                            all_loc.append((start, m.end()))\n",
    "                    if len(all_loc) == 0:\n",
    "                        print(\"data in hand 3: \", loc)\n",
    "                        \n",
    "                if len(all_loc) == 1 or (not time and len(all_loc) >= 1):\n",
    "                    final_loc = all_loc[0]\n",
    "                else:\n",
    "                    in_sentence_check = False\n",
    "                    if time:\n",
    "                        for can_loc in all_loc:\n",
    "                            if can_loc[0] > boundaries[time-1][0] and can_loc[1] < boundaries[time-1][1]:\n",
    "                                final_loc = can_loc\n",
    "                                in_sentence_check = True\n",
    "                                break\n",
    "                        if not in_sentence_check:\n",
    "                            if len(all_loc) == 0:\n",
    "                                selected_boundary = (0, 0)\n",
    "                            else:\n",
    "                                selected_boundary = (0, 0)\n",
    "                                for can_loc in all_loc:\n",
    "                                    if can_loc[0] < boundaries[time-1][0] and can_loc[0] > selected_boundary[0]:\n",
    "                                        selected_boundary = can_loc\n",
    "                                if selected_boundary == (0,0):\n",
    "                                    selected_boundary = all_loc[-1]\n",
    "                                    for can_loc in all_loc: \n",
    "                                         if can_loc[1] > boundaries[time-1][1] and can_loc[1] < selected_boundary[1]:\n",
    "                                                selected_boundary = can_loc\n",
    "                            final_loc = selected_boundary\n",
    "            annotations.append((loc, final_loc))\n",
    "        return annotations\n",
    "    \n",
    "    word1['annotations'] = FunctionalSensor(word1['raw'], text['ready'] ,text['boundaries'], forward=find_spans)\n",
    "    \n",
    "    \n",
    "    def sentence_separator(text):\n",
    "        mapping = torch.ones(len(text), 1)\n",
    "        return mapping, text\n",
    "    \n",
    "    step[text_contain_step, 'raw'] = JointSensor(text['raw'], forward=sentence_separator)\n",
    "    \n",
    "    \n",
    "    def procedure_candidate(*inputs):\n",
    "        import re\n",
    "        mapping1 = torch.zeros(len(inputs[0])*len(inputs[2]), len(inputs[0]))\n",
    "        for i in range(len(inputs[0])):\n",
    "            mapping1[i*len(inputs[2]):(i+1)*len(inputs[2]), i] = 1\n",
    "        \n",
    "        mapping2 = torch.zeros(len(inputs[2]) * len(inputs[0]), len(inputs[2]))\n",
    "        \n",
    "        for i in range(len(inputs[2])):\n",
    "            mapping2[i*len(inputs[0]):(i+1)*len(inputs[0]), i] = 1\n",
    "            \n",
    "        text = [\"Where is \" + str(inputs[0][0]) + \"?!</s>\" + str(inputs[1][0])] * len(inputs[2])\n",
    "        padding = []\n",
    "        for story in text:\n",
    "            for m in re.finditer('/s'.lower(), story.lower()):\n",
    "                end = m.end() + 1\n",
    "                break\n",
    "            padding.append(end)\n",
    "        return mapping1, mapping2, text, padding\n",
    "    \n",
    "    pair[pair_entity.reversed, pair_step.reversed, 'text', 'padding'] = JointSensor(entity['raw'], text['ready'], step['raw'], forward=procedure_candidate)\n",
    "    \n",
    "    \n",
    "    class RoBertaTokenizorSensor(JointSensor):\n",
    "        from transformers import RobertaTokenizerFast\n",
    "        TRANSFORMER_MODEL = 'roberta-large'\n",
    "        tokenizer = RobertaTokenizerFast.from_pretrained(TRANSFORMER_MODEL)\n",
    "\n",
    "        def roberta_extract_timestamp_sequence(self, inputs, end_time):\n",
    "            f_out = []\n",
    "            padding = 0\n",
    "            for time in range(-1, end_time - 1):\n",
    "                timestamp_id = []\n",
    "                if time == -1:\n",
    "                    check = -1\n",
    "                    for index, ids in enumerate(inputs['input_ids'][time + 1]):\n",
    "                        if ids == 2:\n",
    "                            check += 1\n",
    "                            if check == 0:\n",
    "                                padding = index + 1\n",
    "                        if check == -1:\n",
    "                            timestamp_id.append(0)\n",
    "                        elif ids == 2:\n",
    "                            timestamp_id.append(0)\n",
    "                        else:\n",
    "                            timestamp_id.append(2)\n",
    "                else:\n",
    "                    check = -1\n",
    "                    for index, ids in enumerate(inputs['input_ids'][time + 1]):\n",
    "                        if ids == 2:\n",
    "                            check += 1\n",
    "                        if check == -1:\n",
    "                            timestamp_id.append(0)\n",
    "                        elif ids == 2:\n",
    "                            timestamp_id.append(0)\n",
    "                        else:\n",
    "                            if check < time :\n",
    "                                timestamp_id.append(1)\n",
    "                            elif check == time:\n",
    "                                timestamp_id.append(2)\n",
    "                            else:\n",
    "                                timestamp_id.append(3)\n",
    "                timestamp_id = torch.tensor(timestamp_id).to(device=inputs['input_ids'].device)\n",
    "                f_out.append(timestamp_id)\n",
    "            inputs['timestep_type_ids'] = torch.stack(f_out)\n",
    "            return inputs, padding\n",
    "\n",
    "        def forward(self, *inputs):\n",
    "            sentences = inputs[0]\n",
    "            tokens = self.tokenizer(\n",
    "                sentences,\n",
    "                return_tensors='pt',\n",
    "                return_offsets_mapping=True,\n",
    "            )\n",
    "            token_strings = []\n",
    "            token_nums = []\n",
    "            mapping = torch.zeros(len(tokens['input_ids'][0])*len(sentences), len(sentences))\n",
    "            tokens, padding = self.roberta_extract_timestamp_sequence(inputs=tokens, end_time=len(sentences))\n",
    "            for sen_num in range(len(sentences)):\n",
    "                token_strings.append(self.tokenizer.convert_ids_to_tokens(tokens['input_ids'][sen_num]))\n",
    "                token_nums.append(len(tokens['input_ids'][sen_num]))\n",
    "                mapping[sen_num*len(tokens['input_ids'][0]):((sen_num+1)*len(tokens['input_ids'][0])),sen_num] = 1\n",
    "\n",
    "            for key in tokens.keys():\n",
    "                tokens[key] = functools.reduce(operator.iconcat, tokens[key], [])\n",
    "                tokens[key] = torch.stack(tokens[key])\n",
    "            tokens['tokens'] = token_strings\n",
    "            tokens['token_nums'] = token_nums\n",
    "            \n",
    "            return mapping, tokens['input_ids'], tokens['attention_mask'], tokens['offset_mapping'], tokens['timestep_type_ids'], tokens['tokens'], tokens['token_nums']\n",
    "        \n",
    "\n",
    "    word[pair_contains_words, 'input_ids', 'attention_mask', 'offset_mapping', \"timestep_type_ids\", 'tokens', 'token_nums'] = RoBertaTokenizorSensor(pair['text'], pair[pair_entity.reversed], pair[pair_step.reversed])\n",
    "    \n",
    "#     pair[pair_contains_words.reversed] = FunctionalSensor(word[pair_contains_words], forward=lambda x : x[0].t)\n",
    "    \n",
    "    class BatchifyLearner(TorchLearner):\n",
    "        import functools\n",
    "        import operator\n",
    "        def __init__(self, *pres, batchify=True, **kwargs):\n",
    "            super().__init__(*pres, **kwargs)\n",
    "            self.batchify = batchify\n",
    "            \n",
    "            \n",
    "        def fetch_value(self, pre, selector=None, concept=None):\n",
    "            from regr.graph.relation import Transformed, Relation\n",
    "            from regr.sensor.sensor import Sensor\n",
    "            from regr.graph.property import Property\n",
    "            concept = concept or self.concept\n",
    "            if isinstance(pre, str):\n",
    "                return super().fetch_value(pre, selector, concept)\n",
    "            elif isinstance(pre, (Property, Sensor)):\n",
    "                return self.context_helper[pre]\n",
    "            elif isinstance(pre, Relation):\n",
    "                return self.context_helper[self.concept[pre]]\n",
    "            elif isinstance(pre, Transformed):\n",
    "                return pre(self.context_helper, device=self.device)\n",
    "            return pre\n",
    "    \n",
    "        def define_inputs(self):\n",
    "            self.inputs = []\n",
    "            if len(self.batchify):\n",
    "                hinter = self.fetch_value(self.batchify[0])\n",
    "            for pre in self.pres:\n",
    "                values = self.fetch_value(pre)\n",
    "#                 print(pre, values)\n",
    "#                 values = torch.stack(values)\n",
    "                if len(self.batchify):\n",
    "                    final_val = []\n",
    "                    for hint in hinter.t():\n",
    "                        slicer = torch.nonzero(hint).squeeze(-1)\n",
    "                        final_val.append(values.index_select(0, slicer))\n",
    "                    values = torch.stack(final_val)\n",
    "                self.inputs.append(values)\n",
    "                \n",
    "        def update_pre_context(\n",
    "            self,\n",
    "            data_item: Dict[str, Any],\n",
    "            concept=None\n",
    "        ) -> Any:\n",
    "            super().update_pre_context(data_item, concept)\n",
    "            concept = concept or self.concept\n",
    "            for batchifier in self.batchify:\n",
    "                for sensor in concept[batchifier].find(self.non_label_sensor):\n",
    "                    sensor(data_item=data_item)\n",
    "                    \n",
    "        def update_context(\n",
    "            self,\n",
    "            data_item: Dict[str, Any],\n",
    "            force=False,\n",
    "            override=True):\n",
    "            if not force and self in data_item:\n",
    "                # data_item cached results by sensor name. override if forced recalc is needed\n",
    "                val = data_item[self]\n",
    "            else:\n",
    "                self.update_pre_context(data_item)\n",
    "                self.define_inputs()\n",
    "                val = self.forward_wrap()\n",
    "                \n",
    "                if len(self.batchify):\n",
    "                    val = functools.reduce(operator.iconcat, val, [])\n",
    "                    val = torch.stack(val)\n",
    "                    \n",
    "                data_item[self] = val\n",
    "            if override and not self.label:\n",
    "                data_item[self.prop] = val  # override state under property name\n",
    "                \n",
    "           \n",
    "    class BatchifyModuleLearner(ModuleLearner, BatchifyLearner):\n",
    "        pass\n",
    "    \n",
    "    class RobertaModelLearner(BatchifyModuleLearner):\n",
    "        device=\"cpu\"\n",
    "        def forward(self, *inputs):\n",
    "            running = {}\n",
    "            running[\"input_ids\"] = inputs[0]\n",
    "            running[\"attention_mask\"] = inputs[1]\n",
    "            running[\"timestep_type_ids\"] = inputs[2]\n",
    "            transformer_result = self.model(**running)\n",
    "            return transformer_result[0]\n",
    "        \n",
    "    from roberta import RobertaModel\n",
    "    word[\"embedding\"] = RobertaModelLearner('input_ids', 'attention_mask', 'timestep_type_ids', batchify=[pair_contains_words], module=RobertaModel.from_pretrained('tli8hf/unqover-roberta-large-squad'))\n",
    "            \n",
    "    \n",
    "    import torch.nn as nn\n",
    "    \n",
    "    word['start'] = BatchifyModuleLearner('embedding', batchify=[pair_contains_words], module=nn.Sequential(nn.Linear(1024, 1), nn.Softmax(dim=-1)))\n",
    "    word['end'] = BatchifyModuleLearner('embedding', batchify=[pair_contains_words], module=nn.Sequential(nn.Linear(1024, 1), nn.Softmax(dim=-1)))\n",
    "    \n",
    "    def compute_first(*inputs):\n",
    "        connection = inputs[0].t()\n",
    "        idx = torch.arange(connection.shape[1], 0, -1)\n",
    "        tmp2= connection * idx\n",
    "        indices = torch.argmax(tmp2, 1, keepdim=True).squeeze(-1)\n",
    "        result = torch.index_select(inputs[1], 0, indices)\n",
    "        return result\n",
    "        \n",
    "    pair[\"first_word_repr\"] = FunctionalSensor(word[pair_contains_words], word['embedding'], forward=compute_first)\n",
    "    \n",
    "    pair[non_existence] = ModuleLearner('first_word_repr', module=nn.Sequential(nn.Linear(1024, 2), nn.Softmax(dim=-1)))\n",
    "    pair[unknown_loc] = ModuleLearner('first_word_repr', module=nn.Sequential(nn.Linear(1024, 2), nn.Softmax(dim=-1)))\n",
    "    pair[known_loc] = ModuleLearner('first_word_repr', module=nn.Sequential(nn.Linear(1024, 2), nn.Softmax(dim=-1)))\n",
    "    \n",
    "    pair[non_existence] = ReaderSensor(keyword=\"non_existence\")\n",
    "    pair[unknown_loc] = ReaderSensor(keyword=\"unknown\")\n",
    "    pair[known_loc] = ReaderSensor(keyword=\"location\")\n",
    "    \n",
    "    class BatchifySensor(FunctionalSensor):\n",
    "        import functools\n",
    "        import operator\n",
    "        def __init__(self, *pres, batchify=True, ignore=-1, **kwargs):\n",
    "            super().__init__(*pres, **kwargs)\n",
    "            self.batchify = batchify\n",
    "            self.ignore = ignore\n",
    "            \n",
    "            \n",
    "        def fetch_value(self, pre, selector=None, concept=None):\n",
    "            from regr.graph.relation import Transformed, Relation\n",
    "            from regr.sensor.sensor import Sensor\n",
    "            from regr.graph.property import Property\n",
    "            concept = concept or self.concept\n",
    "            if isinstance(pre, str):\n",
    "                return super().fetch_value(pre, selector, concept)\n",
    "            elif isinstance(pre, (Property, Sensor)):\n",
    "                return self.context_helper[pre]\n",
    "            elif isinstance(pre, Relation):\n",
    "                return self.context_helper[self.concept[pre]]\n",
    "            elif isinstance(pre, Transformed):\n",
    "                return pre(self.context_helper, device=self.device)\n",
    "            return pre\n",
    "    \n",
    "        def define_inputs(self):\n",
    "            self.inputs = []\n",
    "            if len(self.batchify):\n",
    "                hinter = self.fetch_value(self.batchify[0])\n",
    "            for pre_num, pre in enumerate(self.pres):\n",
    "                values = self.fetch_value(pre)\n",
    "                if pre_num in self.ignore:\n",
    "                    self.inputs.append(values)\n",
    "                else:\n",
    "#                     values = torch.stack(values)\n",
    "                    if len(self.batchify):\n",
    "                        final_val = []\n",
    "                        for hint in hinter.t():\n",
    "                            slicer = torch.nonzero(hint).squeeze(-1)\n",
    "                            final_val.append(values.index_select(0, slicer))\n",
    "                        values = torch.stack(final_val)\n",
    "                    self.inputs.append(values)\n",
    "                \n",
    "        def update_pre_context(\n",
    "            self,\n",
    "            data_item: Dict[str, Any],\n",
    "            concept=None\n",
    "        ) -> Any:\n",
    "            super().update_pre_context(data_item, concept)\n",
    "            concept = concept or self.concept\n",
    "            for batchifier in self.batchify:\n",
    "                for sensor in concept[batchifier].find(self.non_label_sensor):\n",
    "                    sensor(data_item=data_item)\n",
    "                    \n",
    "        def update_context(\n",
    "            self,\n",
    "            data_item: Dict[str, Any],\n",
    "            force=False,\n",
    "            override=True):\n",
    "            if not force and self in data_item:\n",
    "                # data_item cached results by sensor name. override if forced recalc is needed\n",
    "                val = data_item[self]\n",
    "            else:\n",
    "                self.update_pre_context(data_item)\n",
    "                self.define_inputs()\n",
    "                val = self.forward_wrap()\n",
    "                \n",
    "                if len(self.batchify):\n",
    "                    val = functools.reduce(operator.iconcat, val, [])\n",
    "                    \n",
    "                data_item[self] = val\n",
    "            if override and not self.label:\n",
    "                data_item[self.prop] = val  # override state under property name\n",
    "             \n",
    "    def find_exact_token_start(*inputs):\n",
    "        output = torch.zeros(inputs[0].shape[0], inputs[0].shape[1])\n",
    "        for index, data1 in enumerate(inputs[0]):\n",
    "            if inputs[1][index][0] == \"-\":\n",
    "                continue\n",
    "            token_starts = [-1]\n",
    "            for tindex, token in enumerate(data1[1:-1]):\n",
    "                token_starts.append(token[0].item() - inputs[3][index])\n",
    "            token_starts.append(-1)\n",
    "            final_loc = inputs[1][index][1]\n",
    "            if final_loc[0] != 0 or final_loc[1] != 0:\n",
    "                bert_start_token = token_starts.index(final_loc[0])\n",
    "                output[index][bert_start_token] = 1\n",
    "        return output\n",
    "    \n",
    "    def find_exact_token_end(*inputs):\n",
    "        output = torch.zeros(inputs[0].shape[0], inputs[0].shape[1])\n",
    "        for index, data1 in enumerate(inputs[0]):\n",
    "            if inputs[1][index][0] == \"-\":\n",
    "                continue\n",
    "            token_ends = [-1]\n",
    "            for tindex, token in enumerate(data1[1:-1]):\n",
    "                token_ends.append(token[1].item() - inputs[3][index])\n",
    "            token_ends.append(-1)\n",
    "            final_loc = inputs[1][index][1]\n",
    "            if final_loc[0] != 0 or final_loc[1] != 0:\n",
    "                if final_loc[1] in token_ends:\n",
    "                    bert_end_token = token_ends.index(final_loc[1])\n",
    "                elif final_loc[1] + 1 in token_ends:\n",
    "                    bert_end_token = token_ends.index(final_loc[1] + 1)\n",
    "                elif final_loc[1] + 2 in token_ends:\n",
    "                    bert_end_token = token_ends.index(final_loc[1] + 2)\n",
    "                else:\n",
    "                    raise ValueError(\"the bert end not found\")\n",
    "                output[index][bert_end_token] = 1\n",
    "        return output\n",
    "    \n",
    "    word['start'] = BatchifySensor(word['offset_mapping'], word1['annotations'], word['input_ids'], pair['padding'], batchify=[pair_contains_words], ignore=[1, 3], forward=find_exact_token_start)\n",
    "    word['end'] = BatchifySensor(word['offset_mapping'], word1['annotations'], word['input_ids'], pair['padding'], batchify=[pair_contains_words], ignore=[1, 3], forward=find_exact_token_end)\n",
    "    # word[step_contains_word, 'raw'] = ReaderSensor(keyword='words')\n",
    "#     entity['raw'] = ReaderSensor(keyword='entities')\n",
    "\n",
    "#     step[non_existence] = ReaderSensor(procedure_contain_step.forward, 'text', keyword='non_existence')\n",
    "#     step[unknown_loc] = ReaderSensor(procedure_contain_step.forward, 'text', keyword='unknown')\n",
    "#     step[known_loc] = ReaderSensor(procedure_contain_step.forward, 'text', keyword='known')\n",
    "    \n",
    "#     step[non_existence] = ReaderSensor(keyword='non_existence', label=True)\n",
    "#     step[unknown_loc] = ReaderSensor(keyword='unknown', label=True)\n",
    "#     step[known_loc] = ReaderSensor(keyword='known', label=True)\n",
    "    \n",
    "#     action[action_arg1.backward, action_arg2.backward] = JoinReaderSensor(step['text'], keyword='action')\n",
    "    \n",
    "#     action[create] = ReaderSensor(action_arg1.backward, action_arg2.backward, keyword='create')\n",
    "#     action[destroy] = ReaderSensor(action_arg1.backward, action_arg2.backward, keyword='destroy')\n",
    "#     action[other] = ReaderSensor(action_arg1.backward, action_arg2.backward, keyword='other')\n",
    "    \n",
    "#     action[create] = ReaderSensor(keyword='create', label=True)\n",
    "#     action[destroy] = ReaderSensor(keyword='destroy', label=True)\n",
    "#     action[other] = ReaderSensor(keyword='other', label=True)\n",
    "    \n",
    "    before[before_arg1.reversed, before_arg2.reversed] = JoinReaderSensor(keyword=\"before\")\n",
    "    \n",
    "    before[\"check\"] = ReaderSensor(before_arg1.reversed, before_arg2.reversed, keyword=\"before_true\")\n",
    "#     before[\"check\"] = ReaderSensor(keyword=\"before_true\", label=True)\n",
    "    \n",
    "    program = LearningBasedProgram(graph, **{\n",
    "        'Model': PoiModel,\n",
    "        'poi': (word['start'], word['end'], pair[known_loc], pair[unknown_loc], pair[non_existence], before['check'] ),\n",
    "        'loss': None,\n",
    "        'metric': None,\n",
    "    })\n",
    "    return program\n",
    "#     return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # set logger level to see training and testing logs\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    lbp = model_declaration()\n",
    "\n",
    "    dataset = ProparaReader(\"emnlp18/grids.v1.train.json\", 'parse')  # Adding the info on the reader\n",
    "\n",
    "    for datanode in lbp.populate(dataset, device=\"cpu\"):\n",
    "#         print(datanode.findDatanodes(select=pair)[0].getAttribute('first_word_repr'))\n",
    "        print(datanode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.tensor([[1, 1, 1, 0, 0], [0, 0, 0, 1, 1]])\n",
    "k = torch.tensor([10, 5, 7, 9, 4])\n",
    "idx = torch.arange(tt.shape[1], 0, -1)\n",
    "tmp2= tt * idx\n",
    "indices = torch.argmax(tmp2, 1, keepdim=True).squeeze(-1)\n",
    "print(indices)\n",
    "torch.index_select(k, 0, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.graph import DataNodeBuilder\n",
    "from regr.sensor.sensor import Sensor\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "graph1 = model_declaration()\n",
    "# dataset = ProparaReader(\"emnlp18/grids.v1.train.json\", 'parse')\n",
    "# for datanode in lbp.populate(list(dataset)[0:1], device=\"cpu\"):\n",
    "#     pass\n",
    "dataset = ProparaReader(\"emnlp18/grids.v1.train.json\", 'parse')\n",
    "for data in list(iter(dataset))[0:1]:\n",
    "    context = {\"graph\": graph1}\n",
    "    context.update(data)\n",
    "    data_item = DataNodeBuilder(context)\n",
    "    # data_item\n",
    "    for sensor in entity['raw'].find(Sensor):\n",
    "        sensor(data_item)\n",
    "        \n",
    "    datanode = data_item.getDataNode()\n",
    "    print(data_item)\n",
    "#     datanode.inferILPConstrains(create, destroy, other, non_existence, known_loc, unknown_loc, fun=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_updates[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {\"graph\": graph}\n",
    "context.update(list(iter(dataset))[2])\n",
    "data_item = DataNodeBuilder(context)\n",
    "# data_item\n",
    "for sensor in procedure['id'].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in step['text'].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in step[procedure_contain_step.forward].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in step[known_loc].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in step[unknown_loc].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in step[non_existence].find(Sensor):\n",
    "    sensor1 = sensor\n",
    "    sensor(data_item)\n",
    "for sensor in action[action_arg1.backward].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in action[action_arg2.backward].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in action[destroy].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in action[create].find(Sensor):\n",
    "    sensor(data_item)\n",
    "for sensor in action[other].find(Sensor):\n",
    "    sensor(data_item)\n",
    "print(data_item[sensor1])\n",
    "print(list(iter(dataset))[2]['non_existence'])\n",
    "datanode = data_item.getDataNode()\n",
    "print(datanode.findDatanodes(select=step)[1].getAttribute('non_existence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(iter(dataset))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from roberta import RobertaEmbeddings, RobertaConfig\n",
    "config = RobertaConfig()\n",
    "model = RobertaEmbeddings(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertTokenizerFast, RobertaTokenizerFast, RobertaTokenizer, AutoTokenizer\n",
    "tokenizer_fast = RobertaTokenizerFast.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer_fast([\"this is a sample sentence </s> the next step goes here\"], return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_position_ids_from_input_ids(input_ids, padding_idx=config.pad_token_id):\n",
    "    \"\"\"Replace non-padding symbols with their position numbers. Position numbers begin at\n",
    "    padding_idx+1. Padding symbols are ignored. This is modified from fairseq's\n",
    "    `utils.make_positions`.\n",
    "\n",
    "    :param torch.Tensor x:\n",
    "    :return torch.Tensor:\n",
    "    \"\"\"\n",
    "    # The series of casts and type-conversions here are carefully balanced to both work with ONNX export and XLA.\n",
    "    mask = input_ids.ne(padding_idx).int()\n",
    "    incremental_indices = torch.cumsum(mask, dim=1).type_as(mask) * mask\n",
    "    return incremental_indices.long() + padding_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6, -5, -4, -3, -2, -1,  0,  1,  2,  3,  4,  5,  6,  7]])\n"
     ]
    }
   ],
   "source": [
    "result = create_position_ids_from_input_ids(tokens['input_ids'])\n",
    "result = result - 8\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-400e8a40dc45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/examples/Propara/roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, timestep_type_ids)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mtimestep_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestep_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestep_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "model(input_ids=tokens['input_ids'], position_ids=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
