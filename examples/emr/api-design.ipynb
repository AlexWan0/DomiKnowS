{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# envionment setup\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import site\n",
    "site.addsitedir('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data setting\n",
    "relative_path = \"data/EntityMentionRelation\"\n",
    "train_path = \"conll04_train.corp\"\n",
    "valid_path = \"conll04_test.corp\"\n",
    "\n",
    "# model setting\n",
    "EMBEDDING_DIM = 16\n",
    "HIDDEN_DIM = 8\n",
    "\n",
    "# training setting\n",
    "LR = 0.1\n",
    "BATCH = 128\n",
    "EPOCH = 10 # 1000\n",
    "PATIENCE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr import Graph\n",
    "from regr.scaffold import Scaffold\n",
    "from emr.models import datainput, word2vec, fc_sm\n",
    "from emr.data import Data\n",
    "from allennlp.models.model import Model\n",
    "\n",
    "\n",
    "# develop by an ML programmer to wire nodes in the graph and ML Models\n",
    "def make_model(graph: Graph,\n",
    "               data: Data,\n",
    "               scaffold: Scaffold\n",
    "              ) -> Model:\n",
    "    # get concepts from graph\n",
    "    word = graph.word\n",
    "    people = graph.people\n",
    "    \n",
    "    # binding\n",
    "    graph.release() # release anything binded before new assignment\n",
    "    \n",
    "    # filling in data and label\n",
    "    scaffold.assign(word, 'index', *datainput(data['sentence']))\n",
    "    scaffold.assign(people, 'label', *datainput(data['label']))\n",
    "    \n",
    "    # building model\n",
    "    scaffold.assign(word, 'w2v',\n",
    "                    *word2vec(\n",
    "                        word['index'],\n",
    "                        data.vocab.get_vocab_size('tokens'),\n",
    "                        EMBEDDING_DIM,\n",
    "                        'tokens'\n",
    "                    ))\n",
    "    scaffold.assign(people, 'label',\n",
    "                    *fc_sm(\n",
    "                        word['w2v'],\n",
    "                        EMBEDDING_DIM,\n",
    "                        2\n",
    "                    ))\n",
    "    # now people['label'] has multiple assignment,\n",
    "    # and the loss should come from the inconsistency here\n",
    "\n",
    "    # get the model\n",
    "    ModelCls = scaffold.build(graph) # or should it be model = graph.build()\n",
    "    # NB: Link in the graph make be use to provide non parameterized\n",
    "    #     transformation, what is a core feature of our graph.\n",
    "    #     Is there a better semantic interface design?\n",
    "    model = ModelCls(data.vocab)\n",
    "    model.field_name['output'] = people.fullname + '[label]'\n",
    "    model.field_name['label'] = 'label'\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# envionment setup\n",
    "\n",
    "#import logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def seed1():\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "    torch.manual_seed(1)\n",
    "    \n",
    "seed1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from emr.data import Data, NERPeopReader\n",
    "from emr.graph import graph\n",
    "from emr.models import get_trainer\n",
    "from regr.scaffold import AllennlpScaffold\n",
    "import torch\n",
    "\n",
    "# data\n",
    "reader = NERPeopReader()\n",
    "train_dataset = reader.read(os.path.join(relative_path, train_path))\n",
    "valid_dataset = reader.read(os.path.join(relative_path, valid_path))\n",
    "data = Data(train_dataset, valid_dataset)\n",
    "\n",
    "scaffold = AllennlpScaffold()\n",
    "\n",
    "# model from graph\n",
    "model = make_model(graph, data, scaffold)\n",
    "\n",
    "# trainer for model\n",
    "trainer = get_trainer(graph, model, data, scaffold)\n",
    "\n",
    "# train the model\n",
    "trainer.train()\n",
    "\n",
    "# save the model\n",
    "with open(\"/tmp/model.th\", 'wb') as fout:\n",
    "    torch.save(model.state_dict(), fout)\n",
    "data.vocab.save_to_files(\"/tmp/vocab\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
