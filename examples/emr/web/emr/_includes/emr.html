<!--
This file was programmatically generated by
github.com/allenai/allennlp/tutorials/tagger/convert.py.
Any manual changes you make to it will be overwritten
the next time the file is generated. Please make your changes
to the original python file or to the convert.py script, 
as appropriate.
-->
<h1>
<a id="user-content-example-entity-mention-relation-emr" class="anchor" href="#example-entity-mention-relation-emr" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Example: Entity-Mention-Relation (EMR)</h1>
<h2>
<a id="user-content-steps" class="anchor" href="#steps" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Steps</h2>
<p>This example follows the three declarative steps:</p>
<ol>
<li>Knowledge Declaration</li>
<li>Data Declaration</li>
<li>Learning Declaration</li>
</ol>
<div id="annotated-code">
  <!-- Code Blocks -->
  <div class="annotated-code__pane annotated-code__pane--code-container">
<div class="annotated-code__code-block" id="c0">
{% highlight python %}
from regr.sensor.allennlp.sensor import SentenceSensor, SentenceEmbedderSensor, LabelSensor, CartesianProductSensor, ConcatSensor, NGramSensor, TokenDistantSensor, TokenDepSensor, TokenLcaSensor, TokenDepDistSensor
from regr.sensor.allennlp.learner import SentenceEmbedderLearner, RNNLearner, MLPLearner, ConvLearner, LogisticRegressionLearner
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c1">
{% highlight python %}
from regr.graph.allennlp import AllenNlpGraph
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c2">
{% highlight python %}
#from .data import Conll04SensorReader as Reader
from data_spacy import Conll04SpaCyBinaryReader as Reader
from config import Config
from utils import seed
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c3">
{% highlight python %}
def knowledge_declaration():
    from graph import graph
    return graph
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c4">
{% highlight python %}
def data_and_learning_declaration(graph, config):
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c5">
{% highlight python %}
    graph.detach()
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c6">
{% highlight python %}
    sentence = graph['linguistic/sentence']
    word = graph['linguistic/word']
    pair = graph['linguistic/pair']
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c7">
{% highlight python %}
    people = graph['application/people']
    organization = graph['application/organization']
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c8">
{% highlight python %}
    work_for = graph['application/work_for']
    kill = graph['application/kill']
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c9">
{% highlight python %}
    reader = Reader()
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c10">
{% highlight python %}
    sentence['raw'] = SentenceSensor(reader, 'sentence')
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c11">
{% highlight python %}
    word['raw'] = SentenceEmbedderSensor('word', config.pretrained_dims['word'], sentence['raw'], pretrained_file=config.pretrained_files['word'])
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c12">
{% highlight python %}
    word['pos'] = SentenceEmbedderLearner('pos_tag', config.embedding_dim, sentence['raw'])
    word['dep'] = SentenceEmbedderLearner('dep_tag', config.embedding_dim, sentence['raw'])
    # possible to add more this kind
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c13">
{% highlight python %}
    word['all'] = ConcatSensor(word['raw'], word['pos'], word['dep'])
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c14">
{% highlight python %}
    word['ngram'] = NGramSensor(config.ngram, word['all'])
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c15">
{% highlight python %}
    word['encode'] = RNNLearner(word['ngram'], layers=config.rnn.layers, bidirectional=config.rnn.bidirectional, dropout=config.dropout)
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c16">
{% highlight python %}
    word['compact'] = MLPLearner(config.compact.layers, word['encode'], activation=config.activation)
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c17">
{% highlight python %}
    pair['cat'] = CartesianProductSensor(word['compact'])
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c18">
{% highlight python %}
    pair['tkn_dist'] = TokenDistantSensor(config.distance_emb_size * 2, config.max_distance, sentence['raw'])
    pair['tkn_dep'] = TokenDepSensor(sentence['raw'])
    pair['tkn_dep_dist'] = TokenDepDistSensor(config.distance_emb_size, config.max_distance, sentence['raw'])
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c19">
{% highlight python %}
    pair['onehots'] = ConcatSensor(pair['tkn_dist'], pair['tkn_dep'], pair['tkn_dep_dist'])
    pair['emb'] = MLPLearner([config.relemb.emb_size,], pair['onehots'], activation=None)
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c20">
{% highlight python %}
    pair['tkn_lca'] = TokenLcaSensor(sentence['raw'], word['compact'])
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c21">
{% highlight python %}
    pair['encode'] = ConcatSensor(pair['cat'], pair['tkn_lca'], pair['emb'])
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c22">
{% highlight python %}
    people['label'] = LabelSensor(reader, 'Peop', output_only=True)
    organization['label'] = LabelSensor(reader, 'Org', output_only=True)
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c23">
{% highlight python %}
    people['label'] = LogisticRegressionLearner(word['encode'])
    organization['label'] = LogisticRegressionLearner(word['encode'])
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c24">
{% highlight python %}
    work_for['label'] = LabelSensor(reader, 'Work_For', output_only=True)
    kill['label'] = LabelSensor(reader, 'Kill', output_only=True)
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c25">
{% highlight python %}
    work_for['label'] = LogisticRegressionLearner(pair['encode'])
    kill['label'] = LogisticRegressionLearner(pair['encode'])
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c26">
{% highlight python %}
    lbp = AllenNlpGraph(graph, **config.graph)
    return lbp
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c27">
{% highlight python %}
def main():
    save_config = Config.deepclone()
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c28">
{% highlight python %}
    graph = knowledge_declaration()
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c29">
{% highlight python %}
    lbp = data_and_learning_declaration(graph, Config.Model)
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c30">
{% highlight python %}
    seed()
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c31">
{% highlight python %}
    lbp.train(Config.Data, Config.Train)
{% endhighlight %}
</div>
<div class="annotated-code__code-block" id="c32">
{% highlight python %}
    save_to = Config.Train.trainer.serialization_dir or '/tmp/emr'
    lbp.save(save_to, config=save_config)
{% endhighlight %}
</div>
</div>
    <!-- END Code Blocks -->

    <!-- Annotations -->
    <div class="annotated-code__pane annotated-code__pane--annotations-container">
        <ul id="annotated-code__annotations">
<li class="annotation" id="a0"><p>With <code>regr</code>, we assign sensors to properties of concept. There are two types of sensor: <code>Sensor</code>s and <code>Learner</code>s. <code>Sensor</code> is the more general term, while a <code>Learner</code> is a <code>Sensor</code> with learnable parameters.</p>
</li>
<li class="annotation" id="a1"><p><code>AllenNlpGraph</code> is a special subclass of <code>Graph</code> that wraps a <code>Graph</code> and adds computational functionalities to it.</p>
</li>
<li class="annotation" id="a2"><p>There are a few other components that are needed in common machine learning models. * <code>Conll04SensorReader</code> is a AllenNLP <code>DatasetReader</code>. We added a bit of magic to make it more compatible with <code>regr</code>. See <code>data.py</code> for details. * <code>Config</code> contains configurations for model, data, and training. * <code>seed</code> is a useful function that resets random seed of all involving sub-systems: Python, numpy, and PyTorch, to make the performance of training consistent, as a demo.</p>
</li>
<li class="annotation" id="a3"><p>"<em>Knowledge Declaration</em>" A graph of the concepts, representing the ontology in this application, is declared. It can be compile from standard ontology formats like <code>OWL</code>, writen with python grammar directly, or combine both way. Here we just import the graph from <code>graph.py</code>. Please also refer to <code>graph.py</code> for details.</p>
</li>
<li class="annotation" id="a4"><p>"<em>Data Declaration</em>" and "<em>Learning Declaration</em>" Sensors and learners are connected to the graph, what wraps the graph with functionalities to retieve data, forward computing, learning from error, and inference during all those processes. <code>graph</code> is a <code>Graph</code> object retrieved from the "Knowledge Declaration". <code>config</code> is configurations relatred to the model.</p>
</li>
<li class="annotation" id="a5"><p><code>Graph</code> class has some kind of global variables. Use <code>.detach()</code> to reset them to avoid baffling error.</p>
</li>
<li class="annotation" id="a6"><p>Retrieve concepts that are needed in this model. Notice that these concepts are already well defined in <code>graph.py</code>. Here we just retrieve them to use them as python variables. <code>sentence</code>, <code>phrase</code>, and <code>pair</code> are basic linguistic concepts in this demo.</p>
</li>
<li class="annotation" id="a7"><p><code>people</code> and <code>organization</code> are entities we want to extract in this demo.</p>
</li>
<li class="annotation" id="a8"><p><code>kill</code> and <code>work_for</code> are relations we want to extract in this demo.</p>
</li>
<li class="annotation" id="a9"><p>Create a <code>Reader</code> instance, to be assigned with properties, and allow the model to get corresponding data from it.</p>
</li>
<li class="annotation" id="a10"><p>"<em>Data Declaration</em>" We start with linguistic concepts. <code>SentenceSensor</code> provides the ability to read words from a <code>TextField</code> in AllenNLP. It takes two arguments, firstly the reader to read with, and secondly a <code>key</code> for the reader to refer to correct <code>TextField</code>.</p>
</li>
<li class="annotation" id="a11"><p><code>SentenceEmbedderSensor</code> provides the ability to index the words and convert them into word embeddings. Notice that <code>SentenceEmbedderSensor</code> is a load pretrained embedding and do not train anymore.</p>
</li>
<li class="annotation" id="a12"><p>We can also specify <code>SentenceEmbedderLearner</code> to train tokens with or without pretrained parameters. Here <code>pos_tag</code> and <code>dep_tag</code> are also text-based in the original input.</p>
</li>
<li class="annotation" id="a13"><p>Then we can concatenate them together.</p>
</li>
<li class="annotation" id="a14"><p><code>NGramSensor</code> use a sliding window to collect context for each word.</p>
</li>
<li class="annotation" id="a15"><p><code>RNNLearner</code> takes a sequence of representations as input, encodes them with recurrent nerual networks (RNN), like LSTM or GRU, and provides the encoded output.</p>
</li>
<li class="annotation" id="a16"><p>The output is high-dimensional after N-gram and bidirectional RNN. We want to have a compact representation with a simple fully connected layer.</p>
</li>
<li class="annotation" id="a17"><p><code>CartesianProductSensor</code> is a <code>Sensor</code> that takes the representation from <code>word['emb']</code>, makes all possible combination of them, and generates a concatenating result for each combination.</p>
</li>
<li class="annotation" id="a18"><p>Also add some pair-wise features.</p>
</li>
<li class="annotation" id="a19"><p>Map the onehot features to a dense feature space by a simple fully connected layer.</p>
</li>
<li class="annotation" id="a20"><p>Yet another pair-wise feature.</p>
</li>
<li class="annotation" id="a21"><p>Put them all together.</p>
</li>
<li class="annotation" id="a22"><p>Then we connect properties with ground-truth from <code>reader</code>. <code>LabelSensor</code> takes the <code>reader</code> as argument to provide the ground-truth data. The second argument indicates the key we used for each lable in reader. The last keyword argument <code>output_only</code> indicates that these sensors are not to be used with forward computation.</p>
</li>
<li class="annotation" id="a23"><p>We connect properties with learners that generate predictions. Notice that we connect the predicting <code>Learner</code>s to the same properties as "ground-truth" <code>Sensor</code>s. Multiple assignment is a feature in <code>regr</code> to allow each property to have multiple sources. Value from different sources will be compared, to generate inconsistency error. The training of this model is then based on this inconsistency error. In this example, "ground-truth" <code>Sensor</code>s has no parameters to be trained, while predicting <code>Learner</code>s have all sets of paramters to be trained. The error also propagate backward through the computational path to all modules as assigned above.</p>
</li>
<li class="annotation" id="a24"><p>We repeat these on composed-concepts. There is nothing different in usage thought they are higher ordered concepts.</p>
</li>
<li class="annotation" id="a25"><p>We also connect the predictors for composed-concepts.</p>
</li>
<li class="annotation" id="a26"><p>Lastly, we wrap these graph with <code>AllenNlpGraph</code> functionalities to get the full learning based program.</p>
</li>
<li class="annotation" id="a27"><p>The main entrance of the program.</p>
</li>
<li class="annotation" id="a28"><ol>
<li>"Knowledge Declaration" to get a graph, as a partial program.</li>
</ol>
</li>
<li class="annotation" id="a29"><ol start="2">
<li>"Data Declaration" and "Learning Declaration" to connect sensors and learners and get the full program.</li>
</ol>
</li>
<li class="annotation" id="a30"><ol start="3">
<li>Train and save the model To have better reproducibility, we initial the random seeds of all subsystems.</li>
</ol>
</li>
<li class="annotation" id="a31"><p>Train the model with inference functionality inside.</p>
</li>
<li class="annotation" id="a32"><p>Save the model, including vocabulary use to index the tokens.</p>
</li>
</ul>
  </div><!-- END Annotations -->
</div><!-- END Annotated Code -->
<p>This example show a full pipeline how to work with <code>regr</code>.</p>

 {% include more-tutorials.html %}
