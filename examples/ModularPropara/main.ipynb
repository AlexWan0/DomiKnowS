{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "twenty-baseball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hfaghihi/Framework/new/DomiKnowS/examples\n",
      "root Folder Absoloute path:  /home/hfaghihi/Framework/new/DomiKnowS\n"
     ]
    }
   ],
   "source": [
    "import os,sys,inspect\n",
    "import json\n",
    "import torch\n",
    "currentdir = os.path.dirname(os.getcwd())\n",
    "print(currentdir)\n",
    "# parent_dir = os.path.abspath(os.path.join(currentdir, os.pardir))\n",
    "root = os.path.dirname(currentdir)\n",
    "print(\"root Folder Absoloute path: \", root)\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(root)\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import __main__\n",
    "\n",
    "__main__.__file__=\"main.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "danish-copyright",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "dict_keys(['para_id', 'location_cand', 'states', 'loc_spans', 'boundaries', 'states_mapping', 'states_in_tokens', 'spans', 'roberta_tokens', 'states_annotation', 'roberta_bounds', 'participants', 'sentence_paragraph', 'sentence_texts', 'trips_annotation', 'actions', 'ltype', 'net_results'])\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/tracker.log\", \"r\") as file:\n",
    "    tracker = []\n",
    "    for line in file:\n",
    "        tracker.append(json.loads(line))\n",
    "print(len(tracker))\n",
    "print(tracker[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "leading-found",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 5, 4])\n",
      "tensor([[[3.1940e-01, 4.0114e-01, 1.0121e-02, 2.6934e-01],\n",
      "         [6.1400e-01, 4.4190e-03, 4.0276e-02, 3.4130e-01],\n",
      "         [6.1400e-01, 4.4190e-03, 4.0276e-02, 3.4130e-01],\n",
      "         [6.1400e-01, 4.4190e-03, 4.0276e-02, 3.4130e-01],\n",
      "         [6.1400e-01, 4.4190e-03, 4.0276e-02, 3.4130e-01]],\n",
      "\n",
      "        [[7.0585e-01, 7.2110e-04, 3.8825e-02, 2.5460e-01],\n",
      "         [7.0585e-01, 7.2110e-04, 3.8825e-02, 2.5460e-01],\n",
      "         [7.0585e-01, 7.2110e-04, 3.8825e-02, 2.5460e-01],\n",
      "         [7.0585e-01, 7.2110e-04, 3.8825e-02, 2.5460e-01],\n",
      "         [7.0585e-01, 7.2110e-04, 3.8825e-02, 2.5460e-01]],\n",
      "\n",
      "        [[5.7955e-01, 3.5761e-04, 3.9642e-01, 2.3672e-02],\n",
      "         [4.5550e-01, 2.2812e-02, 2.1059e-02, 5.0063e-01],\n",
      "         [2.4481e-01, 1.5927e-05, 5.0667e-01, 2.4850e-01],\n",
      "         [5.7955e-01, 3.5761e-04, 3.9642e-01, 2.3672e-02],\n",
      "         [5.7955e-01, 3.5761e-04, 3.9642e-01, 2.3672e-02]],\n",
      "\n",
      "        [[5.8445e-01, 2.2438e-04, 4.1525e-01, 7.7910e-05],\n",
      "         [4.7322e-01, 1.5209e-01, 2.2237e-02, 3.5245e-01],\n",
      "         [3.9070e-01, 1.2423e-04, 4.6707e-01, 1.4211e-01],\n",
      "         [5.8445e-01, 2.2438e-04, 4.1525e-01, 7.7910e-05],\n",
      "         [5.8445e-01, 2.2438e-04, 4.1525e-01, 7.7910e-05]],\n",
      "\n",
      "        [[4.9528e-01, 1.3112e-04, 5.0160e-01, 2.9867e-03],\n",
      "         [4.8133e-01, 3.8054e-02, 2.9991e-02, 4.5062e-01],\n",
      "         [3.9759e-01, 3.2104e-05, 2.6090e-01, 3.4147e-01],\n",
      "         [2.4675e-01, 9.7338e-05, 2.2553e-01, 5.2763e-01],\n",
      "         [4.9528e-01, 1.3112e-04, 5.0160e-01, 2.9867e-03]],\n",
      "\n",
      "        [[5.1854e-01, 7.5958e-02, 3.4988e-01, 5.5627e-02],\n",
      "         [4.4911e-01, 2.5779e-01, 1.2754e-02, 2.8035e-01],\n",
      "         [2.7838e-01, 1.9356e-04, 4.0850e-01, 3.1293e-01],\n",
      "         [2.6215e-01, 1.1953e-03, 2.9791e-01, 4.3874e-01],\n",
      "         [3.0583e-01, 1.1966e-03, 6.2840e-01, 6.4576e-02]]])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "action_probs = torch.tensor([tracker[0]['net_results'][i]['action_probabilities'] for i in range(len(tracker[0]['sentence_texts']))]).squeeze(-2)\n",
    "print(action_probs.shape)\n",
    "print(action_probs.softmax(dim=-1))\n",
    "print(len(tracker[0]['sentence_texts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "isolated-medication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "with open(\"data/train_propara_roberta_version_trips.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "print(len(data))\n",
    "updated_data = []\n",
    "lines = 0\n",
    "for item in tracker:\n",
    "    lines += len(item[\"sentence_texts\"])\n",
    "    try:\n",
    "        temp = item.copy()\n",
    "        new_state = []\n",
    "        location_types = []\n",
    "        for state_id, states in enumerate(temp['states']):\n",
    "            temp2 = [\"-\", ]\n",
    "            \n",
    "            ltemp = []\n",
    "            if states[0] == \"?\":\n",
    "                ltemp.append(\"Unknown\")\n",
    "            elif states[0] == \"-\":\n",
    "                ltemp.append(\"-\")\n",
    "            else:\n",
    "                ltemp.append(\"Known\")\n",
    "                \n",
    "            prev_loc = states[0]\n",
    "            for loc in states[1:]:\n",
    "                if loc == \"?\":\n",
    "                    ltemp.append(\"Unknown\")\n",
    "                elif loc == \"-\":\n",
    "                    ltemp.append(\"-\")\n",
    "                else:\n",
    "                    ltemp.append(\"Known\")\n",
    "\n",
    "                if loc == prev_loc:\n",
    "                    temp2.append(\"No change\")\n",
    "                elif loc != \"-\" and prev_loc == \"-\":\n",
    "                    temp2.append(\"Create\")\n",
    "                elif loc == \"-\" and prev_loc != \"-\":\n",
    "                    temp2.append(\"Destroy\")\n",
    "                else:\n",
    "                    temp2.append(\"Move\")\n",
    "                prev_loc = loc\n",
    "            new_state.append(temp2)\n",
    "            location_types.append(ltemp)\n",
    "        temp['actions'] = new_state\n",
    "        temp['ltype'] = location_types\n",
    "        \n",
    "\n",
    "#         new_annotation = []\n",
    "#         for state in temp['states_annotation']:\n",
    "#             temp2 = state\n",
    "#             for loc in temp2:\n",
    "#                 if loc[0] == \"?\":\n",
    "#                     loc[2] = item['boundaries'][-1][1] + 1\n",
    "#                     loc[3] = item['boundaries'][-1][1] + 1\n",
    "#             new_annotation.append(temp2)\n",
    "\n",
    "#         temp['new_annotation'] = new_annotation\n",
    "    except:\n",
    "        print(item)\n",
    "        raise\n",
    "    updated_data.append(temp)\n",
    "    \n",
    "for item in updated_data:\n",
    "    steps = len(item['sentence_paragraph'])\n",
    "    entities = len(item['participants'])\n",
    "    probs = action_probs = torch.tensor([item['net_results'][i]['action_probabilities'] for i in range(len(item['sentence_texts']))]).squeeze(-2).softmax(dim=-1)\n",
    "    item['action_probs'] = probs.tolist()\n",
    "#     tprobs = torch.softmax(torch.randn(steps, entities, 4), dim=-1)\n",
    "#     item['Taction_probs'] = tprobs.tolist()\n",
    "    \n",
    "with open(\"data/train.json\", \"w\") as file:\n",
    "    json.dump(updated_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "raising-fitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/train.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "constant-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.data.reader import RegrReader\n",
    "import torch\n",
    "\n",
    "\n",
    "class ProparaReader(RegrReader):\n",
    "    def getProcedureIDval(self, item):\n",
    "        return [item[\"para_id\"]]\n",
    "\n",
    "    def getEntitiesval(self, item):\n",
    "        return [' '.join(item['participants'])]\n",
    "        \n",
    "    def getEntityval(self, item):\n",
    "        return item[\"participants\"]\n",
    "    \n",
    "    def getContextval(self, item):\n",
    "        return [item['sentence_paragraph']]\n",
    "\n",
    "    def getStepval(self, item):\n",
    "        sentences = item[\"sentence_texts\"]\n",
    "        return  sentences\n",
    "    \n",
    "    def getActionval(self, item):\n",
    "        return torch.tensor(item['action_probs'])\n",
    "    \n",
    "    def getbeforeval(self, item):\n",
    "        b1s = []\n",
    "        b2s = []\n",
    "        for step in range(len(item[\"sentence_texts\"])):\n",
    "            b1 = torch.zeros(len(item[\"sentence_texts\"]))\n",
    "            b1[step] = 1\n",
    "            for step1 in range(len(item[\"sentence_texts\"])):\n",
    "                b2 = torch.zeros(len(item[\"sentence_texts\"]))\n",
    "                b2[step1] = 1\n",
    "                b1s.append(b1)\n",
    "                b2s.append(b2)\n",
    "        return torch.stack(b1s), torch.stack(b2s)\n",
    "\n",
    "    def getbefore_trueval(self, item):\n",
    "        num_steps = len(item[\"sentence_texts\"])\n",
    "        values = torch.zeros(num_steps * num_steps)\n",
    "        for step in range(len(item[\"sentence_texts\"])):\n",
    "            for step1 in range(step + 1, len(item[\"sentence_texts\"])):\n",
    "                values[(step * num_steps) + step1] = 1\n",
    "        return values\n",
    "    \n",
    "#     def getTActionval(self, item):\n",
    "#         actions = []\n",
    "#         for step, step_text in enumerate(item['sentence_texts']):\n",
    "#             actions.append([])\n",
    "#             for eid, entity in enumerate(item['participants']):\n",
    "#                 actions[-1].append(item['Taction_probs'])\n",
    "\n",
    "#         return torch.tensor(actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "governmental-noise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 6])\n",
      "torch.Size([36, 6])\n",
      "torch.Size([36])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "train_reader = ProparaReader(\"data/train.json\")\n",
    "sample = next(iter(train_reader))\n",
    "print(sample['before'][0].shape)\n",
    "print(sample['before'][1].shape)\n",
    "print(sample['before_true'].shape)\n",
    "print(len(sample['Step']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "improving-flash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file for dataNode is in: /home/hfaghihi/Framework/new/DomiKnowS/examples/ModularPropara/logs/datanode.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main.py:25: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('arg1', 'step'), ('arg2', 'step')]) is used.\n",
      "  before_arg1,\n"
     ]
    }
   ],
   "source": [
    "from regr.graph import Graph, Concept, Relation\n",
    "from regr.graph.logicalConstrain import orL, andL, existsL, notL, atLeastL, atMostL, ifL, nandL, V, exactL\n",
    "from regr.graph import EnumConcept\n",
    "\n",
    "\n",
    "Graph.clear()\n",
    "Concept.clear()\n",
    "Relation.clear()\n",
    "\n",
    "with Graph('global') as graph:\n",
    "    procedure = Concept(\"procedure\")\n",
    "    \n",
    "    context = Concept(\"context\")\n",
    "    entities = Concept(\"entities\")\n",
    "    \n",
    "    (procedure_context, procedure_entities) = procedure.has_a(context, entities)\n",
    "    \n",
    "    entity = Concept('entity')\n",
    "    (entity_rel, ) = entities.contains(entity)\n",
    "    \n",
    "    step = Concept(\"step\")\n",
    "    (context_step, ) = context.contains(step)\n",
    "    \n",
    "    before = Concept(\"before\")\n",
    "    (before_arg1, before_arg2) = before.has_a(arg1=step, arg2=step)\n",
    "    \n",
    "    action = Concept(name='action')\n",
    "    (action_step, action_entity) = action.has_a(step, entity)\n",
    "    \n",
    "    \n",
    "    action_label = action(name=\"action_label\", ConceptClass=EnumConcept, values=[\"nochange\", \"destroy\", \"create\", \"move\"])\n",
    "#     create = action(name=\"create\")\n",
    "#     destroy = action(name=\"destroy\")\n",
    "#     move = action(name=\"move\")\n",
    "#     nochange = action(name='nochange')\n",
    "    \n",
    "#     Tcreate = action(name=\"trips_create\")\n",
    "#     Tdestroy = action(name=\"trips_destroy\")\n",
    "#     Tmove = action(name=\"trips_move\")\n",
    "#     Tnochange = action('trips_none')\n",
    "\n",
    "#     exactL(Tcreate, Tdestroy, Tmove, Tnochange)\n",
    "#     exactL(create, destroy, move, nochange)\n",
    "    \n",
    "#     ifL(Tcreate, create)\n",
    "#     ifL(Tdestroy, destroy)\n",
    "#     ifL(Tmove, move)\n",
    "#     ifL(Tnochange, nochange)\n",
    "    \n",
    "#     ifL(\n",
    "#         destroy('x'), \n",
    "#         notL(\n",
    "#             andL(\n",
    "#                 existsL(\n",
    "#                     andL(destroy('y'), existsL(before('y', path=('x', arg1, 'before', arg1)))),\n",
    "#                     notL(\n",
    "#                         existsL(\n",
    "#                             andL(\n",
    "#                                 create('z'), \n",
    "#                                 eqL(before('z'))\n",
    "#                             )\n",
    "#                         )\n",
    "#                     )\n",
    "#                 )\n",
    "#             )\n",
    "#         )\n",
    "#     )\n",
    "#   atMostL(1, (\"x\"), andL(entity, \"y\", create()))\n",
    "    # No entity_step\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "experienced-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.sensor.pytorch.sensors import FunctionalSensor, JointSensor, ReaderSensor, FunctionalReaderSensor\n",
    "from regr.sensor.pytorch.learners import ModuleLearner\n",
    "from regr.sensor.pytorch.relation_sensors import CompositionCandidateSensor\n",
    "from regr.sensor.pytorch.query_sensor import DataNodeReaderSensor\n",
    "\n",
    "class JointFunctionalReaderSensor(JointSensor, FunctionalReaderSensor):\n",
    "    pass\n",
    "\n",
    "\n",
    "procedure['id'] = ReaderSensor(keyword='ProcedureID')\n",
    "context['text'] = ReaderSensor(keyword='Context')\n",
    "entities['text'] = ReaderSensor(keyword='Entities')\n",
    "\n",
    "def make_procedure(arg1m, arg2m, data):\n",
    "    total_procedures = len(arg1m) * len(arg2m)\n",
    "    rel_links1 = torch.zeros(total_procedures, len(arg1m))\n",
    "    rel_links2 = torch.zeros(total_procedures, len(arg2m))\n",
    "    past1 = 0\n",
    "    past2 = 0\n",
    "    for i in range(total_procedures):\n",
    "        rel_links1[i, past2: past2 + len(arg2m)] = 1\n",
    "        past2 = past2 + len(arg2m)\n",
    "        rel_links2[i, past1: past1 + len(arg1m)] = 1\n",
    "        past1 = past1 + len(arg1m)\n",
    "\n",
    "    return rel_links1, rel_links2\n",
    "    \n",
    "    \n",
    "procedure[procedure_context.reversed, procedure_entities.reversed] = JointFunctionalReaderSensor(context['text'], entities['text'], keyword=\"ProcedureID\", forward=make_procedure)\n",
    "\n",
    "def read_initials(*prev, data):\n",
    "    number = len(data)\n",
    "    rel_links = torch.ones(number, 1)\n",
    "    indexes = [i for i in range(number)]\n",
    "    print(rel_links, data, indexes)\n",
    "    return rel_links, data, indexes\n",
    "\n",
    "entity[entity_rel, 'text', 'index'] = JointFunctionalReaderSensor(entities['text'], keyword='Entity', forward=read_initials)\n",
    "\n",
    "step[context_step, 'text', 'index'] = JointFunctionalReaderSensor(context['text'], keyword='Step', forward=read_initials)\n",
    "\n",
    "def make_actions(r1, r2, entities, steps):\n",
    "    print(r1, r2)\n",
    "    all_actions = len(steps) * len(entities)\n",
    "    link1 = torch.zeros(all_actions, len(steps))\n",
    "    link2 = torch.zeros(all_actions, len(entities))\n",
    "    for i in range(len(steps)):\n",
    "        link1[i*len(entities):(i+1)*len(entities),i] = 1\n",
    "\n",
    "    for j in range(all_actions):\n",
    "        link2[j, j%len(entities)] = 1\n",
    "    \n",
    "#     print(link1, link2)\n",
    "#     print(\"steps: \", len(steps))\n",
    "#     print(\"entities: \", len(entities))\n",
    "    return link1, link2\n",
    "    \n",
    "action[action_step.reversed, action_entity.reversed] = JointSensor(entity[entity_rel], step[context_step], entity['index'], step['index'], forward=make_actions)\n",
    "\n",
    "def read_labels(*prevs, data):\n",
    "    print(prevs[0].shape, prevs[1].shape)\n",
    "    c = data.view(1, -1, *(data.size()[2:]))\n",
    "    print(c.squeeze(0).shape)\n",
    "    return c.squeeze(0)\n",
    "#     pass\n",
    "    \n",
    "action[action_label] = FunctionalReaderSensor(action_step.reversed, action_entity.reversed, keyword=\"Action\", forward=read_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "behavioral-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.program import POIProgram, IMLProgram, SolverPOIProgram\n",
    "from regr.program.primaldualprogram import PrimalDualProgram\n",
    "from regr.program.model.pytorch import SolverModel\n",
    "from regr.program.metric import MacroAverageTracker, PRF1Tracker, PRF1Tracker, DatanodeCMMetric\n",
    "from regr.program.loss import NBCrossEntropyLoss, NBCrossEntropyIMLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "whole-facial",
   "metadata": {},
   "outputs": [],
   "source": [
    "program = SolverPOIProgram(graph, poi=(procedure, action, action_label), inferTypes=['ILP', 'local/argmax'], loss=MacroAverageTracker(NBCrossEntropyLoss()), metric={'ILP':PRF1Tracker(DatanodeCMMetric()),'argmax':PRF1Tracker(DatanodeCMMetric('local/argmax'))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "broadband-butler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]) ['plant; animal', 'soft tissues', 'bones', 'mineral', 'fossils'] [0, 1, 2, 3, 4]\n",
      "<class 'regr.graph.graph.Graph'>\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "edgesensor-2\n",
      "Error list index out of range during updating data item {'Action': tensor([[[3.1940e-01, 4.0114e-01, 1.0121e-02, 2.6934e-01],\n",
      "         [6.1400e-01, 4.4190e-03, 4.0276e-02, 3.4130e-01],\n",
      "         [6.1400e-01, 4.4190e-03, 4.0276e-02, 3.4130e-01],\n",
      "         [6.1400e-01, 4.4190e-03, 4.0276e-02, 3.4130e-01],\n",
      "         [6.1400e-01, 4.4190e-03, 4.0276e-02, 3.4130e-01]],\n",
      "\n",
      "        [[7.0585e-01, 7.2110e-04, 3.8825e-02, 2.5460e-01],\n",
      "         [7.0585e-01, 7.2110e-04, 3.8825e-02, 2.5460e-01],\n",
      "         [7.0585e-01, 7.2110e-04, 3.8825e-02, 2.5460e-01],\n",
      "         [7.0585e-01, 7.2110e-04, 3.8825e-02, 2.5460e-01],\n",
      "         [7.0585e-01, 7.2110e-04, 3.8825e-02, 2.5460e-01]],\n",
      "\n",
      "        [[5.7955e-01, 3.5761e-04, 3.9642e-01, 2.3672e-02],\n",
      "         [4.5550e-01, 2.2812e-02, 2.1059e-02, 5.0063e-01],\n",
      "         [2.4481e-01, 1.5927e-05, 5.0667e-01, 2.4850e-01],\n",
      "         [5.7955e-01, 3.5761e-04, 3.9642e-01, 2.3672e-02],\n",
      "         [5.7955e-01, 3.5761e-04, 3.9642e-01, 2.3672e-02]],\n",
      "\n",
      "        [[5.8445e-01, 2.2438e-04, 4.1525e-01, 7.7910e-05],\n",
      "         [4.7322e-01, 1.5209e-01, 2.2237e-02, 3.5245e-01],\n",
      "         [3.9070e-01, 1.2423e-04, 4.6707e-01, 1.4211e-01],\n",
      "         [5.8445e-01, 2.2438e-04, 4.1525e-01, 7.7910e-05],\n",
      "         [5.8445e-01, 2.2438e-04, 4.1525e-01, 7.7910e-05]],\n",
      "\n",
      "        [[4.9528e-01, 1.3112e-04, 5.0160e-01, 2.9867e-03],\n",
      "         [4.8133e-01, 3.8054e-02, 2.9991e-02, 4.5062e-01],\n",
      "         [3.9759e-01, 3.2104e-05, 2.6090e-01, 3.4147e-01],\n",
      "         [2.4675e-01, 9.7338e-05, 2.2553e-01, 5.2763e-01],\n",
      "         [4.9528e-01, 1.3112e-04, 5.0160e-01, 2.9867e-03]],\n",
      "\n",
      "        [[5.1854e-01, 7.5958e-02, 3.4988e-01, 5.5627e-02],\n",
      "         [4.4911e-01, 2.5779e-01, 1.2754e-02, 2.8035e-01],\n",
      "         [2.7838e-01, 1.9356e-04, 4.0850e-01, 3.1293e-01],\n",
      "         [2.6215e-01, 1.1953e-03, 2.9791e-01, 4.3874e-01],\n",
      "         [3.0583e-01, 1.1966e-03, 6.2840e-01, 6.4576e-02]]]), 'Context': ['a plant of animal dies in a watery environment . is buried in mud and silt . soft tissues quickly decompose leaving behind hard bones or shells . over time sediment builds over the top and hardens into rock . as the bone decays mineral seeps in replacing it . fossils are formed .'], 'Entities': ['plant; animal soft tissues bones mineral fossils'], 'Entity': ['plant; animal', 'soft tissues', 'bones', 'mineral', 'fossils'], 'ProcedureID': [37], 'Step': ['a plant of animal dies in a watery environment .', 'is buried in mud and silt .', 'soft tissues quickly decompose leaving behind hard bones or shells .', 'over time sediment builds over the top and hardens into rock .', 'as the bone decays mineral seeps in replacing it .', 'fossils are formed .'], 'before_true': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), 'before': (tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.]]), tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.]])), 'graph': Graph(name='global', fullname='global'), 'READER': 0, 'Counter_setitem': 16, 'Counter/global/procedure/id/readersensor': {tensor([37]): {'counter': 1, 'recent': True}}, 'dataNode': [], 'global/procedure/index': [procedure 0], ReaderSensor(name='readersensor', fullname='global/procedure/id/readersensor'): tensor([37]), 'DataNodeTime': 0.0022444725036621094, Property(name='id', fullname='global/procedure/id'): tensor([37]), 'Counter/global/context/text/readersensor-1': {('a plant of animal dies in a watery environment . is buried in mud and silt . soft tissues quickly decompose leaving behind hard bones or shells . over time sediment builds over the top and hardens into rock . as the bone decays mineral seeps in replacing it . fossils are formed .',): {'counter': 1, 'recent': True}}, 'global/context/index': [context 0], ReaderSensor(name='readersensor-1', fullname='global/context/text/readersensor-1'): ['a plant of animal dies in a watery environment . is buried in mud and silt . soft tissues quickly decompose leaving behind hard bones or shells . over time sediment builds over the top and hardens into rock . as the bone decays mineral seeps in replacing it . fossils are formed .'], Property(name='text', fullname='global/context/text'): ['a plant of animal dies in a watery environment . is buried in mud and silt . soft tissues quickly decompose leaving behind hard bones or shells . over time sediment builds over the top and hardens into rock . as the bone decays mineral seeps in replacing it . fossils are formed .'], 'Counter/global/entities/text/readersensor-2': {('plant; animal soft tissues bones mineral fossils',): {'counter': 1, 'recent': True}}, 'global/entities/index': [entities 0], ReaderSensor(name='readersensor-2', fullname='global/entities/text/readersensor-2'): ['plant; animal soft tissues bones mineral fossils'], Property(name='text-1', fullname='global/entities/text'): ['plant; animal soft tissues bones mineral fossils'], JointFunctionalReaderSensor(name='jointfunctionalreadersensor', fullname='global/procedure/(Relation(name='procedure-has_a-0-context.reversed', fullname='global/procedure-has_a-0-context.reversed'), Relation(name='procedure-has_a-1-entities.reversed', fullname='global/procedure-has_a-1-entities.reversed'))/jointfunctionalreadersensor'): (tensor([[1.]]), tensor([[1.]])), Property(name='(Relation(name='procedure-has_a-0-context.reversed', fullname='global/procedure-has_a-0-context.reversed'), Relation(name='procedure-has_a-1-entities.reversed', fullname='global/procedure-has_a-1-entities.reversed'))', fullname='global/procedure/(Relation(name='procedure-has_a-0-context.reversed', fullname='global/procedure-has_a-0-context.reversed'), Relation(name='procedure-has_a-1-entities.reversed', fullname='global/procedure-has_a-1-entities.reversed'))'): (tensor([[1.]]), tensor([[1.]])), 'Counter/global/procedure/procedure-has_a-0-context.reversed/edgesensor': {tensor([[1.]]): {'counter': 1, 'recent': True}}, 'procedureRelationAttrsCache': {'procedure-has_a-0-context': tensor([[1.]]), 'procedure-has_a-1-entities': tensor([[1.]])}, EdgeSensor(name='edgesensor', fullname='global/procedure/procedure-has_a-0-context.reversed/edgesensor'): tensor([[1.]]), Property(name='procedure-has_a-0-context.reversed', fullname='global/procedure/procedure-has_a-0-context.reversed'): tensor([[1.]]), 'Counter/global/procedure/procedure-has_a-1-entities.reversed/edgesensor-1': {tensor([[1.]]): {'counter': 1, 'recent': True}}, EdgeSensor(name='edgesensor-1', fullname='global/procedure/procedure-has_a-1-entities.reversed/edgesensor-1'): tensor([[1.]]), Property(name='procedure-has_a-1-entities.reversed', fullname='global/procedure/procedure-has_a-1-entities.reversed'): tensor([[1.]]), JointFunctionalReaderSensor(name='jointfunctionalreadersensor-1', fullname='global/entity/(Contains(name='entities-contains-0-entity', fullname='global/entities-contains-0-entity'), 'text', 'index')/jointfunctionalreadersensor-1'): (tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), ['plant; animal', 'soft tissues', 'bones', 'mineral', 'fossils'], [0, 1, 2, 3, 4]), Property(name='(Contains(name='entities-contains-0-entity', fullname='global/entities-contains-0-entity'), 'text', 'index')', fullname='global/entity/(Contains(name='entities-contains-0-entity', fullname='global/entities-contains-0-entity'), 'text', 'index')'): (tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), ['plant; animal', 'soft tissues', 'bones', 'mineral', 'fossils'], [0, 1, 2, 3, 4]), 'Counter/global/entity/entities-contains-0-entity/edgesensor-2': {tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]): {'counter': 1, 'recent': True}}} with sensor global/entity/entities-contains-0-entity/edgesensor-2\n",
      "Error list index out of range during updating data item {'Action': tensor([[[3.1940e-01, 4.0114e-01, 1.0121e-02, 2.6934e-01],\n",
      "         [6.1400e-01, 4.4190e-03, 4.0276e-02, 3.4130e-01],\n",
      "         [6.1400e-01, 4.4190e-03, 4.0276e-02, 3.4130e-01],\n",
      "         [6.1400e-01, 4.4190e-03, 4.0276e-02, 3.4130e-01],\n",
      "         [6.1400e-01, 4.4190e-03, 4.0276e-02, 3.4130e-01]],\n",
      "\n",
      "        [[7.0585e-01, 7.2110e-04, 3.8825e-02, 2.5460e-01],\n",
      "         [7.0585e-01, 7.2110e-04, 3.8825e-02, 2.5460e-01],\n",
      "         [7.0585e-01, 7.2110e-04, 3.8825e-02, 2.5460e-01],\n",
      "         [7.0585e-01, 7.2110e-04, 3.8825e-02, 2.5460e-01],\n",
      "         [7.0585e-01, 7.2110e-04, 3.8825e-02, 2.5460e-01]],\n",
      "\n",
      "        [[5.7955e-01, 3.5761e-04, 3.9642e-01, 2.3672e-02],\n",
      "         [4.5550e-01, 2.2812e-02, 2.1059e-02, 5.0063e-01],\n",
      "         [2.4481e-01, 1.5927e-05, 5.0667e-01, 2.4850e-01],\n",
      "         [5.7955e-01, 3.5761e-04, 3.9642e-01, 2.3672e-02],\n",
      "         [5.7955e-01, 3.5761e-04, 3.9642e-01, 2.3672e-02]],\n",
      "\n",
      "        [[5.8445e-01, 2.2438e-04, 4.1525e-01, 7.7910e-05],\n",
      "         [4.7322e-01, 1.5209e-01, 2.2237e-02, 3.5245e-01],\n",
      "         [3.9070e-01, 1.2423e-04, 4.6707e-01, 1.4211e-01],\n",
      "         [5.8445e-01, 2.2438e-04, 4.1525e-01, 7.7910e-05],\n",
      "         [5.8445e-01, 2.2438e-04, 4.1525e-01, 7.7910e-05]],\n",
      "\n",
      "        [[4.9528e-01, 1.3112e-04, 5.0160e-01, 2.9867e-03],\n",
      "         [4.8133e-01, 3.8054e-02, 2.9991e-02, 4.5062e-01],\n",
      "         [3.9759e-01, 3.2104e-05, 2.6090e-01, 3.4147e-01],\n",
      "         [2.4675e-01, 9.7338e-05, 2.2553e-01, 5.2763e-01],\n",
      "         [4.9528e-01, 1.3112e-04, 5.0160e-01, 2.9867e-03]],\n",
      "\n",
      "        [[5.1854e-01, 7.5958e-02, 3.4988e-01, 5.5627e-02],\n",
      "         [4.4911e-01, 2.5779e-01, 1.2754e-02, 2.8035e-01],\n",
      "         [2.7838e-01, 1.9356e-04, 4.0850e-01, 3.1293e-01],\n",
      "         [2.6215e-01, 1.1953e-03, 2.9791e-01, 4.3874e-01],\n",
      "         [3.0583e-01, 1.1966e-03, 6.2840e-01, 6.4576e-02]]]), 'Context': ['a plant of animal dies in a watery environment . is buried in mud and silt . soft tissues quickly decompose leaving behind hard bones or shells . over time sediment builds over the top and hardens into rock . as the bone decays mineral seeps in replacing it . fossils are formed .'], 'Entities': ['plant; animal soft tissues bones mineral fossils'], 'Entity': ['plant; animal', 'soft tissues', 'bones', 'mineral', 'fossils'], 'ProcedureID': [37], 'Step': ['a plant of animal dies in a watery environment .', 'is buried in mud and silt .', 'soft tissues quickly decompose leaving behind hard bones or shells .', 'over time sediment builds over the top and hardens into rock .', 'as the bone decays mineral seeps in replacing it .', 'fossils are formed .'], 'before_true': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), 'before': (tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.]]), tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.]])), 'graph': Graph(name='global', fullname='global'), 'READER': 0, 'Counter_setitem': 16, 'Counter/global/procedure/id/readersensor': {tensor([37]): {'counter': 1, 'recent': True}}, 'dataNode': [], 'global/procedure/index': [procedure 0], ReaderSensor(name='readersensor', fullname='global/procedure/id/readersensor'): tensor([37]), 'DataNodeTime': 0.0022444725036621094, Property(name='id', fullname='global/procedure/id'): tensor([37]), 'Counter/global/context/text/readersensor-1': {('a plant of animal dies in a watery environment . is buried in mud and silt . soft tissues quickly decompose leaving behind hard bones or shells . over time sediment builds over the top and hardens into rock . as the bone decays mineral seeps in replacing it . fossils are formed .',): {'counter': 1, 'recent': True}}, 'global/context/index': [context 0], ReaderSensor(name='readersensor-1', fullname='global/context/text/readersensor-1'): ['a plant of animal dies in a watery environment . is buried in mud and silt . soft tissues quickly decompose leaving behind hard bones or shells . over time sediment builds over the top and hardens into rock . as the bone decays mineral seeps in replacing it . fossils are formed .'], Property(name='text', fullname='global/context/text'): ['a plant of animal dies in a watery environment . is buried in mud and silt . soft tissues quickly decompose leaving behind hard bones or shells . over time sediment builds over the top and hardens into rock . as the bone decays mineral seeps in replacing it . fossils are formed .'], 'Counter/global/entities/text/readersensor-2': {('plant; animal soft tissues bones mineral fossils',): {'counter': 1, 'recent': True}}, 'global/entities/index': [entities 0], ReaderSensor(name='readersensor-2', fullname='global/entities/text/readersensor-2'): ['plant; animal soft tissues bones mineral fossils'], Property(name='text-1', fullname='global/entities/text'): ['plant; animal soft tissues bones mineral fossils'], JointFunctionalReaderSensor(name='jointfunctionalreadersensor', fullname='global/procedure/(Relation(name='procedure-has_a-0-context.reversed', fullname='global/procedure-has_a-0-context.reversed'), Relation(name='procedure-has_a-1-entities.reversed', fullname='global/procedure-has_a-1-entities.reversed'))/jointfunctionalreadersensor'): (tensor([[1.]]), tensor([[1.]])), Property(name='(Relation(name='procedure-has_a-0-context.reversed', fullname='global/procedure-has_a-0-context.reversed'), Relation(name='procedure-has_a-1-entities.reversed', fullname='global/procedure-has_a-1-entities.reversed'))', fullname='global/procedure/(Relation(name='procedure-has_a-0-context.reversed', fullname='global/procedure-has_a-0-context.reversed'), Relation(name='procedure-has_a-1-entities.reversed', fullname='global/procedure-has_a-1-entities.reversed'))'): (tensor([[1.]]), tensor([[1.]])), 'Counter/global/procedure/procedure-has_a-0-context.reversed/edgesensor': {tensor([[1.]]): {'counter': 1, 'recent': True}}, 'procedureRelationAttrsCache': {'procedure-has_a-0-context': tensor([[1.]]), 'procedure-has_a-1-entities': tensor([[1.]])}, EdgeSensor(name='edgesensor', fullname='global/procedure/procedure-has_a-0-context.reversed/edgesensor'): tensor([[1.]]), Property(name='procedure-has_a-0-context.reversed', fullname='global/procedure/procedure-has_a-0-context.reversed'): tensor([[1.]]), 'Counter/global/procedure/procedure-has_a-1-entities.reversed/edgesensor-1': {tensor([[1.]]): {'counter': 1, 'recent': True}}, EdgeSensor(name='edgesensor-1', fullname='global/procedure/procedure-has_a-1-entities.reversed/edgesensor-1'): tensor([[1.]]), Property(name='procedure-has_a-1-entities.reversed', fullname='global/procedure/procedure-has_a-1-entities.reversed'): tensor([[1.]]), JointFunctionalReaderSensor(name='jointfunctionalreadersensor-1', fullname='global/entity/(Contains(name='entities-contains-0-entity', fullname='global/entities-contains-0-entity'), 'text', 'index')/jointfunctionalreadersensor-1'): (tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), ['plant; animal', 'soft tissues', 'bones', 'mineral', 'fossils'], [0, 1, 2, 3, 4]), Property(name='(Contains(name='entities-contains-0-entity', fullname='global/entities-contains-0-entity'), 'text', 'index')', fullname='global/entity/(Contains(name='entities-contains-0-entity', fullname='global/entities-contains-0-entity'), 'text', 'index')'): (tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), ['plant; animal', 'soft tissues', 'bones', 'mineral', 'fossils'], [0, 1, 2, 3, 4]), 'Counter/global/entity/entities-contains-0-entity/edgesensor-2': {tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]): {'counter': 1, 'recent': True}}} with sensor global/action/(Relation(name='action-has_a-0-step.reversed', fullname='global/action-has_a-0-step.reversed'), Relation(name='action-has_a-1-entity.reversed', fullname='global/action-has_a-1-entity.reversed'))/jointsensor\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Framework/new/DomiKnowS/examples/ModularPropara/main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     lbp.test(dataset, device='auto')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mall_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdatanode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlbp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdatanode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferILPResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/program/program.py\u001b[0m in \u001b[0;36mpopulate\u001b[0;34m(self, dataset, device)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpopulate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/program/program.py\u001b[0m in \u001b[0;36mpopulate_epoch\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdata_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mdetuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/program/model/pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data_item, build)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdata_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"graph\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'READER'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mbuilder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataNodeBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;34m*\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mdatanode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetDataNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatanode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/program/model/pytorch.py\u001b[0m in \u001b[0;36mpopulate\u001b[0;34m(self, builder, run)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpopulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mdata_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/program/model/pytorch.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, builder)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTorchSensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0msensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;31m#             for output_sensor, target_sensor in self.find_sensors(prop):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;31m#             # make sure the sensors are evaluated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbundle_call\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data_item)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_helper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error {} during updating data item {} with sensor {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36mupdate_context\u001b[0;34m(self, data_item, force, override)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         override=True):\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36mupdate_context\u001b[0;34m(self, data_item, force, override)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_pre_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefine_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36mupdate_pre_context\u001b[0;34m(self, data_item, concept)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProperty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_label_sensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0msensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mpre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data_item)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_helper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error {} during updating data item {} with sensor {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36mupdate_context\u001b[0;34m(self, data_item, force, override)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mdata_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'graph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/graph/dataNode.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, _key, value)\u001b[0m\n\u001b[1;32m   1886\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m             \u001b[0m_DataNodeBulder__Logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s found in the graph; it is a concept'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_conceptName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1888\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__buildDataNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvInfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconceptInfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeyDataName\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Build or update Data node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/graph/dataNode.py\u001b[0m in \u001b[0;36m__buildDataNode\u001b[0;34m(self, vInfo, conceptInfo, keyDataName)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m             \u001b[0;31m# ---------- DataNodes already created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m             \u001b[0mexistingDnsForConcept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindDataNodesInBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconceptName\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Try to get DataNodes of the current concept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexistingDnsForConcept\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m# Check if datannote for this concept already created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/graph/dataNode.py\u001b[0m in \u001b[0;36mfindDataNodesInBuilder\u001b[0;34m(self, select, indexes)\u001b[0m\n\u001b[1;32m   1931\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfindDataNodesInBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m         \u001b[0mexistingRootDns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dataNode'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Datanodes roots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1933\u001b[0;31m         \u001b[0mfoundDns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexistingRootDns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindDatanodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexistingRootDns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1935\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfoundDns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "lbp = program\n",
    "\n",
    "dataset = ProparaReader(file=\"data/train.json\")  # Adding the info on the reader\n",
    "\n",
    "#     lbp.test(dataset, device='auto')\n",
    "all_updates = []\n",
    "for datanode in lbp.populate(dataset, device=\"cpu\"):\n",
    "    datanode.inferILPResults(action_label, fun=None)\n",
    "\n",
    "    final_output = {\n",
    "        \"id\": datanode.getAttribute(\"id\"),\n",
    "        \"steps\": [],\n",
    "        \"actions\": [],\n",
    "        \"steps_before\": [],\n",
    "        \"actions_before\": [],\n",
    "    }\n",
    "\n",
    "    for action_info in datanode.findDatanodes(select=action):\n",
    "        c = action_info.getAttribute(action_label, \"ILP\")\n",
    "        final_output[\"actions\"].append(c)\n",
    "        c = action_info.getAttribute(action_label)\n",
    "        final_output[\"actions_before\"].append(c)\n",
    "\n",
    "    all_updates.append(final_output)\n",
    "\n",
    "#         print('datanode:', datanode)\n",
    "#         print('inference spam:', datanode.getAttribute(Spam, 'ILP'))\n",
    "#         print('inference regular:', datanode.getAttribute(Regular, 'ILP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-scoop",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-salem",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
